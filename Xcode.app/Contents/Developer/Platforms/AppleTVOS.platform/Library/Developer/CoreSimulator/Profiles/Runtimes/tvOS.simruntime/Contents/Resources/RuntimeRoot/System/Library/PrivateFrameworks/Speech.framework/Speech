@(#)PROGRAM:Speech  PROJECT:SpeechRecognition-1
MbP?
@mcpl
_acousticFeaturePerFrame
_frameDuration
, featureValues=%@, frameDuration=%f
supportsSecureCoding
TB,R
acousticFeatureValuePerFrame
T@"NSArray",R,C,N,V_acousticFeatureValuePerFrame
frameDuration
Td,R,N,V_frameDuration
_jitter
_shimmer
_pitch
_voicing
, jitter=%@, shimmer=%@, pitch=%@, voicing=%@
jitter
T@"SFAcousticFeature",R,C,N,V_jitter
shimmer
T@"SFAcousticFeature",R,C,N,V_shimmer
pitch
T@"SFAcousticFeature",R,C,N,V_pitch
voicing
T@"SFAcousticFeature",R,C,N,V_voicing
speakingRate
averagePauseDuration
v32@?0@"NSString"8@"NSString"16^B24
response
T@"NSHTTPURLResponse",R,N,V_response
data
T@"NSData",R,N,V_data
searchType
Tq,R,N,V_searchType
com.apple.Speech.Task.Internal
v8@?0
User denied access to speech recognition
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
_taskHint
Tq,R,N,V_taskHint
requestIdentifier
T@"NSString",R,C,N,V_requestIdentifier
state
Tq,R,N
finishing
TB,R,N,GisFinishing,V_finishing
cancelled
TB,R,N,GisCancelled,V_cancelled
error
T@"NSError",R,C,N,V_error
v24@?0@"SFSpeechRecognitionResult"8@"NSError"16
v32@?0@"AFSpeechToken"8Q16^B24
v32@?0@"AFSpeechInterpretation"8Q16^B24
_bestTranscription
_rawTranscription
_final
 final=%d, bestTranscription=%@
v32@?0@"NSString"8Q16^B24
v32@?0@"SFTranscriptionSegment"8Q16^B24
rawTranscription
T@"SFTranscription",R,C,N,V_rawTranscription
rawTranscriptions
T@"NSArray",R,C,N
bestTranscription
T@"SFTranscription",R,C,N,V_bestTranscription
transcriptions
final
TB,R,N,GisFinal,V_final
hi-IN
Cannot make recognizer for %@. Supported locale identifiers are %@
%@-%@
v16@?0@"NSNotification"8
v16@?0@"NSArray"8
Result handler must be non-null
%@ queue must not be nil
_availableForForcedOfflineRecognition
TB,R,N,G_isAvailableForForcedOfflineRecognition
available
TB,R,N,GisAvailable
locale
T@"NSLocale",R,C,N,V_locale
supportsOnDeviceRecognition
TB,N,V_supportsOnDeviceRecognition
delegate
T@"<SFSpeechRecognizerDelegate>",W,N,V_delegate
defaultTaskHint
Tq,N,V_defaultTaskHint
queue
T@"NSOperationQueue",&,N,V_queue
, substringRange=%@, timestamp=%@, duration=%@, confidence=%@, substring=%@, alternativeSubstrings=%@, phoneSequence=%@, ipaPhoneSequence=%@, voiceAnalytics=%@
_substring
_substringRange.location
_substringRange.length
_timestamp
_duration
_confidence
_alternativeSubstrings
_alternativeConfidences
_phoneSequence
_ipaPhoneSequence
_voiceAnalytics
SFTranscriptionSegment.m
alternativeConfidences
T@"NSArray",R,N,V_alternativeConfidences
phoneSequence
T@"NSString",R,N,V_phoneSequence
ipaPhoneSequence
T@"NSString",R,N,V_ipaPhoneSequence
substring
T@"NSString",R,C,N,V_substring
substringRange
T{_NSRange=QQ},R,N,V_substringRange
timestamp
Td,R,N,V_timestamp
duration
Td,R,N,V_duration
confidence
Tf,R,N,V_confidence
alternativeSubstrings
T@"NSArray",R,N,V_alternativeSubstrings
voiceAnalytics
T@"SFVoiceAnalytics",R,N,V_voiceAnalytics
SFSpeechPreecordedRequest
hi-IN-translit
Translit
searchTypes
Tq,N,V_searchTypes
headerFields
T@"NSDictionary",C,N,V_headerFields
queryParameters
T@"NSDictionary",C,N,V_queryParameters
_searchRequest
T@"_SFSearchRequest",&,N,G_searchRequest,S_setSearchRequest:,V_searchRequest
detectMultipleUtterances
TB,N,V_detectMultipleUtterances
_forceOfflineRecognition
TB,N,G_forceOfflineRecognition,S_setForceOfflineRecognition:,V_forceOfflineRecognition
_voiceTriggerEventInfo
T@"NSDictionary",&,N,G_voiceTriggerEventInfo,S_setVoiceTriggerEventInfo:,V_voiceTriggerEventInfo
_maximumRecognitionDuration
Td,N,G_maximumRecognitionDuration,S_setMaximumRecognitionDuration:,V_maximumRecognitionDuration
_recognitionOverrides
T@"NSDictionary",&,N,G_recognitionOverrides,S_setRecognitionOverrides:,V_recognitionOverrides
_modelOverrideURL
T@"NSURL",&,N,G_modelOverrideURL,S_setModelOverrideURL:,V_modelOverrideURL
taskHint
Tq,N,V_taskHint
shouldReportPartialResults
TB,N,V_shouldReportPartialResults
contextualStrings
T@"NSArray",C,N,V_contextualStrings
interactionIdentifier
T@"NSString",C,N,V_interactionIdentifier
requiresOnDeviceRecognition
TB,N
Use -[SFSpeechURLRecognitionRequest initWithURL:]
Could not add output for %@
B8@?0
T@"NSURL",R,C,N,V_URL
com.apple.SFSpeechAudioBufferRecognitionRequest
SFSpeechRecognitionRequest.m
%@ cannot be re-used
Invalid audio format
@"AVAudioBuffer"20@?0I8^q12
Could not drain converter %@
Could not run audio converter %@
nativeAudioFormat
T@"AVAudioFormat",R,N
CMBlockBufferCopyDataBytes could not copy data: %d
_speakingRate
_avgPauseDuration
, formattedString=%@, segments=%@, speakingRate=%f, averagePauseDuration=%f
_segments
_formattedString
formattedString
T@"NSString",R,C,N,V_formattedString
segments
T@"NSArray",R,C,N,V_segments
Td,R,N,V_speakingRate
Td,R,N,V_averagePauseDuration
SFAcousticFeature
NSCopying
NSSecureCoding
NSCoding
SFVoiceAnalytics
_SFSearchResult
SFSpeechRecognitionTask
AFDictationDelegate
NSObject
SFSpeechRecognitionBufferDelegate
_SFSpeechRecognitionBlockTask
_SFSpeechRecognitionDelegateTask
SFSpeechRecognitionResult
SFSpeechRecognizer
SFTranscriptionSegment
_SFSearchRequest
SFSpeechRecognitionRequest
SFSpeechURLRecognitionRequest
SFSpeechAudioBufferRecognitionRequest
SFTranscription
encodeObject:forKey:
encodeDouble:forKey:
init
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
decodeDoubleForKey:
copy
description
stringByAppendingFormat:
supportsSecureCoding
copyWithZone:
encodeWithCoder:
initWithCoder:
_initWithAcousticFeatureValue:frameDuration:
acousticFeatureValuePerFrame
frameDuration
.cxx_destruct
_acousticFeatureValuePerFrame
_frameDuration
decodeObjectOfClass:forKey:
_initWithJitter:shimmer:pitch:voicing:
jitter
shimmer
pitch
voicing
_jitter
_shimmer
_pitch
_voicing
statusCode
intValue
headers
enumerateKeysAndObjectsUsingBlock:
_responseWithCFURLResponse:
result
searchType
isEqualToString:
JSONObjectWithData:options:error:
dataWithJSONObject:options:error:
initWithData:encoding:
stringByAppendingString:
initWithVoiceSearchResult:
response
data
_response
_data
_searchType
UUID
UUIDString
taskHint
_startedConnectionWithLanguageCode:delegate:taskHint:requestIdentifier:
stopSpeechWithOptions:
cancelSpeech
peakPower
averagePower
code
dictionaryWithObjects:forKeys:count:
errorWithDomain:code:userInfo:
addRecordedSpeechSampleData:
array
string
countByEnumeratingWithState:objects:count:
removeSpaceBefore
removeSpaceAfter
appendString:
text
length
startTime
silenceStartTime
confidenceScore
_initWithSubstring:range:timestamp:duration:confidence:alternativeSubstrings:alternativeConfidences:phoneSequence:ipaPhoneSequence:voiceAnalytics:
addObject:
_initWithSegments:formattedString:speakingRate:averagePauseDuration:
recognition
phrases
audioAnalytics
utteranceStart
rawRecognition
isFinal
_initWithBestTranscription:rawTranscription:final:
transcriptionsWithTokens:
recognizedResultFromPackage:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
dictationConnectionSpeechRecordingWillBegin:
dictationConnectionSpeechRecordingDidBegin:
dictationConnection:speechRecordingDidBeginWithOptions:
dictationConnection:didBeginLocalRecognitionWithModelInfo:
dictationConnectionSpeechRecordingDidEnd:
dictationConnectionSpeechRecordingDidCancel:
dictationConnection:speechRecordingDidFail:
dictationConnection:speechRecognitionDidFail:
dictationConnection:didDetectLanguage:confidenceScores:
dictationConnection:didDetectLanguage:confidenceScores:isConfident:
dictationConnection:didRecognizeMultilingualSpeech:
dictationConnection:languageDetectorFailedWithError:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:
dictationConnection:didRecognizePhrases:languageModel:correctionIdentifier:replacingPreviousPhrasesCount:
dictationConnection:didRecognizeTokens:languageModel:
dictationConnection:didRecognizePartialResult:
dictationConnection:didProcessAudioDuration:
dictationConnectionSpeechRecognitionDidSucceed:
dictationConnection:didRecognizeTranscriptionObjects:languageModel:
dictationConnnectionDidChangeAvailability:
dictationConnection:didFinishWritingAudioFile:error:
dictationConnection:didReceiveSearchResults:recognizedText:stable:final:
dictationConnection:didRecognizePackage:
stopSpeech
_initWithRequest:queue:languageCode:taskHint:
state
finish
cancel
_taskHint
isFinishing
isCancelled
error
requestIdentifier
_dictationConnection
_externalQueue
_languageCode
_request
_internalQueue
_completed
_running
_finishing
_cancelled
_error
_requestIdentifier
addOperationWithBlock:
_fireResultHandlerWithResult:error:
_finalizeResultHandler
shouldReportPartialResults
_initWithRequest:queue:languageCode:taskHint:resultHandler:
_resultHandler
_hasFiredFinalResult
_searchRequest
speechRecognitionTaskWasCancelled:
speechRecognitionTask:didFinishSuccessfully:
_tellDelegateDidFinishSuccessfully:
speechRecognitionTaskFinishedReadingAudio:
speechRecognitionTask:didReceiveSearchResults:recognizedText:stable:final:
bestTranscription
formattedString
speechRecognitionTask:didFinishRecognition:
speechRecognitionTask:didHypothesizeTranscription:
speechRecognitionTask:didProcessAudioDuration:
numberWithInteger:
setObject:forKey:
_initWithRequest:queue:languageCode:taskHint:delegate:
_delegate
_recognitionResultToReportAfterFinalSearchResults
_selfReference
_waitForVoiceSearchResult
_hasSentRealSearchResults
interpretations
firstObject
tokens
numberWithDouble:
phoneSequence
ipaPhoneSequence
enumerateObjectsUsingBlock:
stringWithString:
speechRecognitionFeatures
objectForKey:
doubleValue
acousticFeatures
count
subarrayWithRange:
decodeBoolForKey:
encodeBool:forKey:
segments
alternativeSubstrings
alternativeConfidences
mutableCopy
substring
insertObject:atIndex:
confidence
numberWithFloat:
addObjectsFromArray:
substringRange
removeObjectAtIndex:
objectAtIndex:
timestamp
duration
floatValue
stringByReplacingCharactersInRange:withString:
expandTranscription:
_initWithBestTranscription:final:
transcriptions
rawTranscriptions
rawTranscription
_transcriptions
_rawTranscriptions
_final
_bestTranscription
_rawTranscription
setWithCapacity:
localeWithLocaleIdentifier:
currentLocale
initWithLocale:
localeIdentifier
stringByReplacingOccurrencesOfString:withString:
containsObject:
stringWithFormat:
mainQueue
setDelegate:
beginAvailabilityMonitoring
defaultCenter
_informDelegateOfPreferencesChange
addObserverForName:object:queue:usingBlock:
endSession
cancelAvailabilityMonitoring
removeObserver:
dealloc
dictationIsEnabled
dictationIsAvailableForLanguage:synchronous:
_isAvailableForForcedOfflineRecognition
forcedOfflineDictationIsAvailableForLanguage:
requestOfflineDictationSupportForLanguage:completion:
getForcedOfflineDictationSupportedLanguagesWithCompletion:
raise:format:
_informDelegateOfAvailabilityChange
speechRecognizer:availabilityDidChange:
isAvailable
initialize
supportedLocales
authorizationStatus
requestAuthorization:
_fetchSupportedForcedOfflineLocalesWithCompletion:
supportsOnDeviceRecognition
_requestOfflineDictationSupportWithCompletion:
_isInternalTaskHint:
recognitionTaskWithRequest:resultHandler:
recognitionTaskWithRequest:delegate:
setQueue:
locale
setSupportsOnDeviceRecognition:
delegate
defaultTaskHint
setDefaultTaskHint:
queue
_facetimeObserver
_foregroundObserver
_preferencesObserver
_supportsOnDeviceRecognition
_locale
_defaultTaskHint
_queue
encodeInteger:forKey:
decodeIntegerForKey:
decodeObjectForKey:
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
voiceAnalytics
_confidence
_substring
_timestamp
_duration
_alternativeSubstrings
_voiceAnalytics
_alternativeConfidences
_phoneSequence
_ipaPhoneSequence
_substringRange
searchTypes
setSearchTypes:
headerFields
setHeaderFields:
queryParameters
setQueryParameters:
_searchTypes
_headerFields
_queryParameters
setDetectMultipleUtterances:
_setForceOfflineRecognition:
_forceOfflineRecognition
mainBundle
bundleIdentifier
setApplicationName:
infoDictionary
setApplicationVersion:
setInlineItemList:
setRequestIdentifier:
setVoiceTriggerEventInfo:
setMaximumRecognitionDuration:
setDetectUtterances:
setVoiceSearchTypeOptions:
setVoiceSearchQueryParameters:
setVoiceSearchHeaderFields:
setKeyboardType:
setTaskHint:
setInteractionIdentifier:
setForceOfflineRecognition:
setRecognitionOverrides:
setModelOverrideURL:
initWithActivationEvent:
automaticallyEndpoint
setUseAutomaticEndpointing:
setUseStreamingDictation:
processInfo
systemUptime
setActivationEventTime:
_setSearchRequests:
_searchRequests
_powerMeteringAvailable
setRequiresOnDeviceRecognition:
requiresOnDeviceRecognition
_dictationOptionsWithTaskHint:requestIdentifier:
_speechRequestOptions
_maximumRecognitionDuration
_setMaximumRecognitionDuration:
_setSearchRequest:
_voiceTriggerEventInfo
_setVoiceTriggerEventInfo:
_recognitionOverrides
_setRecognitionOverrides:
_modelOverrideURL
_setModelOverrideURL:
setShouldReportPartialResults:
contextualStrings
setContextualStrings:
interactionIdentifier
detectMultipleUtterances
_shouldReportPartialResults
_detectMultipleUtterances
_contextualStrings
_interactionIdentifier
setFieldLabel:
assetWithURL:
caseInsensitiveCompare:
setKeyboardIdentifier:
setOriginalAudioFileURL:
tracksWithMediaType:
formatDescriptions
startRecordedAudioDictationWithOptions:forLanguage:narrowband:
assetReaderWithAsset:error:
numberWithUnsignedInteger:
assetReaderAudioMixOutputWithAudioTracks:audioSettings:
canAddOutput:
addOutput:
startReading
copyNextSampleBuffer
initWithURL:
_URL
initWithStreamDescription:
startRecordedAudioDictationWithOptions:forLanguage:
_appendAudioPCMBuffer:
_appendAudioSampleBuffer:
_endAudio
nativeAudioFormat
format
_drainAndClearAudioConverter
int16ChannelData
frameLength
dataWithBytes:length:
_convertAndFeedPCMBuffer:
initWithPCMFormat:frameCapacity:
setFrameLength:
convertToBuffer:error:withInputFromBlock:
inputFormat
initFromFormat:toFormat:
setSampleRateConverterQuality:
mutableAudioBufferList
appendAudioPCMBuffer:
appendAudioSampleBuffer:
endAudio
_bufferDelegate
_queuedBuffers
_converter
_audioEnded
initWithLength:
mutableBytes
speakingRate
averagePauseDuration
_formattedString
_segments
_speakingRate
_averagePauseDuration
B16@0:8
@24@0:8^{_NSZone=}16
v24@0:8@16
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@32@0:8@16d24
@16@0:8
d16@0:8
v16@0:8
@"NSArray"
@48@0:8@16@24@32@40
@"SFAcousticFeature"
q16@0:8
@"NSHTTPURLResponse"
@"NSData"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v32@0:8@16@24
v40@0:8@16@24@32
v44@0:8@16@24@32B40
v48@0:8@16@24@32@40
v56@0:8@16@24@32@40Q48
v32@0:8@16d24
v48@0:8@16@24@32B40B44
v24@0:8@"AFDictationConnection"16
v32@0:8@"AFDictationConnection"16@"AFDictationOptions"24
v32@0:8@"AFDictationConnection"16@"NSString"24
v32@0:8@"AFDictationConnection"16@"NSError"24
v40@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32
v44@0:8@"AFDictationConnection"16@"NSString"24@"NSDictionary"32B40
v32@0:8@"AFDictationConnection"16@"SASMultilingualSpeechRecognized"24
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40
v56@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32@40Q48
v40@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32
v32@0:8@"AFDictationConnection"16@"SASSpeechPartialResult"24
v32@0:8@"AFDictationConnection"16d24
v40@0:8@"AFDictationConnection"16@"NSFileHandle"24@"NSError"32
v48@0:8@"AFDictationConnection"16@"NSArray"24@"NSString"32B40B44
v32@0:8@"AFDictationConnection"16@"AFSpeechPackage"24
v24@0:8@"NSData"16
@48@0:8@16@24@32q40
f16@0:8
@"AFDictationConnection"
@"NSOperationQueue"
@"NSString"
@"SFSpeechRecognitionRequest"
@"NSObject<OS_dispatch_queue>"
@"NSError"
@56@0:8@16@24@32q40@?48
@56@0:8@16@24@32q40@48
v20@0:8B16
@"<_SFSpeechRecognitionTaskDelegatePrivate>"
@"SFSpeechRecognitionResult"
@"_SFSpeechRecognitionDelegateTask"
@28@0:8@16B24
@36@0:8@16@24B32
@"SFTranscription"
v24@0:8@?16
B24@0:8q16
@32@0:8@16@?24
@32@0:8@16@24
v24@0:8q16
@"<NSObject>"
@"NSLocale"
@"<SFSpeechRecognizerDelegate>"
@100@0:8@16{_NSRange=QQ}24d40d48f56@60@68@76@84@92
{_NSRange=QQ}16@0:8
@"SFVoiceAnalytics"
{_NSRange="location"Q"length"Q}
@"NSDictionary"
@48@0:8@16@24q32@40
@32@0:8q16@24
v24@0:8d16
@"_SFSearchRequest"
@"NSURL"
v24@0:8^{opaqueCMSampleBuffer=}16
@"<SFSpeechRecognitionBufferDelegate>"
@"NSMutableArray"
@"AVAudioConverter"
@48@0:8@16@24d32d40
mcpl
