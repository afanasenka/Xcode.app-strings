N2ma19CameraMotionSegmentE
>N2ma19SubtleMotionSegmentE
B`e>;
fff>
D@16MAComputeRequest
Bffffff
$CV&
C2wACA
?22MAImageAnalysisRequest
NSt3__120__shared_ptr_emplaceI25VCPImageHumanPoseAnalyzerNS_9allocatorIS1_EEEE
N2ma17DescriptorSegmentE
16VCPProtoKeypoint
B>fff?
G!?=
Ga>R
=q=J
ff&?R
Q8?H
?N4dlib7array2dIhNS_33memory_manager_stateless_kernel_1IcEEEE
N4dlib10enumerableIhEE
N4dlib33memory_manager_stateless_kernel_1IhEE
14VCPProtoBounds
N2ma11EncodeStatsE
N2ma15EncodeStatsAVE1E
N2ma15EncodeStatsAVE2E
N2ma13EncodeStatsHWE
N2ma13EncodeStatsSWE
333?fff?ff
N2ma24FineSubjectMotionSegmentE
NSt3__120__shared_ptr_emplaceI21VCPCNNEspressoContextNS_9allocatorIS1_EEEE
]@lwh
333?
G20MAImageComputeResult
333333
?333?
>N2ma22InterestingnessSegmentE
?333333
fff?
@oDA
43s?433?
333?43s?
@333?
N2ma19MovingObjectSegmentE
333333
N2ma18ObstructionSegmentE
?N2ma14QualitySegmentE
N2ma15RotationSegmentE
`@N2ma12SceneSegmentE
N2ma7SegmentE
N2ma17SlowMotionSegmentE
?N2ma20SubjectMotionSegmentE
>N2ma12TrackSegmentE
33s?
22MAMovieAnalysisRequest
28VCPProtoImageHumanPoseResult
=AB/'
R[DmPJ>
@Z_g@
#=H!
@333?
u?ff&?
>fff
?333?
mcpl)
Q9RI
Q9RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
k;KY
Q:RI
Q9RI
k:RI
DX;$
d*<4
?F<4
DX;4
Q:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
j<<b
ew=I
{r<b
j<<>
ew<M
ew<>
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
{r<M
7x=J{
/>:#
O/<N
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
|P>-
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
=R' =
d=&S
:p>7
R&?t
@=R' =
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
=R' =
d=&S
:p>7
R&?t
@=R' =
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
|P>-
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
{r<M
7x=J{
/>:#
O/<N
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
j<<>
ew<M
ew<>
j<<b
ew=I
{r<b
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
DX;$
d*<4
?F<4
DX;4
Q:RI
Q9RI
k:RI
Q9RI
k;KY
Q:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
7:RI
Q9RI
q=J?\
~|zxvuusqpnmkjiggfecba`_^]]\[ZYXWVUTTSRQQPONNMMLKKJIIHGGGFFEDDCCBBBAA@@??>>===<<;;:::999888776666555444333322211110000////.....----,,,,+++++*****)))))((((('''''''&&&&&&%%%%%%$$$$$$$########""""""!!!!!!!!!        X|E
+>>%I
????????????????
""""""""""""""""
                
            
~~~~~~~~~~~~~~~~
Bffffff
@333333
P@q=
?St12length_error
St11logic_error
St9exception
St12out_of_range
 !"#$%&''()*+,-./01223456789:;<<=>?@ABCDDEFGHIJKKLMNOPQQRSTUVWWXYZ[\]]^_`abbcdefghhijkllmnopqqrstuuvwxyzz{|}~~
NSt3__112future_errorE
#,6A
)6FX
$/AXs
!)6G
!)6G[
81*#
92+$
:3,%
;4-&
<5.'=6/>7?
%EEe
&&&FFFffffffffffffffff
IYizEUdtBP_n>LZh;HVc8EQ^5AMY3>IU0;EP.8BL+5?H)2;E'08A%-6>#+3;!)08 '.5
!"! ""##! ""3344! 32445565  443322221111321055446666GGGGXXXXiiiizzzz
21DCVUhgzy
3210FE44HHGGZZYYllkkmmmmnnnn6321D@77HHEEZZYY\\\\kkkkmmmm6541CB88IIGGZZPP[[[[\\\\6543A@77HHBBJJJJYYYY[[[[543277669999HHHHQQQQ````jjjj32%%66448888GGGGQQQQ````iiii%$6377AARR``hh$#&&55BBWW``aa$#%%22FFPPQQ
3522AA@@
"4A@
%&4-'$ 
!(,.5:3/)"
#*06;<71+28=>9?
")081*#
$+29:3,%
&-4;<5.'/6=>7?
  !""##$$%%%&&&''''
 ()*234
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
  00  00
  00@@00@@
  00@@00@@
@@ 0@@PP``PP``
 00@@00@@
 0@@PP@@PP
 0@@PP@@PP
@P 0@P``pp``pp
  00@@00@@
00@@PP@@PP
00@@PP@@PP
@@ 0PP``pp``pp
0@PP``PP``
@P``pp``pp
@P``pp``pp
@P 0`p
 0@@ 0@@
  0@PP0@PP
  0@PP0@PP
@@ 0@@P`ppP`pp
 0@PP0@PP
 0@P``@P``
 0@P``@P``
@P 0@P`p
  0@PP0@PP
00@P``@P``
00@P``@P``
@@ 0PP`p
0@P`ppP`pp
@P`p
@P`p
@P 0`p
  @@00@@
  00PP@@PP
  00PP@@PP
@@ 0@@PPpp``pp
 00PP@@PP
 0@@``PP``
 0@@``PP``
@P 0@P``
  00PP@@PP
00@@``PP``
00@@``PP``
@@ 0PP``
0@PPpp``pp
@P``
@P``
@P 0`p
 0``@P``
  0@ppP`pp
  0@ppP`pp
@@ 0@@P`
 0@ppP`pp
 0@P
 0@P
@P 0@P`p
  0@ppP`pp
00@P
00@P
@@ 0PP`p
0@P`
@P`p
@P`p

@P 0`p
  0@  0@
  00@P00@P
  00@P00@P
@@ 0@@PP`pPP`p
 00@P00@P
 0@@P`@@P`
 0@@P`@@P`
@P 0@P``p
  00@P00@P
00@@P`@@P`
00@@P`@@P`
@@ 0PP``p
0@PP`pPP`p
@P``p
@P``p
@P 0`p
 0@P 0@P
  0@P`0@P`
  0@P`0@P`
@@ 0@@P`p
 0@P`0@P`
 0@P`p@P`p
 0@P`p@P`p
@P 0@P`p
  0@P`0@P`
00@P`p@P`p
00@P`p@P`p
@@ 0PP`p
0@P`p
@P`p
@P`p
@P 0`p
  @P00@P
  00P`@@P`
  00P`@@P`
@@ 0@@PPp
 00P`@@P`
 0@@`pPP`p
 0@@`pPP`p
@P 0@P``
  00P`@@P`
00@@`pPP`p
00@@`pPP`p
@@ 0PP``
0@PPp
@P``
@P``
@P 0`p
 0`p@P`p
  0@p
  0@p
@@ 0@@P`
 0@p
 0@P
 0@P
@P 0@P`p
  0@p
00@P
00@P
@@ 0PP`p
0@P`
@P`p
@P`p
@P 0`p
  00  @@
  00@@00PP
  00@@00PP
@@ 0@@PP``PPpp
 00@@00PP
 0@@PP@@``
 0@@PP@@``
@P 0@P``pp``
  00@@00PP
00@@PP@@``
00@@PP@@``
@@ 0PP``pp``
0@PP``PPpp
@P``pp``
@P``pp``
@P 0`p
 0@@ 0PP
  0@PP0@``
  0@PP0@``
@@ 0@@P`ppP`
 0@PP0@``
 0@P``@Ppp
 0@P``@Ppp
@P 0@P`p
  0@PP0@``
00@P``@Ppp
00@P``@Ppp
@@ 0PP`p
0@P`ppP`
@P`p
@P`p
@P 0`p
  @@00PP
  00PP@@``
  00PP@@``
@@ 0@@PPpp``
 00PP@@``
 0@@``PPpp
 0@@``PPpp
@P 0@P``
  00PP@@``
00@@``PPpp
00@@``PPpp
@@ 0PP``
0@PPpp``
@P``
@P``
@P 0`p
 0``@Ppp
  0@ppP`
  0@ppP`
@@ 0@@P`
 0@ppP`
 0@P
 0@P
@P 0@P`p
  0@ppP`
00@P
00@P
@@ 0PP`p
0@P`
@P`p
@P`p
@P 0`p
  0@  P`
  00@P00`p
  00@P00`p
@@ 0@@PP`pPP
 00@P00`p
 0@@P`@@p
 0@@P`@@p
@P 0@P``p
  00@P00`p
00@@P`@@p
00@@P`@@p
@@ 0PP``p
0@PP`pPP
@P``p
@P``p
@P 0`p
 0@P 0`p
  0@P`0@p
  0@P`0@p
@@ 0@@P`p
 0@P`0@p
 0@P`p@P
 0@P`p@P
@P 0@P`p
  0@P`0@p
00@P`p@P
00@P`p@P
@@ 0PP`p
0@P`p
@P`p
@P`p
@P 0`p
  @P00`p
  00P`@@p
  00P`@@p
@@ 0@@PPp
 00P`@@p
 0@@`pPP
 0@@`pPP
@P 0@P``
  00P`@@p
00@@`pPP
00@@`pPP
@@ 0PP``
0@PPp
@P``
@P``
@P 0`p
 0`p@P
  0@p
  0@p
@@ 0@@P`
 0@p
 0@P
 0@P
@P 0@P`p
  0@p
00@P
00@P
@@ 0PP`p
0@P`
@P`p
@P`p
@P 0`p
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
3c:Xy,
PgbTG
L6}%Dhx
B*GDQj
sgwS
~NL]q2
2 Uz
~s$R
Fq0rhA
{7gra
_xc|MiL(b
Hm_P
H.Xa
f%y}=
P4^;m
avpy
`tPsd!
3}a^t
pY9<
b7cIl
CIsf
O]+f
hoDd
RBzS
C{-x
mO\mG
zyg9
`dTK_
e;\Y
h:zg
qq|]
QZ{8r^
Wet4
az,_
n_rj\muY
auFjm
1t(#
vu!}e
nV(
pY{I
b3-H
PWx_
?;Du
z8#2pj?
oh@k
i-C{
YiYu
vut.V
Q|Ko
;_C5m`
vS7b
;_3wN;
b{9Y
c{n{Mz!
x6BC`
|t~X
yEI#
IS>\D
>`B.
r+a{
-|QZ
Iux%uJ
4y~;
1mM+
pD-a
.w6P
dQRmd
Mze>
hz{]
x-Ee
_HybT
ww5_
b}GYn
v{}/Na
eI?h.de
MQ&Np
vOUjJnY
.z@v
i:_W
zvb|
ykGoqUn
W|vK9kn
T[FZ
"=ep
+=&qh?
}Z5"R
Vlq]
]-^]v
KsKT=b
'R[#
cUYh
Vqi0
SD6m`
r;NF
bN`o+E
Xt\Cg
e7nq
x0k5
|6q=
y2]6
ogc}m^
p|1~
 $(-28?GPZeq
,"!6
%*a
7"*>
IYizIYizEUdtEUdtBP_nBP_n>LZh>LZh;HVc;HVc8EQ^8EQ^5AMY5AMY3>IU3>IU0;EP0;EP.8BL.8BL+5?H+5?H)2;E)2;E'08A'08A%-6>%-6>#+3;#+3;!)08!)08 '.5 '.5
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}|}~
 ! !$%$%&'&'*+*+,-,-./0101234545676789:;:;<=<=<=>?@A@ABCBCBCDEDEFGFGFGHIHIHIJKJKJKLMLM~
000
:.oK4w
!4@[G
)DKxo
[b=R
#kp@
9`p^em
/1Pz
CVJL>
)r9*
hs;^^-
+Ouh
KV*x
_Y[I
|d:)1
RdO';B
,b\9
^+*S
z,RT\y
XHqrIvj
4s"eFZT
'-74}y8(
'rf&
\VeK
    
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
cnn_human_pose.espresso.net
res_256x256
res_192x192
VCPHumanPoseEspresso
@"VCPCNNModelEspresso"8@?0
res_320x192
res_192x320
trackingMode
TB,V_trackingMode
%@ %@
timestamp
qualityScoreForLivePhoto
visualPleasingScore
overallFaceQualityScore
exposureScore
penaltyScore
textureScore
sharpness
faceResults
globalQualityScore
contentScore
Td,N,V_timestamp
Tf,N,V_qualityScoreForLivePhoto
Tf,N,V_visualPleasingScore
Tf,N,V_overallFaceQualityScore
Tf,N,V_exposureScore
Tf,N,V_penaltyScore
Tf,N,V_textureScore
Tf,N,V_sharpness
T@"NSMutableArray",&,N,V_faceResults
hasGlobalQualityScore
TB,N
Tf,N,V_globalQualityScore
hasContentScore
Tf,N,V_contentScore
minX
Tf,V_minX
maxX
Tf,V_maxX
minY
Tf,V_minY
maxY
Tf,V_maxY
Tf,V_flag
GlobalXSum
GlobalYSum
Type
inputSize
T@"NSMutableArray",W,V_inputSize
outputSize
T@"NSMutableArray",&,V_outputSize
input
T@"VCPCNNData",W,V_input
output
T@"VCPCNNData",&,V_output
T@"VCPCNNMetalContext",R,V_context
generateOutput
TB,V_generateOutput
sdof
TB,V_sdof
VCPCNNBlurAnalyzerEspresso.sharedModelPool-%lu
cnn_blurV2.espresso.net
cnn_blur.espresso.net
@"VCPObjectPool"8@?0
VCPBlurEspresso
res_299x299
res_400x400
res_400x300
res_300x400
cnn_blur.dat
size
T@"NSMutableArray",&,V_size
data
T^f,V_data
isInputOutput
TB,V_isInputOutput
context
T@"VCPCNNMetalContext",W,V_context
v8@?0
espressoContext
T^v,R,N,V_espressoContext
Action
ActionScore
cnn_lm.dat
cnn_blink.espresso.net
VCPGazeEspresso
ImageAnalysis
MovieAnalysis
MAComputeRequestClass
device
T@"<MTLDevice>",&,V_device
commandQueue
T@"<MTLCommandQueue>",&,V_commandQueue
commandBuffer
T@"<MTLCommandBuffer>",&,V_commandBuffer
B8@?0
Error: failed to processSampleBuffer
T@"VCPCNNData",R,V_output
float32StorageType
forceCPU
sharedContext
inputBlobs
T{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t> >=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t> >=^{?}}},N,V_inputBlobs
outputBlobs
T{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t> >=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t> >=^{?}}},N,V_outputBlobs
inputBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_inputBlob
outputBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_outputBlob
resConfig
T@"NSString",R,N,V_resConfig
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
rawTime
stabCropRect
homography
Width
sourceSize
inputBounds
timeRange
confidence
T@"VCPProtoTimeRange",&,N,V_timeRange
Tf,N,V_confidence
cnn_pets.espresso.net
VCPPetsEspresso
res_0
res_1
res_2
Failed to load asset
Asset contains no video tracks
Failed to create video track output
Failed to start decoding video track
Video processor cancelled
Failed to complete video decoding
progressHandler
T@?,C,V_progressHandler
favorite
hidden
anonymizedName
verifiedType
isVerified
manualOrder
Tq,N
keyFace
T@"<PVFaceProtocol>",&,N
TB,D,N
com.apple.mediaanalysis.VCPVideoProcessorSession
Video processing requests must have completion handler
Specified request already active; cannot add
Failed to create request with specified configuration
Specified request not found; cannot remove
Sample buffer does not contain video frame
Sample buffer must contain uncompressed video
orientation
TI,N,V_orientation
T@"VCPProtoBounds",&,N,V_faceBounds
cnn_pose.dat
cnn_smile.dat
asset
T@"PHAsset",R,N,V_asset
analysis
T@"NSDictionary",R,N,V_analysis
com.apple.mediaanalysis.sql
SELECT id, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
, statsFlags
 FROM Assets WHERE localIdentifier=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?
) AND resultsType IN (?
SELECT id, localIdentifier, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
 FROM Assets WHERE localIdentifier IN (?
SELECT assetId, resultsType, results FROM Results WHERE assetId IN (?
SELECT date FROM Blacklist WHERE localIdentifier=(?) AND count>=(?);
i8@?0
SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM Blacklist WHERE count>=(?);
SELECT localIdentifier FROM Assets WHERE dateAnalyzed>=(?) UNION SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND date>=(?);
SELECT localIdentifier, status, attempts, (date + (%lu << (3*min(attempts - 1, 5)))) FROM ProcessingStatus WHERE taskID=(?) AND status!=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
SELECT COUNT(*) FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
flags
TQ,V_flags
bounds
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
Tf,V_confidence
DeviceClass
AudioAccessory
mediaanalysis://asset.mov
analysisConfidence
gyroStabilization
Tf,N,V_analysisConfidence
TB,N,V_gyroStabilization
absoluteScore
relativeScore
humanScore
Tf,N,V_absoluteScore
Tf,N,V_relativeScore
Tf,N,V_humanScore
AveStats
Failed to parse AVE statistics frame attachment; re-generating statistics
iChatUsageString
EnableStatsCollect
EnableUserQPForFacetime
EnableUserRefForFacetime
EnableWeightedPrediction
UserFrameType
ReferenceFrameNumDriver
ReferenceL0
UserQpMap
MBStatistics
NotSync
com.apple.mediaanalysisd.timer
Orientation
Regions
leftEyeClosed
TB,V_leftEyeClosed
rightEyeClosed
TB,V_rightEyeClosed
smile
TB,V_smile
Tq,V_yaw
trackID
Ti,V_trackID
faceQuality
Tf,V_faceQuality
observation
T@"VNFaceObservation",&,V_observation
start
T{?=qiIq},V_start
last
T{?=qiIq},V_last
position
TQ,V_position
faceID
TQ,V_faceID
elapsedTimeSeconds
Td,R,V_elapsedTimeSeconds
started
TB,R,V_started
StartDate
EndDate
TimeZone
AllDay
Title
Location
Notes
<VCPEvent: %p
%-9@  %@
supportsSecureCoding
TB,R
startDate
T@"NSDate",&,N,V_startDate
endDate
T@"NSDate",&,N,V_endDate
timeZone
T@"NSTimeZone",&,N,V_timeZone
allDay
TB,N,V_allDay
title
T@"NSString",&,N,V_title
location
T@"NSString",&,N,V_location
T@"NSURL",&,N,V_url
notes
T@"NSString",&,N,V_notes
Address
EmailAddress
Event
FlightInfo
Link
PhoneNumber
TrackingInfo
Transcript
Home face identification task cancelled
No face present in face crop
Photos identity model not present
mediaanalysisd
asset in (%@)
any person.personUUID in %@
total-allowed
PVPersonClusterManager
%@ | %@
master
T@"NSString",R,V_master
adjusted
T@"NSString",R,V_adjusted
Requested unavailable frame %d
com.apple.mediaanalysis.FaceProcessingGroup
@"VNSession"8@?0
Error: no faceObservation
Error: unable to determine normalized face bounding box { { %f, %f } { %f, %f } }
@"VNRequest"16@?0#8
@"VNObservation"24@?0@"NSUUID"8@"VNRequest"16
Unable to serialize faceprint
personLocalIdentifier is empty
(verifiedType = %d) OR (verifiedType = %d)
personLocalIdentifier
B24@?0@"NSString"8@"NSDictionary"16
PVFace
Unable to find class %s
/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
/System/Library/PrivateFrameworks/PhotoVision.framework/Contents/MacOS/PhotoVision
PVGeometryUtils
PVFaceprint
textureness
hasFlash
stillTime
Tf,N,V_textureness
TB,N,V_hasFlash
Tf,N,V_stillTime
sceneprintBlob
T@"NSData",&,N,V_sceneprintBlob
mammal
bird
people
adult
animal
stuffed_animals
fire
fireplace
embers
flame
beach
liquid
ocean
lake
creek
river
snow
jacuzzi
pool
grass
plant
coral_reef
foliage
tree
grill
waterways
shore
waterfall
thunderstorm
manhole
aurora
light
spotlight
smoking_item
flag
flagpole
underwater
candle
kettle
teapot
storm
tornado
lightning
blossom
surfing
pyrotechnics
blizzard
fountain
billboards
curtain
lamp
drinking_glass
fondue
blender
storefront
garden
shrub
firecracker
bubble_soap
watersport
haze
volcano
aquarium
fishtank
flower
seaweed
jellyfish
fish
flashlight
bonfire
smoking
lakeshore
sparkler
sparkling_wine
shower
geyser
qualityScore
Tf,V_qualityScore
actionScore
Tf,V_actionScore
interestingnessScore
Tf,V_interestingnessScore
obstructionScore
Tf,V_obstructionScore
trackingScore
Tf,V_trackingScore
objectsMotion
T@"NSDictionary",R,N,V_objectsMotion
globalMotion
T@"NSArray",R,N,V_globalMotion
Point0
Point1
Radius
Theta
Length
q24@?0@"NSDictionary"8@"NSDictionary"16
cnn_human_pose_single.espresso.net
humanPoseResults
cnn_faceblur.dat
Tf,R,V_sharpness
Tf,R,V_textureScore
%@ canceled
%@ is not yet implemented
completionHandler
T@?,R,N,V_completionHandler
cancelBlock
T@?,C,N,V_cancelBlock
Tf,R,N,V_exposureScore
faceAdjustmentVersion != nil
additionalAttributes.sceneAnalysisVersion >= %d &&  additionalAttributes.sceneAnalysisVersion != %d
Video stabilization task cancelled
Video stabilization processing failed
faceQualityScores
T@"NSMutableArray",&,V_faceQualityScores
com.apple.mediaanalysisd.moviecurationresults
com.apple.mediaanalysisd.livephotokeyframeresults
com.apple.mediaanalysisd.das.dutycycle
com.apple.mediaanalysisd.das.dutycycle.task
com.apple.mediaanalysisd.analysis.pets
MediaType
AutoPlayableScore
SummaryDuration
IsTrimmed
KeyFrameIsSuggested
KeyFrameScoreDifference
KeyFrameTimestampOffset
KeyFrameIsFaceQualityDominant
KeyFrameIsSharpnessDominant
KeyFrameIsSemanticDominant
KeyFrameIsSuggestedEdit
KeyFrameScoreDifferenceEdit
KeyFrameTimestampOffsetEdit
KeyFrameIsFaceQualityDominantEdit
KeyFrameIsSharpnessDominantEdit
KeyFrameIsSemanticDominantEdit
previousQoS
previousQoSDuration
requestedQoS
taskName
DownloadAssetCount
DownloadBytes
Duration
Delay
AvgSpeed
AssetType
NumberOfPetFacesDetected
NumberOfPetsDetected
ResourceType
SceneType
AggregatedBoundingBoxSizeRatio
LargestBoundingBoxSizeRatio
Quick Face ID task cancelled
faceAdjustmentVersion = nil
Quick Face ID canceled with %lu job done
T{CGPoint=dd},N,V_location
keypoints
T@"NSArray",&,N,V_keypoints
relativeActionScore
Tf,N,V_relativeActionScore
absoluteActionScore
Tf,N,V_absoluteActionScore
personID
Ti,N,V_personID
revision
Ti,N,V_revision
handID
Ti,N,V_handID
com.apple.mediaanalysis.VCPImageManager.decodequeue
VCPImageManager
@"VCPImageManager"8@?0
v16@?0@"NSData"8
v16@?0@"NSError"8
v32@?0@8Q16^B24
%@ <%p>:
  person1LocalIdentifier  : %@
  person2LocalIdentifier  : %@
  reason                  : %@
person1LocalIdentifier
T@"NSString",R,V_person1LocalIdentifier
person2LocalIdentifier
T@"NSString",R,V_person2LocalIdentifier
reason
T@"NSString",R,V_reason
asset.dateCreated
asset.addedDate
asset.filename
centerX
centerY
(clusterSequenceNumber > 0)
(manual == 0) AND (faceAlgorithmVersion = %d)
localIdentifier
Could not access the library
Canceled operation to get CSNs of faces missing from the library
v40@?0@"NSArray"8{_NSRange=QQ}16^B32
v32@?0@"NSString"8@"PHFetchResult"16^B24
(clusterSequenceNumber in %@)
Canceled operation to ungroup faces
v16@?0^B8
Canceled operation to uncluster faces
(clusterSequenceNumber = 0)
((clusterSequenceNumber > 0) AND (faceGroup = nil))
could not access the library
Canceled operation to cleanup grouped faces with CSN=0
No faceGroups found for person with localIdentifier '%@'
Failed to fetch faces from the faceGroup that contributed the most number of face to person with localIdentifier '%@'
photoLibrary is nil
clusterSequenceNumber IN %@
@"PHFace"16@?0@"NSNumber"8
v24@?0@"NSNumber"8^B16
v32@?0@"NSString"8@"NSNumber"16^B24
Saving clustering results cancelled
Canceled operation to reset library clusters
-[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:]
person localIdentifiers
Failed to find persons with local identifiers: '%@'
B24@?0@"PHPerson"8@"NSDictionary"16
UpdateKeyFaces: Operation canceled
Unimplemented %s in VCPPhotosPersistenceDelecate
-[VCPPhotosPersistenceDelegate associateFace:withFaceCrop:error:]
-[VCPPhotosPersistenceDelegate clearDirtyStateOnFaceCrops:error:]
-[VCPPhotosPersistenceDelegate dirtyFaceCropsWithLimit:]
-[VCPPhotosPersistenceDelegate faceAssociatedWithFaceCrop:]
-[VCPPhotosPersistenceDelegate facesFromAsset:]
-[VCPPhotosPersistenceDelegate persistFaces:deleteFaces:forAsset:persistedFaces:error:]
-[VCPPhotosPersistenceDelegate persistGeneratedFaceCrops:error:]
-[VCPPhotosPersistenceDelegate recordNeedToPersonBuildOnFaceGroupContainingFace:error:]
-[VCPPhotosPersistenceDelegate suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:]
-[VCPPhotosPersistenceDelegate updateFaceprint:ofPersistedFace:error:]
(personBuilderState = %ld)
Canceled cleaning up merge candidates of verified persons
v24@?0@"PHFetchResult"8@"NSMutableSet"16
v24@?0@"VCPMergeCandidatePair"8^B16
Canceled cleaning up merge candidates
(trainingType = %d) || (trainingType = %d)
v32@?0@"PHPerson"8@"NSString"16^B24
B24@?0@"VCPMergeCandidatePair"8@"NSDictionary"16
(clusterSequenceNumber IN %@)
Person building cancelled
v32@?0@"NSNumber"8@"NSOrderedSet"16^B24
clusterSequenceNumber = %ld
clusterSequenceNumber != %ld
invalid merge candidate pair created from cluster rejections
potential invalid merge candidate pair created from cluster rejections
invalid merge candidate pair from cluster rejection for verified person
potential invalid merge candidate pair from cluster rejection for verified person
B16@?0^@8
no training faces in level1 cluster - create 'unverified person : verified/migrated person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : training person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : verified person' candidate pair
all training faces on single verified person in level1 cluster - create 'training person : verified person' candidate pair
invalid merge candidate pair because we may have a dirty level0 cluster
multiple training persons in level0 cluster - create 'training person : training person' pair
clusterSequenceNumber
single training person in level0 cluster - create 'training person : verified person with confirmed face' pair
single training person in level0 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
invalid merge candidate pair because one person has face rejected for the other
invalid merge candidate pair because we have > 3 verified persons in the face group
single training person in level1 cluster - create 'training person : verified person with confirmed face' pair
single training person in level1 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
level1 cluster - create 'training person : training person' pair
level1 cluster - create 'unverifed person : training person' pair
invalid merge candidate pair because we have a cluster rejection
v32@?0@"NSMutableSet"8@"NSMapTable"16@"NSSet"24
invalid merge candidate pair because we have a face on verified person but cluster-rejected on another verified person
-[VCPPhotosPersistenceDelegate buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:]
faceLocalIdentifier is nil
fetched %lu faces for %@
clusterSequenceNumber is nil
personLocalIdentifier is nil
fetched %lu persons for %@
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
(manual = 0) AND ((nameSource = %d) OR (nameSource = %d) OR (nameSource = %d)) AND ((trainingType = %d) OR (trainingType = nil))
Operation to remove faces from verified persons has been canceled
Failed to removed faces from person with localIdentifiers '%@'
faceAlgorithmUmbrellaVersion
TI,N
sceneAlgorithmUmbrellaVersion
personBuilderMergeCandidatesDisabled
TB,N,V_personBuilderMergeCandidatesDisabled
updateBlock
T@?,C,N,V_updateBlock
TI,N,V_faceAlgorithmUmbrellaVersion
TI,N,V_sceneAlgorithmUmbrellaVersion
PVUtils
PVVisionHelper
not known
PVCanceler
PGGraphHelper
/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
/System/Library/PrivateFrameworks/PhotosGraph.framework/Contents/MacOS/PhotosGraph
cnn_person_detector.espresso.net
Tf,R,V_qualityScore
salientRegion
salientScore
cnn_saliency.dat
com.apple.mediaanalysis.SceneProcessingGroup
v16@?0Q8
PVSceneTaxonomy
{{%.*g, %.*g}, {%.*g, %.*g}}
Email
Time
DateTime
DateDuration
TimeDuration
FlightInformation
TrackingNumber
http://trackingshipment.apple.com/?Company=%@&TrackingNumber=%@
v16@?0@"NSArray"8
Failed to create VNImageRequestHandler
v16@?0^{opaqueCMSampleBuffer=}8
Tf,R,V_actionScore
publicResults
T@"NSDictionary",R,N
privateResults
LogLevel
yyyy-MM-dd HH:mm:ss
logLevel
Ti,R,V_logLevel
output1
output2
output3
cnn_hand_detector.espresso.net
com.apple.mediaanalysis
com.apple.mediaanalysisd.analysis
com.apple.mediaanalysisd.photos
com.apple.mediaanalysisd.homekit
com.apple.mediaanalysisd.homekitsession
dateModified
dateAnalyzed
masterFingerprint
adjustedFingerprint
performedAnalysisTypes
metadataRanges
SyncPoint
FaceResults
ShotTypeResults
SceneResults
QualityResults
JunkResults
BlurResults
ExposureResults
FeatureVectorResults
CameraMotionResults
SubjectMotionResults
FineSubjectMotionResults
SubtleMotionResults
OrientationResults
DistanceResults
IrisRecommendResults
IrisSharpnessResults
PreEncodeResults
MovingObjectsResults
ObstructionResults
SaliencyResults
CompositionResults
ClassificationResults
InterestingnessResults
MusicResults
UtteranceResults
ActivityLevelResults
FacePrintResults
PetsResults
PetsFaceResults
MovieSummaryResults
MovieHighlightResults
KeyFrameResults
KeyFrameBlurResults
KeyFrameStillResults
TrackingResults
LivePhotoEffectsResults
SceneChangeResults
ApplauseResults
BabbleResults
CheeringResults
LaughterResults
HumanPoseResults
HumanActionResults
HumanPoseInternalResults
HandsResults
LoudnessResults
KeyFrameResourceResults
SceneprintResults
VideoStabilizationResults
SongResults
HumanActionClassificationResults
FaceQualityFlag
attributes
energyValues
peakValues
facePosition
facePoseYaw
faceId
facePrint
sharpnessFaces
saliencyBounds
saliencyConfidence
featureVector
songSignature
sceneprint
vanishingPointConfidence
distance
sceneprintDistance
neighbor
neighborDateModified
slowMoFlicker
stabilizationRecipe
Data
junk
petsBounds
petsConfidence
keyFrameTime
keyFrameScore
livePhotoEffectsRecipe
livePhotoEffectsGatingDescriptions
livePhotoEffectsMatchingScenes
aesthetic
sceneClassification
saliency
saliencyObjectness
overallScore
allScores
wellFramedSubjectScore
wellChosenBackgroundScore
tastefullyBlurredScore
sharplyFocusedSubjectScore
wellTimedShotScore
pleasantLightingScore
pleasantReflectionsScore
harmoniousColorScore
livelyColorScore
pleasantSymmetryScore
pleasantPatternScore
immersivenessScore
pleasantPerspectiveScore
pleasantPostProcessingScore
noiseScore
failureScore
pleasantCompositionScore
interestingSubjectScore
intrusiveObjectPresenceScore
pleasantCameraTiltScore
lowKeyLightingScore
acceptableCrop
preferredCrop
humanBounds
humanKeypoints
humanConfidence
humanID
handsBounds
handsKeypoints
handsKeypointsConfidents
handsID
frameQualityScore
faceQualityScore
texture
flashFired
QualityOfService
DutyCycling
VCPTaskIDs
GyroStabilization
PixelStabilization
MaxNumberOfAssetToProcess
ForceFullScan
Full Face, 
Face, 
Voice, 
Full Scene, 
Scene, 
Junk, 
Blur, 
Exposure, 
Distance, 
Feature, 
Saliency, 
Composition, 
Classification, 
ActivityLevel, 
CurationScore, 
Pets, 
MovieCuration, 
Effects, 
Audio Classification, 
Human pose, 
Loudness Measure, 
Hands, 
Video Stabilization Pixel, 
Video Stabilization Gyro, 
Gyro Analytics, 
Song detection, 
Video Interpolation, 
Human action, 
index
summaryTimerange
duplicate
SceneAnalysis
FaceAnalysis
hier_text_document
hier_tragic_failure
tragic_failure
screenshot
bad_framing
bad_lighting
blurry
food_or_drink
junk_other
medical_reference
negative
receipt_or_document
repair_reference
shopping_reference
utility_reference
junk_negative
hier_negative
junk_non_memorable
hier_non_memorable
junk_poor_quality
hier_poor_quality
No Resource
Soft Failure
Hard Failure
PhotoLibraries
ImageTooSmall
UsingBestResource
FacesToDelete
FacesToPersist
QuickFaceIdentification
processed
Confidence
BoundingBox
UserInteractive
UserInitiated
Default
Utility
Background
Unspecified
IrisObjectsResults
MetaFocusResults
MetaMotionResults
MetaMotionProcessedResults
MetaStabilizationResults
MetaStabilizationFrameResults
MetaHomographyDimensionResults
MetaHomographyResults
MetaPresentationTimeResults
MetaMotionBlurResults
MetaPTSResults
MetaOriginalPTSResults
MetaLensSwitchResults
summaryIsTrimmed
livePhoto
movie
@"NSMutableDictionary"8@?0
timeStamp
T{?=qiIq},R,N,V_timeStamp
score
Tf,R,N,V_score
timerange
T{?={?=qiIq}{?=qiIq}},R,N,V_timerange
keyFrame
T@"VCPVideoKeyFrameResult",R,N,V_keyFrame
phAsset
T@"PHAsset",R,N,V_phAsset
highlights
T@"NSMutableArray",R,&,N,V_highlights
T{?={?=qiIq}{?=qiIq}},N,V_timerange
Tf,N,V_score
junkScore
Tf,N,V_junkScore
Tf,N,V_qualityScore
expressionScore
Tf,N,V_expressionScore
Tf,N,V_actionScore
voiceScore
Tf,N,V_voiceScore
humanActionScore
Tf,N,V_humanActionScore
humanPoseScore
Tf,N,V_humanPoseScore
bestPlaybackCrop
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bestPlaybackCrop
isAutoPlayable
TB,N,V_isAutoPlayable
isTrimmed
TB,N,V_isTrimmed
descriptor
T@"VCPImageDescriptor",&,N,V_descriptor
T@"VCPVideoKeyFrame",&,N,V_keyFrame
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
v32@?0@"VCPMovieHighlight"8Q16^B24
com.apple.mediaanalysisd.realtime
ContentType
faceMetadataArray
realtimeFaceRect
realtimeFaceRoll
realtimeFaceYaw
InProcess
com.apple.mediaanalysis.service.management
com.apple.mediaanalysis.service.handler
MediaAnalysisService
Error issuing sandbox extension
v16@?0d8
[MediaAnalysis] Error connecting to background analysis service
Assets from multiple libraries not supported
v24@?0@"NSString"8@"NSError"16
PersonProcessingDeletePersons
faceCSN
faceIdentifier
personIdentifier
personFaceCount
status
requestAdvancedStatus
advancedStatus
PLPhotoAnalysisVisionServiceFaceReclusteringThreshold
PLPhotoAnalysisVisionServiceFaceReclusteringShouldRecluster
v24@?0@"NSArray"8@"NSError"16
v20@?0B8@"NSError"12
AllowOnDemand
AllowOnDemandPixel
AllowOnDemandGyro
AllowStreaming
KeepPrivateResults
MaxHighlightDuration
Standalone
StoreAnalysis
com.apple.mediaanalysis.ondemand
com.apple.mediaanalysis.storage
com.apple.mediaanalysis.VCPMediaAnalyzer.sandboxQueue
VCPMediaAnalyzer
v16@?0@"NSString"8
creationDate
T{?={?=qiIq}{?=qiIq}},R,N,V_timeRange
numOfFrames
TQ,R,N,V_numOfFrames
frame idx = %d
size = %d, track_target_exist = %d, target_lost = %d, tracking_score = %6.2f
before filter: frame(%d): time_stamp=%f, ave_motion=(%f,%f)
frame(%d): time_stamp=%f, ave_motion=(%f,%f), acc_var=(%f, %f), motion_chg=(%f, %f)
faceprintData
T@"NSData",R,N
qualityMeasure
ageType
TS,R,N
Tq,D,N
enabled
formatDescriptions
naturalSize
nominalFrameRate
preferredTransform
tracks
allowStreaming
TB,N,V_allowStreaming
maxHighlightDuration
Tf,N,V_maxHighlightDuration
faceDominated
TB,N,V_faceDominated
Tq,R,V_status
T@"VCPProtoBounds",&,N,V_bounds
Ti,N,V_flags
fetchedObjects
B16@?0@"PHAssetResource"8
com.apple.VideoProcessing
com.apple.mediaanalysisd
kind == %d
mediaType == %d
kind == %d && kindsubtype != %d
mediaType == %d && !((mediaSubtype & %d) == %d)
kindsubtype == %d
(mediaSubtype & %d) == %d
UserOrig
UserAlgo
NoUserAlgo
NoAlgo
variation = %6.2f
sum = %6.2f, tracking_score = %6.2f
Target Captured @ [%5.0f, %5.0f, %5.0f, %5.0f]
initial @ [%d %d] s = %6.5f
stop    @ [%d %d] s = %6.5f
lost = %d
[%6.2f, %6.2f, %6.2f, %6.2f]
box0: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box1: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box : (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
overlap_area = %6.2f, max_area = %6.2f, weight = %6.2f
derr = %6.2f, terr = %6.2f
add new expert with weight %6.2f
expert %d was replaced: voting weight(%6.2f --> %6.2f)!
after voting --> update target
detector and tracker did not match well --> experts vote
detector and tracker matched well --> update experts
v32@?0@"NSString"8@"NSString"16@"NSError"24
com.apple.mediaanalysis.quickfaceid.management
verifiedType = %@ OR verifiedType = %@
faceCount
uuid
roll == 0.0
isInVIPModel == YES
PVContext
PVFaceIDModel
PVImage
FaceIDModelLastGenerationKey
PhotoAnalysisServicePreferences.plist
faceWorkerState.plist
/var/mobile/Media/PhotoData
/var/mobile/Media/MediaAnalysis/mediaanalysis.db
MediaAnalysis
mediaanalysis.db
Angle
seg %d: [%d, %d], sceneCut=%d
prev(%d) [%d, %d][%6.1f, %6.1f] qs = %6.2f, curr(%d) [%d, %d] [%6.1f, %6.1f]qs = %6.2f:
dist({%d %d}, {%d %d}) = %6.2f, th = %6.2f
prev: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
curr: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
segments
===========SceneChangeSegments=============
[%f, %f]
com.apple.mediaanalysisd.generic
Failed to created sandbox extension for %@
CVPixelBuffer must be IOSurface-backed
v32@?0@"NSString"8Q16^B24
VCPVoiceover task cancelled
analyzeFace failed
analyzeScene failed
Start
subtleMotionScore
Tf,R,V_subtleMotionScore
Multiple cadence options specified
%@ value must be NSNumber
%@ value must be poisitive
%@ is not supported
v32@?0@"NSString"8@16^B24
request
T@"VNRequest",R,N,V_request
timeInterval
T{?=qiIq},R,N,V_timeInterval
frameInterval
TQ,R,N,V_frameInterval
Tracking
NumOfValidFrames
TrackingScore
Destructive Trim Range: [%.2f - %.2f]
after repare
after consecutive short merge
after sparse short merge
after post processing
=========Segment %s==========
v32@?0@"VCPSegment"8Q16^B24
 [%.2f - %.2f]: %.2f
--[%.2f - %.2f]
NotImplementedException
[VCPAsset %@] should not be called
mediaType
mediaSubtypes
pixelWidth
pixelHeight
Live Photo
Pano Photo
Screenshot
HDR Photo
SDOF Photo
Photo
Slow-mo Movie
Timelapse Movie
Movie
Unknown
Tq,R,N
TQ,R,N
modificationDate
T@"NSDate",R,N
fingerprint
T@"VCPFingerprint",R,N
isImage
TB,R,N
isMovie
T@"NSString",R,N
mainFileURL
T@"NSURL",R,N
scenes
exif
imageWithPreferredDimension:
isPano
isLivePhoto
isScreenshot
isHDR
isSDOF
hadFlash
exposureTimeSeconds
Tf,R,N
photoOffsetSeconds
originalPhotoOffsetSeconds
movie:
originalMovie:
isSlowmo
isTimelapse
duration
Td,R,N
slowmoRate
timelapseRate
quality
subjectMotionScore
sharpnessScore
sceneChangeScore
VoiceResults
browDown_L
browDown_R
browInnerUp
browOuterUp_L
browOuterUp_R
cheekPuff
cheekSquint_L
cheekSquint_R
eyeBlink_L
eyeBlink_R
eyeLookDown_L
eyeLookDown_R
eyeLookIn_L
eyeLookIn_R
eyeLookOut_L
eyeLookOut_R
eyeLookUp_L
eyeLookUp_R
eyeSquint_L
eyeSquint_R
eyeWide_L
eyeWide_R
jawForward
jawLeft
jawOpen
jawRight
mouthClose
mouthDimple_L
mouthDimple_R
mouthFrown_L
mouthFrown_R
mouthFunnel
mouthLeft
mouthLowerDown_L
mouthLowerDown_R
mouthPress_L
mouthPress_R
mouthPucker
mouthRight
mouthRollLower
mouthRollUpper
mouthShrugLower
mouthShrugUpper
mouthSmile_L
mouthSmile_R
mouthStretch_L
mouthStretch_R
mouthUpperUp_L
mouthUpperUp_R
noseSneer_L
noseSneer_R
focalLengthInPixels
faceBounds
objects
faceRollAngles
faceAnchor
vertices
transform
blendshapes
geometry
dispatchQueue
regionsOfInterest
aggSubjectMotionScore
turboMode
frameWidth
frameHeight
vertexCount
TQ,R,N,V_vertexCount
Tr^,R,N
T{?=[4]},R,N,V_transform
blendShapes
T@"NSDictionary",R,N,V_blendShapes
T@"VCPFaceGeometry",R,N,V_geometry
VCPCaptureAnalysis
v24@?0f8Q12i20
aggregatedResults
T@"NSDictionary",R
com.apple.mediaanalysis.VCPClientDatabaseManager
cnn_content.dat
@"NSDictionary"8@?0
v24@?0^v8Q16
cancel
T@?,C,N,V_cancel
votes
Tq,N,V_votes
count
Tq,N,V_count
v32@?0@"NSString"8@"VCPVoteStats"16^B24
[MediaAnalysis][%@]Unable to open movie, skip
[MediaAnalysis][%@]Failed to create asset
[%@] Analysis cancelled
[%@] Analysis failed to complete
<VCPFaceTimeFace: %p faceprint: %@>
faceprint
T@"VNFaceprint",&,N,V_faceprint
taskID
TQ,R,N,V_taskID
T@"NSString",R,N,V_localIdentifier
TQ,R,N,V_status
attempts
TQ,R,N,V_attempts
nextRetryDate
T@"NSDate",R,N,V_nextRetryDate
gesture_recognition.espresso.net
facePrintBlob
T@"VCPProtoTime",&,N,V_timestamp
facetime.sqlite
VCPFaceTimeDataModel
v24@?0@"NSPersistentStoreDescription"8@"NSError"16
Session
<VCPFaceTimeSession: %p sessionID: %@ callerID: %@ date: %@>
sessionID
T@"NSString",&,N,V_sessionID
callerID
T@"NSString",&,N,V_callerID
date
T@"NSDate",&,N,V_date
faces
T@"NSArray",R,N
v20@?0f8^B12
frameProcessedByVideoAnalyzer
TB,N,V_frameProcessedByVideoAnalyzer
cameraMotionScore
Tf,N,V_cameraMotionScore
subjectActionScore
Tf,N,V_subjectActionScore
Tf,N,V_interestingnessScore
Tf,N,V_obstructionScore
colorfulnessScore
Tf,N,V_colorfulnessScore
subMbMotionAvailable
TB,N,V_subMbMotionAvailable
frameExpressionScore
Tf,N,V_frameExpressionScore
faceArea
Tf,N,V_faceArea
frameProcessedByHumanAnalyzer
TB,N,V_frameProcessedByHumanAnalyzer
frameProcessedByFaceDetector
TB,N,V_frameProcessedByFaceDetector
detectedFaces
T@"NSMutableArray",&,N,V_detectedFaces
videoActivityDescriptor
T@"VCPVideoActivityDescriptor",&,N,V_videoActivityDescriptor
com.apple.homekitanalysis.service.management
com.apple.homekitanalysis.service.handler
Failed to fetch person by local identifier (%@)
HMIAnalysisService
/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
/System/Library/PrivateFrameworks/HomeAI.framework/Contents/MacOS/HomeAI
HMITaskService
mediaanalysis://in-memory
com.apple.mediaanalysisd.VCPInMemoryAVAsset
com.apple.mediaanalysis.reachability
Not c
hasWifiOrEthernetConnection
TB,R,N,V_hasWifiOrEthernetConnection
None
TransientConnection
Reachable
ConnectionRequired
ConnectionOnTraffic
InterventionRequired
ConnectionOnDemand
IsLocalAddress
IsDirect
IsWWAN
Frame: %u
canceled
TB,N,V_canceled
%@ (face=%@ image=%@)
User canceled
v32@?0@"VCPFaceCropSourceDescriptor"8Q16^B24
{ { %f, %f }, { %f, %f} } is not a normalized rect
Image cannot provide an URL or a data representation
faceCropSourceDescriptor.face is nil
faceCropSourceDescriptor.image is nil
failed to create PVFaceCrop
cannot generate a facecrop without an originating face
cannot find originating face %@
cannot generate facecrop on manual originating face %@
Error: No faceCrop
Error: facecrop does not have any image data
Error: facecrop image data is not valid
Error: facecrop data does not have crop bounds information
Error: facecrop image size equals to 0
Error: failed to calculate normalized facecrop bounding box
Error: unable to obtain the facecrop image dimensions
Error: unable to create VNImageRequestHandler
Error: unable to create a VNRequest to detect face rectangle
Error: unable to create a VNRequest to create faceTorsoprint
Error: failed to analyze facecrop: %@
Error: failed to create faceprint for facecrop: %@
Error: failed to create PVFace from face observation
Error: invalide faceprint/faceTorsoprint
Error: face %@ has already been persisted with a facecrop
Error: face %@ does not have a faceprint
Error: could not fetch facecrop: %@
Error: could not publish facecrop analysis %@
could not locate face %@
v40@?0@"VCPFaceCropSourceDescriptor"8Q16Q24@"NSError"32
PVFaceCropUtils
PVFaceCrop
Measurement
Min (s)
Max (s)
Avg (s)
Total
Count
signpost
q24@?0@"PHSceneClassification"8@"PHSceneClassification"16
resources
hand_keypoint_detector.espresso.net
version
types
statsFlags
typesWide
assetIdentifier
assetModificationDate
assetMasterFingerprint
assetAdjustedFingerprint
imageBlurResults
imageCompositionResults
imageFaceResults
imageFeatureResults
imageJunkResults
imageSaliencyResults
imageShotTypeResults
imagePetsResults
imagePetsFaceResults
imageSceneprintResults
livePhotoEffectsResults
livePhotoRecommendationResults
livePhotoSharpnessResults
livePhotoKeyFrameResults
livePhotoKeyFrameStillResults
movieActivityLevelResults
movieCameraMotionResults
movieClassificationResults
movieFaceResults
movieFaceprintResults
movieFeatureResults
movieFineSubjectMotionResults
movieInterestingnessResults
movieMovingObjectResults
movieMusicResults
movieObstructionResults
movieOrientationResults
moviePreEncodeResults
movieQualityResults
movieSaliencyResults
movieSceneResults
movieSceneprintResults
movieSubjectMotionResults
movieSubtleMotionResults
movieUtteranceResults
movieVoiceResults
movieSummaryResults
movieHighlightResults
imageExposureResults
imageHumanPoseResults
movieHumanPoseResults
movieApplauseResults
movieBabbleResults
movieCheeringResults
movieLaughterResults
movieHumanActionResults
movieLoudnessResults
moviePetsResults
moviePetsFaceResults
movieStabilizationResults
TI,N,V_version
TI,N,V_types
TI,N,V_flags
Td,N,V_date
hasQuality
Td,N,V_quality
hasStatsFlags
TQ,N,V_statsFlags
hasTypesWide
TQ,N,V_typesWide
T@"NSString",&,N,V_assetIdentifier
Td,N,V_assetModificationDate
T@"NSString",&,N,V_assetMasterFingerprint
hasAssetAdjustedFingerprint
T@"NSString",&,N,V_assetAdjustedFingerprint
T@"NSMutableArray",&,N,V_imageBlurResults
T@"NSMutableArray",&,N,V_imageCompositionResults
T@"NSMutableArray",&,N,V_imageFaceResults
T@"NSMutableArray",&,N,V_imageFeatureResults
T@"NSMutableArray",&,N,V_imageJunkResults
T@"NSMutableArray",&,N,V_imageSaliencyResults
T@"NSMutableArray",&,N,V_imageShotTypeResults
T@"NSMutableArray",&,N,V_imagePetsResults
T@"NSMutableArray",&,N,V_imagePetsFaceResults
T@"NSMutableArray",&,N,V_imageSceneprintResults
T@"NSMutableArray",&,N,V_livePhotoEffectsResults
T@"NSMutableArray",&,N,V_livePhotoRecommendationResults
T@"NSMutableArray",&,N,V_livePhotoSharpnessResults
T@"NSMutableArray",&,N,V_livePhotoKeyFrameResults
T@"NSMutableArray",&,N,V_livePhotoKeyFrameStillResults
T@"NSMutableArray",&,N,V_movieActivityLevelResults
T@"NSMutableArray",&,N,V_movieCameraMotionResults
T@"NSMutableArray",&,N,V_movieClassificationResults
T@"NSMutableArray",&,N,V_movieFaceResults
T@"NSMutableArray",&,N,V_movieFaceprintResults
T@"NSMutableArray",&,N,V_movieFeatureResults
T@"NSMutableArray",&,N,V_movieFineSubjectMotionResults
T@"NSMutableArray",&,N,V_movieInterestingnessResults
T@"NSMutableArray",&,N,V_movieMovingObjectResults
T@"NSMutableArray",&,N,V_movieMusicResults
T@"NSMutableArray",&,N,V_movieObstructionResults
T@"NSMutableArray",&,N,V_movieOrientationResults
T@"NSMutableArray",&,N,V_moviePreEncodeResults
T@"NSMutableArray",&,N,V_movieQualityResults
T@"NSMutableArray",&,N,V_movieSaliencyResults
T@"NSMutableArray",&,N,V_movieSceneResults
T@"NSMutableArray",&,N,V_movieSceneprintResults
T@"NSMutableArray",&,N,V_movieSubjectMotionResults
T@"NSMutableArray",&,N,V_movieSubtleMotionResults
T@"NSMutableArray",&,N,V_movieUtteranceResults
T@"NSMutableArray",&,N,V_movieVoiceResults
T@"NSMutableArray",&,N,V_movieSummaryResults
T@"NSMutableArray",&,N,V_movieHighlightResults
T@"NSMutableArray",&,N,V_imageExposureResults
T@"NSMutableArray",&,N,V_imageHumanPoseResults
T@"NSMutableArray",&,N,V_movieHumanPoseResults
T@"NSMutableArray",&,N,V_movieApplauseResults
T@"NSMutableArray",&,N,V_movieBabbleResults
T@"NSMutableArray",&,N,V_movieCheeringResults
T@"NSMutableArray",&,N,V_movieLaughterResults
T@"NSMutableArray",&,N,V_movieHumanActionResults
T@"NSMutableArray",&,N,V_movieLoudnessResults
T@"NSMutableArray",&,N,V_moviePetsResults
T@"NSMutableArray",&,N,V_moviePetsFaceResults
T@"NSMutableArray",&,N,V_movieStabilizationResults
propertyKey %s 
result is nil %s
width
height
Td,N,V_x0
Td,N,V_y0
Td,N,V_width
Td,N,V_height
input_image_1
input_image_2
cnn_moflow.espresso.net
res_landscape
res_portrait
res_sqaure
VCPMoflowEspresso
SHMutableSignature
/System/Library/PrivateFrameworks/ShazamKit.framework/ShazamKit
/System/Library/PrivateFrameworks/ShazamKit.framework/Contents/MacOS/ShazamKit
identifier
TI,N,V_identifier
hasFaceSharpness
vanishingPoint
dominantLine
T@"VCPProtoPoint",&,N,V_vanishingPoint
T@"VCPProtoLine",&,N,V_dominantLine
exposure
underExpose
Tf,N,V_exposure
hasUnderExpose
Tf,N,V_underExpose
eyeExpression
Ti,N,V_eyeExpression
Ti,N,V_yaw
hasFaceQuality
Tf,N,V_faceQuality
featureBlob
T@"NSData",&,N,V_featureBlob
com.apple.mediaanalysisd.voiceover
Face
Scene
com.apple.voiceoveranalysis.service.management
com.apple.voiceoveranalysis.service.handler
VoiceOverAnalysisService
CVPixelbuffer not IOSurface backed
hand_keypoint_detector_acc.espresso.net
object
T@,R,N,V_object
shotType
Ti,N,V_shotType
T@"VCPProtoPoint",&,N,V_start
T@"VCPProtoPoint",&,N,V_end
stabilizeResult
outputFrameDurValue
cropRectX
cropRectY
cropRectHeight
cropRectWidth
timeScale
epoch
frameInstructions
autoloop
bounce
longexposure
stabilize
minVersion
Ti,N,V_stabilizeResult
Tq,N,V_outputFrameDurValue
Ti,N,V_cropRectX
Ti,N,V_cropRectY
Ti,N,V_cropRectHeight
Ti,N,V_cropRectWidth
Ti,N,V_timeScale
hasEpoch
Tq,N,V_epoch
hasFlags
T@"NSMutableArray",&,N,V_frameInstructions
T@"VCPProtoLivePhotoVariationParams",&,N,V_autoloop
T@"VCPProtoLivePhotoVariationParams",&,N,V_bounce
T@"VCPProtoLivePhotoVariationParams",&,N,V_longexposure
T@"VCPProtoLivePhotoVariationParams",&,N,V_stabilize
Ti,N,V_minVersion
Ti,N,V_version
AutoLoop
Bounce
LongExposure
Stabilize
NormStabilizeInstructions
Version
MinVersion
Params
loopFlavor
loopEnergy
outputFrameDur
loopSuggestionState
longExposureSuggestionState
recipeBlob
TQ,N,V_loopSuggestionState
TQ,N,V_longExposureSuggestionState
hasRecipeBlob
T@"NSData",&,N,V_recipeBlob
Error: failed to processImage
idx (%tu) is out of range (%tu)
timeValue
homographyParam
Tq,N,V_timeValue
homographyParamsCount
homographyParams
T^f,R,N
res_384x384
q24@?0@"NSNumber"8@"NSNumber"16
res_%dx%d
Home resident maintenance task cancelled
errorCode
loopFadeLen
loopPeriod
loopStart
Ti,N,V_errorCode
hasLoopFadeLen
Ti,N,V_loopFadeLen
hasLoopPeriod
Ti,N,V_loopPeriod
hasLoopStart
Ti,N,V_loopStart
ErrorCode
activityScore
Tf,N,V_activityScore
motionType
isFast
Ti,N,V_motionType
TB,N,V_isFast
com.apple.homekitanalysis.session.management
com.apple.homekitanalysis.session.handler
No result handler registered
No VCPHomeKitAnalysisSession; cannot process message
weakSession
T@"VCPHomeKitAnalysisSession",W,N,V_weakSession
HMIVideoAnalyzer
classification
classifications
T@"NSMutableArray",&,N,V_classifications
faceprintBlob
TI,N,V_faceID
T@"NSData",&,N,V_faceprintBlob
maxNumberHands
humanActionWindowSize
useCPUOnly
TB,R,N,V_useCPUOnly
TI,R,N,V_revision
mouthExpression
isCloseup
Ti,N,V_mouthExpression
Ti,N,V_position
TB,N,V_isCloseup
Ti,N,V_faceID
cloudIdentifier
filename
originalFilename
locationCoordinate
T{CLLocationCoordinate2D=dd},R,N
distanceIdentity
FramesPerSecond
interestScore
Tf,N,V_interestScore
estimatedAssetCount
approximateCoordinate
isCoarse
energy
peak
Td,N,V_energy
Td,N,V_peak
T@"NSMutableArray",&,N,V_bounds
q24@?0@8@16
yyyy-MM-dd-HH-mm-ss
suggestionLog_
suggestions.html
function addPlaceHolders() {
addPlaceholdersForSet("visionInput", inputFaces);
addPlaceholdersForSet("visionOutput", outputFaces);
addPlaceholdersForSet("visionFiltered", filteredFaces);
function isElementHidden(element) {
var style = window.getComputedStyle(element);
return (style.display === 'none')
function updateVisibility() {
var allDivs = document.getElementsByTagName("div");
for (var i = 0; i < allDivs.length; i++) {
var d = allDivs[i];
if (!d.attributes["img"]) continue;
var rect = d.getBoundingClientRect();
if (
rect.top >= -100 &&
rect.left >= -100 &&
rect.bottom - 100 <= (window.innerHeight || document.documentElement.clientHeight) &&
rect.right - 100 <= (window.innerWidth || document.documentElement.clientWidth)
if (d.childNodes.length == 0) {
d.innerHTML = "<img src='" + d.attributes["img"].value + "' width='100' height='100'>";
else {
if (d.childNodes.length != 0) {
d.innerHTML = "";
function addPlaceholdersForSet(containerId, elements) {
var content = "";
for (var i = 0; i < elements.length; i++) {
content += "<div style='float: left; width: 100px; height: 100px; margin: 3px; background-color: darkgray' img='" + elements[i] + "'></div>"
document.getElementById(containerId).innerHTML = content;
document.onscroll = function (e) {
updateVisibility();
</script>
</head>
<body>
<p>Vision input:</p>
<div id="visionInput">
</div>
<p style="clear: both;">Vision output:</p>
<div id="visionOutput">
</div>
<p style="clear: both;">Vision filtered output:</p>
<div id="visionFiltered">
</div>
</div>
<script>
document.addEventListener("DOMContentLoaded", function (event) {
addPlaceHolders();
</script>
</body>
</html>
could not obtain access to the photo library
photo library could not provide suggestions
_suggestionsForPersonWithLocalIdentifier cancelled
v16@?0q8
<html>
<head>
<script>
 var inputFaces = [
v32@?0@"NSString"8@"NSArray"16@"NSError"24
var outputFaces = [
var filteredFaces = [
suggestPersonsForPersonWithLocalIdentifier cancelled
Input parameter is empty or nil: '%@'
PVCluster is nil
v32@?0@"NSSet"8Q16^B24
v32@?0@"NSString"8@"NSArray"16^B24
verifiedType != %d
VCPFaceProcessingDeleteAllVerifiedPersons
succeeded
failed
VCPFaceProcessingReclusterFacesWithThreshold
VCPFaceProcessingBuildPersons
VCPBuildPersons failed %d
VCPFaceProcessingPromotePersons
VCPPromotePersons failed %d
PVClusterer
PVSuggestionUpdateFinished
PVSuggestionUpdateCancelled
B32@?0@"NSDictionary"8Q16^B24
PVPersonPromoter
v32@?0@"PHFace"8Q16^B24
q24@?0@"PHAssetResource"8@"PHAssetResource"16
PersonBuilderMergeCandidatesEnabled
PersonBuilderLastMinimumFaceGroupSizeForCreatingMergeCandidates
personBuilderState != %lu
VCPFaceProcessingCleanupMergeCandidates
PVUserDefaults
Sceneprint task cancelled
[%@] Thumbnail is not locally available
[%@] Failed to load thumbnail image
[%@] Invalid sceneprint result
Ti,N,V_orientation
statisticsBlob
T@"NSData",&,N,V_statisticsBlob
distanceToPreviousScene
flickerScore
sceneprintDistanceToPreviousScene
hasDistanceToPreviousScene
Tf,N,V_distanceToPreviousScene
hasFlickerScore
Tf,N,V_flickerScore
hasSceneprintDistanceToPreviousScene
Tf,N,V_sceneprintDistanceToPreviousScene
hasAction
TB,N,V_hasAction
v12@?0B8
Face clustering threshold should be in the range: [0.1, 1.0]
VCPFaceProcessingResetFaceClusteringState
VCPFaceProcessingPerformFaceClusteringAndWait
clusterer is not available
VCPFaceProcessingClusterFacesWithExtendTimeoutBlock
com.apple.mediaanalysis.clusteringQueue
faceCountInFaceGroup
isDirty
curationScore
autoPlayable
playbackCrop
Tf,N,V_curationScore
hasKeyFrame
T@"VCPProtoVideoKeyFrame",&,N,V_keyFrame
TB,N,V_autoPlayable
hasPlaybackCrop
T@"VCPProtoBounds",&,N,V_playbackCrop
Td,N,V_x
Td,N,V_y
value
timescale
Tq,N,V_value
Ti,N,V_timescale
T@"VCPProtoTime",&,N,V_start
T@"VCPProtoTime",&,N,V_duration
face
T@"PHFace",R,N,V_face
callerIdentifier
T@"NSString",R,N,V_callerIdentifier
Tf,R,N,V_confidence
inputBoundsX
inputBoundsY
inputBoundsHeight
inputBoundsWidth
sourceSizeHeight
sourceSizeWidth
Tf,N,V_cropRectX
Tf,N,V_cropRectY
Tf,N,V_cropRectHeight
Tf,N,V_cropRectWidth
Tf,N,V_inputBoundsX
Tf,N,V_inputBoundsY
Tf,N,V_inputBoundsHeight
Tf,N,V_inputBoundsWidth
Tf,N,V_sourceSizeHeight
Tf,N,V_sourceSizeWidth
timeValuesCount
timeValues
T^q,R,N
numOfValidFrames
TQ,R,N,V_numOfValidFrames
VCPMovieWriter.mediaDataRequest
com.apple.mediaanalysis.VCPSharedInstanceManager
Received action score %f - %f
=========%s==========
[%.2f - %.2f]: %.2f
capturePointSegmentIdx: %d
----[%.2f - %.2f]
startIdx = %d, endIdx = %d, count = %d, [%f, %f] with score %f captureTime=%f
interesting trim: [%f, %f], score = %.2f
 --[%.2f - %.2f]
com.apple.mediaanalysis.VCPVideoChatAnalysis
sport
cnn_activitylevel.dat
T{?={?=qiIq}{?=qiIq}},V_timerange
Tf,V_score
descriptors
T^f,R
TrackSegments
Hand_waving
Hand_clapping
Dancing
Walking
Running
Jumping
cnn_human_action.espresso.net
T{?=[4]},R,N,V_pose
Tr^,R,N,V_vertices
landmarks
Tr^f,R,N,V_landmarks
bufferRotated
TB,R,N,V_bufferRotated
face1
T@"PVFace",R,N,V_face1
face2
T@"PVFace",R,N,V_face2
Td,R,N,V_score
Cannot align faces: PVImage misses CGImage, URL, Data or pixelBuffer
Cannot align faces: failed to create VNImageRequestHandler.
Cannot align faces: failed to create VNAlignFaceRectangleRequest.
Cannot align faces: error: %@
bound
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bound
pose
T{?=[4]},V_pose
v32@?0@"NSNumber"8@"VCPFace"16^B24
q24@?0@"VCPFace"8@"VCPFace"16
/tmp/
v32@?0@"NSNumber"8@"VNFaceprint"16^B24
v32@?0@"NSNumber"8@"NSNumber"16^B24
T{?=qiIq},N,V_timestamp
semanticScore
Tf,N,V_semanticScore
faceSharpness
Tf,N,V_faceSharpness
isHeadingFrame
TB,N,V_isHeadingFrame
expressionChangeScore
Tf,N,V_expressionChangeScore
T@"NSMutableArray",&,N,V_faceQualityScores
frameResults
T@"NSMutableDictionary",&,N,V_frameResults
v32@?0@"NSNumber"8@"NSArray"16^B24
privECMVct
privEMBVct
privDFArray
privET
privImgG
privTZF
privAFS
privAFSt
privFM
relSampleTime
trajectoryHomography
presentingTimestamp
originalPresentingTimestamp
LivePhotoMetadataSetupDataVersion
FrameworkVersions
CMCaptureCore
mdta/com.apple.quicktime.live-photo-info
T@"NSDictionary",R,&,N
results
T@"NSArray",R,&,N
focusStatus
Tq,V_focusStatus
hadZoom
TB,N,V_hadZoom
minZoom
Tf,N,V_minZoom
maxZoom
Tf,N,V_maxZoom
45.1
v32@?0@"NSString"8@"NSString"16^B24
absMotion
Tf,V_absMotion
stabilityScore
Tf,V_stabilityScore
objectBoundsInitial
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBoundsInitial
objectBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBounds
T{?=qiIq},R,N,V_start
lostCount
Ti,R,N,V_lostCount
SalientRegions
plistRepresentation
v32@?0@"NSNumber"8@"VCPVideoObjectTracker"16^B24
q24@?0@"VCPSaliencyRegion"8@"VCPSaliencyRegion"16
sceneId
T@"NSString",&,V_sceneId
Tf,V_duration
sumConfidence
Tf,V_sumConfidence
q24@?0@"VNClassificationObservation"8@"VNClassificationObservation"16
q24@?0@"VCPClassification"8@"VCPClassification"16
frameScenes
sceneResults
T@"NSArray",&,V_sceneResults
[VideoTrackDecoder status] should not be called
[VideoTrackDecoder copyNextSampleBuffer] should not be called
[VideoTrackDecoder getNextCaptureSampleBuffer] should not be called
com.apple.mediaanalysis.VCPVideoTrackSyncDecoder
voiceDetections
T@"NSMutableArray",&,V_voiceDetections
/Library/Audio/Tunings/Generic/AU/aufx-epv2-mediaanalysis-appl.plist
T@"NSData",&,D,N
T^{CGPoint=dd}
stableInd
lostTrackInd
T^{CGPoint=dd},VP
TB,Vstable
TB,VlostTrack
[Poc %d]: failed to find LTR that is ready to be retired
Failed to find frame poc=%d in DPB
[Poc %d]: reference poc %d is set as both STR and LTR
Wrong short-term RPS index (%d)
VCPRateControlSession
VCPRateControlSession %p (%dx%d)
com.apple.videotoolbox.videoencoder.h264.rtvc
NULL session
Failed to query number of CPUs
com.apple.videotoolbox.videodecoder.h264.rtvc
CMClassImplementationID
unordered_map::at: key not found
DirtyRegionArray
hw.optional.bmi2
hw.optional.bmi1
hw.optional.avx2_0
hw.optional.avx1_0
hw.cachelinesize
hw.logicalcpu
Setup References failed; Encode IDR
VCPSession
phase_y
phase_x
used_height
used_width
SCN_UUID
SetBit
./RateControlSession/Utilities/utilities.h
(idx < 8*sizeof(T)) || (NULL == "Bit index out of range")
GetBit
delta poc: %d, used: %d
Delta poc s1:
Delta poc s0:
num_positive_pics: %d
num_negative_pics: %d
No supported!
inter_ref_pic_set_prediction_flag: %d
Long-term poc lsb:
Unavailable long-term reference - POC %d!
Unavailable short-term reference - POC %d!
FLS;RVRA1:1;AS:2;MS:-1;LTR;CABAC;CR:3;LF:-1;PR;CH1:4;FA:5;
FLS;RVRA1:0;PR;LF:-1;CR:1;CF:2;CH1:3;FA:4;
FLS;MS:-1;LF:-1;LTR;CABAC;POS:0;EOD:1;HTS:2;RR:3;
FLS;LF:-1;POS:5;EOD:1;HTS:2;RR:3;
FLS;
VCPCodec_LRP
VCPCodec_AVC1
SliceType
FirstMB
Height
parameter sets buf overrun
LRPConfigurationRecordToParameterSets failed
VCPCompressionSession
HEVC
H.264
VCPEnc %p (%dx%d, %s): Video compression session invalidated
macOS
VCPEnc %p (%dx%d, %s, %s)
Failed to create rate controller
VCPEnc %p (%dx%d, %s): Failed to create %s video encoder with usage %d on %s, err = %d!
VCPEnc %p (%dx%d, %s): Created video encoder with usage %d on %s.
TileOrder
TileID
PriorityScore
Invalid sample buffer
VCPEnc %p (%dx%d, %s): Got video encoder specification: request_hw = %d, usage = %d, on %s
decodingOrderBase
VCPEnc %p: Encoder got number of tiles video specification: %d
NumberOfTiles
VCPEnc (%dx%d, %s): Failed to create video compression session, err = %d
ThermalLevel
VCPEnc %p (%dx%d, %s): Encoder got compression mode property: %d, but forced to %d
VCPEnc %p (%dx%d, %s): Unexpected compression mode: %d!
VideoProminence: kVCPCompressionPropertyKey_CompressionMode (set by AVC) = %d
CompressionMode
VCPEnc %p (%dx%d, %s): Encoder got ExpectedFrameRate property: %@, will be set to %@ to support %d-tile encoding
VCPEnc %p (%dx%d, %s): Encoder got %@ property = %@
VCPEnc %p (%dx%d, %s): Encoder fails with err = %d, tile id %d order %d
SignpostID
SignpostTimeStamp
VCPEnc %p (%dx%d, %s): Encoder failed to create tile id %d, order %d
VCPEnc %p (%dx%d, %s): Encoder failed to create buffer for tile id %d, order %d
HIDTimeStamp
VCPDecompressionSession
VCPDec %p (%dx%d, %s): Video decompression session invalidated
VCPDec %p (%dx%d, %s): Decoder failed to create video processor, err = %d
VCPDec %p (%dx%d, %s): Failed to create video decoder, err = %d
FaceZoom
VCPDecompressionSessionSetProperty: vcpSession is NULL
VCPDec %p (%dx%d, %s): Failed to set max buffer age of decoder pixel buffer pool
VCPDec %p (%dx%d, %s): Failed to copy decoder pixel buffer pool
VCPDec %p (%dx%d, %s): Failed to create video decoder, usage = %d, on %s, err = %d; FLS = "%s"
VCPDec %p (%dx%d, %s): Created %s video decoder, usage = %d, on %s; FLS = "%s"
VCPDec %p (%dx%d, %s): Decoder failed to create video format description, err = %d!
VCPDec %p (%dx%d, %s): Decoder could not parse config info!
hvcC
VCPDec %p (%dx%d, %s): Decoder FLS doesn't exist
VCPDec %p (%dx%d, %s): Decoder could not get FLS!
VCPDec %p (%dx%d, %s): Decoder failed to create an FLS, err = %d
com.apple.VideoConference
FaceTimeDecoder
VCPDec %p (%dx%d, %s): Decoder failed to initialize stitching filter, err = %d
VCPDec %p (%dx%d, %s): Decoder failed to create stitching filter, err = %d
VCPDec %p: Decoder got buffer height video specification: %d
FrameBufferHeight
VCPDec %p: Decoder got buffer width video specification: %d
FrameBufferWidth
VCPDec %p: Decoder got number of tiles video specification: %d
VCPDec %p (%dx%d, %s): Failed to create decoder specification copy, err = %d
VCPDec %p (%dx%d, %s): Failed to filter the frame after tile (id %d, order %d)
VCPDec %p (%dx%d, %s): Failed to stitch non-dirty tile (id %d, order %d)
VCPDec %p (%dx%d, %s): Failed to stitch tile (id %d, order %d)
VCPDec %p (%dx%d, %s): Timestamp does not match, expected: %d, actual: %d
VCPDec %p (%dx%d, %s): Do not process this subframe because it should be dropped
VCPDec %p (%dx%d, %s): Tile order does not match, expected: %d, actual: %d
VCPDec %p (%dx%d, %s): Decoder failed to create stitched pixel buffer for subframe decoding!
VCPDec %p (%dx%d, %s): Decoder failed to create stitched pixel buffer pool for subframe decoding! (pixfmt %d)
RotationFlags
VraHeight
VraWidth
VCPDec %p (%dx%d, %s): Decoder checksum is N/A
VCPDec %p (%dx%d, %s): Decoder checksum mismatch local %x <-> received %x
v20@?0i8^{__CFDictionary=}12
VCPDec: Failed to create video decompression session, err = %d
EnableVideoChatAnalysis
ExtraInloopFilter
VCPDecompressionSessionDecodeFrame: VCPDecompressionControlByteProcessing failed
Failed to recreate DecompressionSession, err = %d
RequestedRotationFlags
rtpTimestsamp
VCPDec %p (%s): Decoder failed to initialize vcpFrameContext, err = %d
VCPDec %p (%s): Decoder failed to create vcpFrameContext, err = %d
VCPRealTimeAnalysisService
v24@?0@"NSDictionary"8@"NSError"16
NULL plane!
CABAC
RVRA
LRPConfigInfo: extract parameter sets from configuration record failed
Failed to parse SPS
LRPConfigInfo: extract sequence parameter sets from configuration record failed
DecodeCallbacks
H.264: failed to create video decoder instance, err = %d
NegotiationDetails
H.264: video decoder failed to decode frame, err = %d
FrameYUVChecksum
VTImageBufferVisibleRectangle
H.264: failed to create video decoder lib instance, err = %d
avcC
H.264: start sw video decoder session: dimension = %d x %d, usage = %d
H.264: failed to create video decoder pixel buffer attributes, err = %d.
com.apple.coremedia
ForceSyncH264SWDecoder
<H264VideoDecoder %p>
com.apple.VideoProcessing.JVTLib
com.apple.coremedia.JVTlib
hw.physicalcpu
hw.optional.sse4_2
hw.optional.sse4_1
hw.optional.supplementalsse3
hw.optional.sse3
hw.optional.sse2
RVRA7
RVRA4
RVRA1
RVRA3
RVRA2
MVRA
IODeviceTree:/arm-io
compatible
Unimplemented function
{PostProcDitherNoiseUpon2VUY} Error on memory allocation: noiseBlkPosPtr!
{OptimizedCabacDecoder::EndSliceBody} bitstream parsing error!!!!!!!!!!!!!!
{OptimizedCabacDecoder::UpdateBitStreamPtr} bitstream parsing error!!!!!!!!!!!!!!
Wrong filter type!
{PostProcDitherNoiseUpon2VUY} Dithering noise strength (=%u) not currently supported.
    Analyzing Audio Track - ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
Failed to lock CVPixelBuffer (%p, %d)
Cannot lock NULL CVPixelBuffer
Lock attempt failed; cannot unlock buffer
Multiple unlock attempts; cannot unlock buffer
Failed to unlock CVPixelBuffer (%p, %d)
Video track rotation angle is not multiple of 90
Gyro analytics collection not implemented
copyImageToBGRHandKeypointCallFromSPI
preProcessingHandKeypointCallFromSPI
Not implemented, please use initWithOptions
Multiple sampling times (%0.1fs) intersect frame at %lld/%d
%@ skipping sample %lld at %lld/%d
%@ failed for sample at %lld/%d (%@)
[MediaAnalysis] Failed to open database
Closed analysis database
[MediaAnalysis] Unknown result key for result type %u
[MediaAnalysis] Error querying blacklist status for %@
[MediaAnalysis] Failed to query blacklisted assets
[MediaAnalysis] Failed to query asset %@
[MediaAnalysis] Failed to query analysis properties of asset %@
[MediaAnalysis] queryAnalysesForAssets Failed
[MediaAnalysis] Failed to query assets since %@
[MediaAnalysis] Failed to query failed assets for taskID: %lu
[MediaAnalysis] WARNING: ProcessingStatus entry with nil localIdentifier
Failed to extract NSArray from column %d (%@)
Creating faceprint for face crop
Multiple faces present in face crop; using first
Loading quick identification model
Performing quick identification
Quick identification match found: %@
No quick identification match found
Home face identification task failed (%@)
Getting no object IDs when fetching assets on moment %@
VCPFaceAnalyzerReleaseCachedResources
Error: missing VNDetectFaceRectanglesRequest
Error: missing VNDetectFaceLandmarksRequest
Error: missing VNDetectFaceExpressionsRequest
Error: missing VNDetectFacePoseRequest
Error: missing VNCreateFaceTorsoprintRequest
Error: missing VNClassifyFaceAttributesRequest
Error: missing VNDetectFaceCaptureQualityRequest
Error: creating VNDetectFaceRectanglesRequest
Error: creating VNDetectFaceLandmarksRequest
Error: creating VNDetectFaceExpressionsRequest
Error: creating VNDetectFacePoseRequest
Error: creating VNCreateFaceTorsoprintRequest
Error: creating VNClassifyFaceAttributesRequest
Error: creating VNDetectFaceCaptureQualityRequest
Error: creating VNImageBlurScoreRequest
Error: creating VNImageExposureScoreRequest
Faceprint request failed to return a faceprint
Error creating Face VNRequest
VCPFaceAnalyzerImageRequestHandlerPerformRequest
Error: Face VNImageRequestHandler::performRequests: %@
Error: failed to create blur/exposure request
Error: blurScore %f out of bound [%f, %f]
Error: VNImageRequestHandler failed to perform blurRequests: %@
Error: exposureScore %f out of bound [%f, %f]
Error: VNImageRequestHandler failed to perform exposureRequests: %@
VCPFaceAnalyzerBlurExposureAnalysis
VCPFaceAnalyzerPVFaceCreation
VCPFaceAnalyzerVerifyAndMergeFaces
 [%@] Analysis completed; facesDetected %lu | facesToPersist: %lu | facesToDelete: %lu
VCPFaceAnalyzerLoadImageRequestHandler
Failed to create VNImageRequestHandler
Failed to analyze PVImage
Failed to refine analysis
VCPFaceAnalyzerPerformAnalysis
Unexpected media type (%lu)
[%@] Unexpected media type (%d)
%@ canceled (%@)
%@ failed (%@)
[MediaAnalysis] Image descriptor - found more than 1 VNImageprintObservations
VNImageprint init error: %@
Query progress: unsupport taskID (%lu)
Query progress: output parameter statistics must be non-nil
Query progress: unsupported taskID (%lu)
Query progress: %@ - %@
Query progress: unsupported taskID (%@)
Query progress: %@ - %lu out of %lu
VCPVideoStabilizationAssetProcessingTask
Video Stabilization processing failed
[%@] Quick Face ID task failed; skip processing
Quick Face ID batch %lu, jobs: %lu
Quick Face ID task canceled (%@)
Quick Face ID task failed (%@)
[Decode] Downscaling %zux%zu --> %zux%zu
[Decode] %.0fx%.0f --> %zu; subsampling %dx on decode
[Decode] Accelerated decode failed; falling back to CGImage
Found %lu faces with CSN > 0 but not in any face groups
VCP: %@
PersistFaceGroups: Photo library is missing a face with CSN = %@
PersistFaceGroups: Faces with these CSNs will be removed from the cluster cache: %@
PersistFaceGroups: Faces with these localIdentifiers will be re-clustered: %@
PersistFaceGroups: We should not get here! If we did, then we have a previously clustered face without a face group!
PersistFaceGroups: Failed to create a face group change request to add faces!
PersistFaceGroups: Failed to find a faceGroup for face '%@' with CSN: %d
PersistFaceGroups: No faces added to face groups!
PersistFaceGroups: Failed to find face with localIdentier: %@. Could not set its CSN to %@
PersistFaceGroups: Set personBuilderState of faceGroups: %@
PersistFaceGroups: Failed to delete empty face groups with error: %@
PersistFaceGroups: Canceled updating key faces unverified persons after persisting face groups.
PersistFaceGroups: Failed to update key faces unverified persons after persisting face groups. Error: %@
%s: Input parameter is empty or nil: '%@'
%s: %@
UpdateKeyFaces: Key Face exists. Ignoring %@
Updating key face %@ on person %@
Error: did not find single face group for unverified person, unable to set key face on face group, (number of face groups: %lu)
Error: could not set key face for person %@
Warning: Couldn't get faceprint data for face: %@. Ignoring
Error: Failed to get VNFaceTorsoprint from faceprint data, error: %@
Warning: Could not get representativeness for faces, error: %@
PersonBuilder: Deleted duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Failed to delete duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Deduped graph-verified persons '%@' from face group %@
PersonBuilder: Failed to dedupe graph-verified persons '%@' from face group %@
personLocalIdentifier for PHFace %@ is null; skip processing
Found no persons rejected for a rejection training face: %@
PersonBuilder: Did not find merge candidate persons with local identifiers: '%@'
PersonBuilder: Found invalid merge candidate pair ['%@' : '%@']
PersonBuilder: Already found merge candidate pair ['%@' : '%@']
PersonBuilder: Unexpected error - could not create merge candidate pair '%@' : '%@'
PersonBuilder: Unexpected error - could not create invalid merge candidate pair '%@' : '%@'
PersonBuilder: Cleared personBuilderState of faceGroup: '%@'
Could not find a face with clusterSequenceNumber '%@' in the library
PersonBuilder: Got a 'nil' photoLibrary. Cannot build persons
PersonBuilder: Failed to find unverified person for faceGroups '%@'; These will be fixed up and retried later
PersonBuilder: Failed to fix up face groups without unverified person. Error: '%@'
PersonBuilder: Person Building faceGroup '%@'
PersonBuilder: Failed to find unverified person [unverifiedPerson: %@, unverifiedPersonLocalIdentifier: %@] for faceGroup '%@', skipping this face group
Person Builder: Quick classification faces found. Number of faces retained: %@. Number of faces reassigned %@
PersonBuilder: We may have a dirty level0 cluster, persons with training faces: %@
PersonBuilder: We may have a dirty level0 cluster, verified persons with confirmed face: %@
PersonBuilder: Unnamed unconfirmed faces in face group, '%@', without a training face: %@
PersonBuilder: Found training rejection, unassigned faces on trainingPersonLocalIdentifier in level0 cluster: %@
PersonBuilder: Skip processing level0 cluster since we have rejected face for training person '%@' in level1 cluster
PersonBuilder: Failed to build persons [Error: '%@']
PersonBuilder: ---> buildPersonsWithFaceClusterer, %s
PersonBuilder: Person Building is Disabled!
PersonBuilder: Cleared personBuilderState of faceGroups: %@
PersonBuilder: Failed to clear personBuilderState of faceGroups: %@, error: %@
PersonBuilder: <--- buildPersonsWithFaceClusterer
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
Failed to remove auto-assigned faces from person '%@', error: %@
Failed to load PVSceneTaxonomySoft
VCPSceneAnalyzerReleaseCachedResources
Failed to create VNClassifyImageAestheticsRequest
Failed to create VNSceneClassificationRequest
Failed to create VNCreateSceneprintRequest
Failed to create VNClassifyJunkImageRequest
Failed to create VNGenerateAttentionBasedSaliencyImageRequest
Failed to set VNCreateSceneprintRequest::setPrivateRevision %lu: %@
Failed to set VNClassifyJunkImageRequest::setPrivateRevision %lu: %@
Failed to set %@::setPrivateRevision %lu: %@
Failed to create %@
Unsupported observation label %@
Error creating VNRequest
VCPSceneAnalyzerImageRequestHandlerPerformRequest
Failed to run VNImageRequestHandler::performRequests: %@
VCPSceneAnalyzerImageBlurAnalysis
VCPSceneAnalyzerExposureAnalysis
VCPSceneAnalyzerLoadImageRequestHandler
Failed to load imageURL: %@
VCPSceneAnalyzerPerformAnalysis
Analysis Cancelled
SceneProcessingLoadAsset
SceneProcessingAnalyzeAsset
  [%@] Failed to decode last frame of video, fall back to thumbnail 
[MediaAnalysis] Junk analayzer - unexpected %d VNObservations
CNNHandsDetectorEspresso: adopting model config: %@
CNNHandsDetectorEspresso: updating model config to %@
inferenceHandDetectorCallFromSPI
Unknown Media Analysis version specified (%d)
[MediaAnalysis][%@] No slow-mo timestamp mapping file URL found
[MediaAnalysis][%@] No slow-mo timestamp mapping file found
[MediaAnalysis][%@] Resource required for slow-mo timestamp adjustment is not present
[MediaAnalysis][%@] Failed to load resource for slow-mo timestamp adjustment
  [%@] Unknown analysis version %d; discarding
[MediaAnalysisResultsTypesForAnalysisTypes] Unknown result type
Not all needed analysis are available for video highlights.
[%.2f - %.2f] expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, Score=%.2f
[%.2f - %.2f] keyFrameScore=%.2f, expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, humanActionScore=%.2f, humanPoseScore=%0.2f, Score=%.2f
Media analysis client XPC connection interrupted
Media analysis client XPC connection invalidated
[MediaAnalysis] [MediaAnalyzer requestAnalysisTypes] call with invalid resourceURLs
Failed to issue sandbox extension on %@
[MediaAnalysis] Error connecting to background analysis service
[MediaAnalysis] Request %d has completed
[MediaAnalysis] Error connecting to Photos background analysis service
[MediaAnalysis] Unsupported task %lu
[MediaAnalysis] Asset processing request %d has completed
Failed to open Photo Library at %@
[MediaAnalysis] Error connecting to Photos Quick Face Identification service
[MediaAnalysis] Request %d is %.2f%% complete
[MediaAnalysis] Unknown analysis request %d; dropping cancellation request
[MediaAnalysis] No active analysis requests; dropping cancellation request
[MediaAnalysis] Failed to cancel background analysis: %@
[MediaAnalysis] Background analysis canceled
[MediaAnalysis] Error connecting to background analysis service: %@
[MediaAnalysis] Error connecting to request PersonPromoterStatus service
[MediaAnalysis] Request Person Preference %d has completed
[MediaAnalysis] Request VIP model filepath Preference %d has completed
[MediaAnalysis] Error connecting to request SuggestedPersons service
[MediaAnalysis] Request SuggestedPersons %d has completed
[MediaAnalysis] Error connecting to request UpdateKeyFacesOfPersons service
[MediaAnalysis] Request UpdateKeyFacesOfPersons %d has completed
[MediaAnalysis] Error connecting to request FaceCandidatesforKeyFace service
[MediaAnalysis] Request FaceCandidatesforKeyFace %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClassificationModel service
[MediaAnalysis] Request ResetFaceClassificationModel %d has completed
[MediaAnalysis] Error connecting to request SuggestedMePersonIdentifier service
[MediaAnalysis] Request SuggestedMePersonIdentifier %d has completed
[MediaAnalysis] Request PersonPromoterStatus %d has completed
[MediaAnalysis] Error connecting to request ClusterCacheValidation service
[MediaAnalysis] Request ClusterCacheValidation %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClusteringState service
[MediaAnalysis] Request ResetFaceClusteringState %d has completed
[MediaAnalysis] Error connecting to request ReclusterFaces service
[MediaAnalysis] Request ReclusterFaces %d has completed
[MediaAnalysis] Error connecting to request RebuildPersons service
[MediaAnalysis] Request RebuildPersons %d has completed
[MediaAnalysis] failed to get database sandbox extension
[MediaAnalysis] failed to consume sandbox extension
[MediaAnalysis] Consumed sandbox extension
[MediaAnalysis][%@] Storing on-demand analysis
[MediaAnalysis][%@] Failed to store on-demand analysis
[MediaAnalysis][%@]Unable to open movie
[MediaAnalysis][%@]Failed to create asset
[MediaAnalysis][%@] Received analysis request: %@
[MediaAnalysis][%@] Analysis requested for blacklisted asset
[MediaAnalysis][%@] Existing analysis based on old modification
[MediaAnalysis][%@] Existing analysis based on degraded asset
[MediaAnalysis][%@] Existing analysis satisfies request (%@)
[MediaAnalysis][%@] Existing analysis doesn't match asset state
[MediaAnalysis][%@] Existing analysis doesn't satisfy request (%@)
[MediaAnalysis][%@] Generating analysis on-demand: %@
[MediaAnalysis][%@] Analysis served: (%@)
[MediaAnalysis] [MediaAnalyzer requestAnalysisForAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library %@
[MediaAnalysis] [MediaAnalyzer assetsAnalyzedSinceDate] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library (%@)
Cannot load %@ for %@, NSData length: %lu, content: %@
Cannot load %@ from PHAsset, NSData length: %lu, content: %@
[MediaAnalysis] [MediaAnalyzer distanceFromAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for assets
[MediaAnalysis] failed to request analyses
[MediaAnalysis] [requestAnalysesForAssets] call from invalid instance
[MediaAnalysis] [requestAnalysesForAssets] in standalone mode but on-demand not allowed
[MediaAnalysis] call from invalid instance
[MediaAnalysis] on-demand analysis requested in standalone mode
Warning: On demand analysis is not supported.
[MediaAnalysis] Failed to obtain database for collection %@
Warning: No face specified.
[MediaAnalysis] [requestLivePhotoEffectsForAssets] call from invalid instance
[MediaAnalysis] [requestLivePhotoEffectsForAssets] in standalone mode but on-demand not allowed
Warning: requestLivePhotoEffectsForAssets only support iOS device.
  [%@] Existing analysis outdated; dropping
VCPLightVideoAnalyzer
VCPVideoStabilizerPixel
VCPVideoFaceDetector
VCPFullVideoAnalyzer
VCPVideoSceneClassifier
VCPVideoActivityAnalyzer
VCPVideoSaliencyAnalyzer
VCPVideoHumanActionAnalyzer
VCPVideoHumanActionClassifier
VCPVideoPetsAnalyzer
VCPMovieCurationAnalyzer
VCPVideoStabilizer
    Analyzing Video Segment - Track ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
VCPAudioAnalyzer
    Video track has invalid dimensions (%.f,%.f)
VCPMovieAnalyzer
  [%@] Need Face Processing: no faceAdjustmentVersion
  [%@] Need Face Processing: faceAdjustmentVersion %@ != adjustmentTimestamp %@
  [%@] Fingerprint requested for asset with no objectID
  [%@] Fingerprinting failed
QuickFaceID Model: persistent storageDirectoryURL is nil; skip loading FaceID Model
QuickFaceID Model: cannot load FaceID Model: %@
 [%@] QuickFaceID: no local resource
 [%@] QuickFaceID: failed to load image
 [%@] QuickFaceID: failed to analyze asset (%d)
 [%@] QuickFaceID: image too small to classify
 [%@] QuickFaceID: classifying face: %@; skip processing face
 [%@] QuickFaceID: did not find a matching person for face located at (%.3f, %.3f)
 [%@] QuickFaceID: found person: %@
 [%@] QuickFaceID: expected to find a person for person uuid = %@; skipping
 [%@] QuickFaceID: failed to persist classification results: %@
Quick Face ID failed to load persons model
 [%@] QuickFaceID: analyzing asset (deferType: %d)
 [%@] QuickFaceID: asset is not image
 [%@] QuickFaceID: processed %lu faces
QuickFaceID Model: Last job generation %.0fs ago, job is due = %d
QuickFaceID Model: Begin model generation
QuickFaceID Model: Model generation cancelled. Quitting
FaceID Model: fetch count for person %@: %lu
FaceID Model: fetch count without roll predicate for person %@: %lu
QuickFaceID Model: Could not create faceprint for face: %@. Error: %@
QuickFaceID Model: Could not add faceprint to model for face: %@.
QuickFaceID Model: Could not add faceprints to model. Error: %@
QuickFaceID Model: Finished model generation
QuickFaceID Model: Failed to persist model %@
QuickFaceID Model: Could not get face observations for person %@ - %@
QuickFaceID Model: Could not persist isInVIPModel on trained faces - %@
QuickFaceID Model: Finished model generation and persistence
QuickFaceID Model: No need to generate model
[%@] Asset has no small video derivative; skipping
[%@] File size exceeds streaming threshold; skipping
[%@] Duration exceeds streaming threshold; skipping
Unknown VCPTaskID (%lu); redirect to VCPTaskID_MediaAnalysis
  Analyzing degraded version of Movie
  [%@] missing Pre Analysis result
  Analyzing degraded version of Photo
VCPImageFaceDetector
VCPImageFaceExpressionAnalyzer
VCPImageJunkAnalyzer
VCPImageBlurAnalyzer
VCPLowResImageBlurAnalyzer
VCPImageExposureAnalyzer
VCPImageLivePhotoBlurAnalyzer
VCPImageCompositionAnalyzer
VCPImageDescriptor
VCPImageSaliencyAnalyzer
VCPImagePetsAnalyzer
VCPImageHumanPoseAnalyzer
VCPImageHandsAnalyzer
VCPLivePhotoAnalysis
VCPLivePhotoKeyFrameAnalyzer
VCPPhotoAnalyzer
Face Processing storage directory: %@
No persistentStorageDirectoryURL for photoLibrary: %@
Unable to serialize library analysis preferences for %@: %@
Unable to write library analysis preferences for %@: %@
Key for setLibraryAnalysisPreferencesValue is nil
Error -[VNCreateSceneprintRequest setPrivateRevision:error:]
Error -[VNImageRequestHandler requestHandler:error:]
NSKeyedUnarchiver error: %@
[Generic] Client XPC connection interrupted
[Generic] Client XPC connection invalidated
[Generic] Error connecting to analysis service
VCPVoiceOverAssetProcessingTask: missing processingTypes
VCPVoiceOverAssetProcessingTask: pixelBuffer is nil
VCPVoiceOverAssetProcessingTask: completionHandler is nil
VCPVoiceOverAssetProcessingTask: invalid processingTypes
VCPVoiceOverAssetProcessingTask: analyze face error: %@
VCPVoiceOverAssetProcessingTask: analyze scene error: %@
Fail to initialize motionFlowAnalyzer
Fail in generating motion flow
Motion flow is null
Invalid VNRequest configuration (%@)
VNRequest must be non-nil
VCPFaceGeometry initWithCoder - vertices data missing
VCPFaceAnchor initWithCoder - unexpected size of transform data
VCPCaptureAnalysis - missing resolution properties for prewarming
Failed to open analysis database for Photo Library (%@)
Specified Photo Library has no URL (<%@>); cannot find analysis database
[DAS QoS] %@: %@ (%@) download %lu bytes
Requested resource exceeds maximum supported size
Resource already in the buffer. Skip downloading.
requestDownloadOfResource: %@
Download progress: %.2f
    Received %llu bytes (Overall: %llu/%llu)
Data received exceeds maximum supported size
Failed to download asset resource (%@)
Successfully downloaded asset resource
Failed to issue resource request
Download resource timed-out
Cancelling download
No faceprint is decoded from PHFace.
  [%@] Processing
[MediaAnalysis][%@]Unable to open movie, skip
  [%@] Analysis cancelled
  [%@] Analysis failed to complete
Failed to create media analysis directory
Successfully loaded FaceTime persistent store
Failed to load FaceTime persistent store
Failed to fetch all FaceTime sessions
Storing FaceTime Session
Cannot create VCPPersonBuilder
---> Canceling VCPBuildPersons
VCPBuildPersons canceled
VCPBuildPersons failed: %@
Cannot create PVPersonPromoter
---> Canceling VCPPromotePersons
Person Processing: Starting Person Promoting
Person Processing: Person Promoting %@
VCPPromotePersons canceled
VCPPromotePersons failed
HomeKit analysis client XPC connection interrupted
HomeKit analysis client XPC connection invalidated
[HomeKitAnalysis] Error connecting to background analysis service
[HomeKitAnalysis] Request %d is %.2f%% complete
[HomeKitAnalysis] Unknown analysis request %d; dropping cancellation request
[HomeKitAnalysis] No active analysis requests; dropping cancellation request
[HomeKit] Error connecting to background analysis service
  Fullfilled content request: %@
  Fullfilled data request: %@
Reachability initialization failed; assuming no connection
Reachability flags invalid; assuming no connection
%sonnected to internet via WiFi/Ethernet
Network reachability flag changed to: %@
Generated faceCropData is nil
faceCropSourceDescriptors is 0
 [%@] facesToPersist: %lu | facesToDelete: %lu
 [%@] Publish facecrop %@ 
Failed to generate faceprint from facecrop %@ - %@
Failed to persist association of face %@ with facecrop %@ - %@
Failed to fetch just-persisted face with local identifier '%@', error: %@
failed to generate faceprint from facecrop %@ - %@
failed to update faceprint of face %@ associated with facecrop %@ - %@
PersonBuilder: Set personBuilderState of faceGroup: %@
Analyzing facecrop: %@
Facecrop %@ is not in a dirty state
Facecrop %@ does not have a payload (image data)
_updateFace failed for facecrop %@: %@
_recordNeedToPersonBuildOnFaceGroupContainingFace failed for facecrop %@: %@
  [%@] No faces detected; skip facecrop generation
 [%@] Facecrop will not be generated for the manual face %@
Library: %lu dirty face crops to analyze
Failed processing dirty facecrop %@ - %@
VCPFaceProcessingDirtyFaceCrops
[Perf] %s: %0.6fs
%-40s  %10s  %10s  %10s  %10s  %10s
  %-38s  %10.6f  %10.6f  %10.6f  %10.6f  %10zu
  [%@] No scene classification result fetched from pre analysis
Scene identifier %u has no name; ignoring
[%@] Asset has no small video derivative; cannot download
VCPPriorityAnalysis - Start initializing
VCPPriorityAnalysis - Finished initializing hand detector
VCPPriorityAnalysis - Finished initializing hand keypoint detector
VCPPriorityAnalysis - Finished initializing gesture recognizer
VCPPriorityAnalysis - gesture score = %f, priority score after thresholding = %f
VCPPriorityAnalysis - Analysis subsampling ratio = %f
VCPPriorityAnalysis - output priority score = %f
song analysis failed %@
VoiceOver analysis client XPC connection interrupted
VoiceOver analysis client XPC connection invalidated
Pixel buffer not IOSurface-backed; dropping analysis request
[VoiceOverAnalysis] Error connecting to Photos background analysis service
[VoiceOverAnalysis] Asset processing request %d has completed
VCPObjectPool failed to allocate object
ImageHandAnalyzer: input image aspectRatio = %f
ImageHandAnalyzer: aspectRatio = %@, queryAspectRatioVal = %@
ImageHandAnalyzer: feasibleShapeIndex = %d
ImageHandAnalyzer: detectorHeight = %d, detectorWidth = %d
Running Home Resident Maintenance task
Canceling Home Resident Maintenance task (%d)
HomeAI request submitted (%d)
[HomeKit] Failed to connect to analysis service (%@)
[HomeKit] VCPHomeKitAnalysisSession initialization fails (%@)
[HomeKit] Client XPC connection interrupted
[HomeKit] Client XPC connection invalidated
copyImageToBGRHandDetectorCallFromSPI
scalerHandDetectorCallFromSPI
Restore clusterer error (ClusterState = %ld): %@
Restored clusterer, ClusterState = %ld
UpdateKeyFaces for: '%@'
could not update key faces for suggestions: %@
Loaded clustererState: %ld
Returning no suggestions because the clusterer is working
suggestions first phase query start
suggestions first phase query end
suggestions middle phase query start (includes face groups for person query)
suggestions middle phase query end
suggestions last phase query start
suggestions last phase query end
Getting suggestions for person: '%@', numberOfToBeConfirmedPersonSuggestions: %lu, numberOfToBeRejectedPersonSuggestions: %lu
Got %lu suggestions for person: '%@', numberOfToBeConfirmedPersonSuggestions: %lu, numberOfToBeConfirmedPersonSuggestions: %lu
Input parameter is empty or nil: '%@'
FaceID Model: Error could not remove person model at %@: %@
Person Processing: Starting Deleting Persons
VCPFaceProcessingDeleteAllVerifiedPersons
Person Processing: Deleting Persons %@
Person Processing: Starting Face Reclustering
VCPFaceProcessingReclusterFacesWithThreshold
Person Processing: Face Clustering %@
Person Processing: Starting Person Building
VCPFaceProcessingBuildPersons
Person Processing: Person Building %@
Person Processing: Starting Person Promotion
VCPFaceProcessingPromotePersons
Person Processing: Person Promotion %@
Attempt to download resource: %@
Choosing asset resource from preferred list: %@
Network is available, filtering list to remove the CPL Thumb, new list is: %@
No resources locally available, returning a downloadable hi-res resource: %@
Error resetting all FaceGroups Person Builder state: %@
Failed to clean up merge candidates. Error: %@
VCPFaceProcessingCleanupMergeCandidates
->->-> Enabling personBuilderMergeCandidates
Warning: Could not update the key faces of some merge candidates %@
Sceneprint task failed (%@)
Did cluster: %s
Reset restore clusterer error (ClusterState = %ld): %@
Reset restored clusterer, ClusterState = %ld
Person Processing: Starting Reset Face Clustering
VCPFaceProcessingResetFaceClusteringState
Person Processing: Reset Face Clustering Done
Person Processing: Starting Face Clustering
VCPFaceProcessingPerformFaceClusteringAndWait
Person Processing: Face Clustering Done
VCPFaceProcessingClusterFacesWithExtendTimeoutBlock
---> Start face cluster (%ld) with clustering status: %@
---> Finished face cluster (%ld) with clustering status: %@
---> Canceling face cluster
VCPFaceProcessingClusterFaces
VCPFaceProcessingClusterFacesIfNecessary
Real-time analysis client XPC connection interrupted
Real-time analysis client XPC connection invalidated
Real-time analysis client XPC connection error
VCPSceneTaxonomy - Failed to load PVSceneTaxonomy
VCPSceneTaxonomy - cannot find scene name for id %d
VCPSceneTaxonomy - cannot find scene id for scene name %@
Removing existing file at path %@
Failed to remove existing file at path %@ (%@)
Failed to create asset writer (%@)
Failed to create asset writer input
Failed to start asset writer
Pixel buffers are not IOSurface-backed; copying
Failed to align face bbox: aligner returned an empty rectange
Failed to align face bbox for faces in image, error: %@
Cannot Merge: %s faceprint, candidateFaceVersion: %u, contextVersion:%u
Cannot Merge: faceprintDistance (%f) < faceprintThreshold (%f)
Cannot Merge: could not get distance between queryFace: '%@' and candidateFace: '%@', error: '%@'
Cannot Merge in final stage: [mutableDetectedFaces containsObject:detectedFace] %d [facesToDelete containsObject:matchedExistingFace] %d
%lu Face(s) merged based on faceprints: %@
%lu Face(s) merged based on geometries (before): %@
%lu Face(s) merged based on geometries (filtered): %@
inferenceHandKeypointCallFromSPI
time=%.2f sharpness=%.2f, faceSharpness=%.2f, cameraM=%.2f, subjectM=%.2f, junk=%.2f, obstr=%.2f, exposure=%.2f, score=%.2f
VCPVideoKeyFrameBlurAnalyzer
VCPVideoKeyFrameFaceQualityAnalyzer
[MediaAnalysis] [VCPVideoMetaAnalyzer] Unknown analysis type %@
  Extreme aspect ratio %f; initialization failed
[MediaAnalysis] Sample at %lld/%d is being extended %0.1fx
Empty reference list for this frame
VCPRateControlSession: codec type '%c%c%c%c' is not supported
VCPRateControlSession: codec type '%c%c%c%c' is not supported on x86
Failed to create VCPRateControlSession
Failed to create private storage
Failed to initilize VCPRateControlSession
%s: Hardware encoder is not available
%s: encoder id is not supported
%s: VCPRateControlSession is created, use_hw: %d
CFDictionaryCreate failed
%s: %@ property = %@
Profile argument not a string
Unsupported profile %s
pixel format %d is not supported
CFArrayCreate (CreateProfileLevelDict) failed!
CFDictionaryCreate (CreateProfileLevelDict) failed!
CFDictionaryCreate failed
(key '%s'): bad
bad (key '%s') (out of range)
unsupported CFTypeID for SetCommonProperty()
unsupported CFTypeID for CopyCommonProperty()
unrecognised property key
Unable to initialize metal session
no sample attachment found
error in ComputeDirtyTiles
Frame %d: Rate control before encoding failed
Frame %d: Compress failed
Failed to get src frame resource from frame pool.
Failed to alloc resources!
Failed to get rc frame resource from frame pool.
Invalid timescale
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/ShazamKit.framework/ShazamKit
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
VCPAudioAnalyzer
VCPSoundDetector
SNResultsObserving
NSObject
VCPAudioClassifier
VCPVideoStabilizer
VCPImageHumanPoseAnalyzer
CMTimerange
VCPSlowmo
VCPProtoLivePhotoKeyFrameResult
NSCopying
VCPBlurAnalyzer
VCPBoundingBox
LegacyConversion
VCPProtoResultLegacyConversionProtocol
VCPProtoMovieBabbleResult
VCPCNNBlock
VCPCNNBlurAnalyzer
VCPCNNBlurAnalyzerEspresso
VCPCNNBlurAnalyzerMPS
VCPCNNConvBlock
VCPCNNConvBlockGPU
VCPCNNConvBlockScalar
VCPCNNConvBlockVector
VCPCNNData
VCPCNNDataGPU
VCPCNNEspressoContext
VCPCNNFaceLandmarkDetector
VCPCNNFaceLandmarkDetectorMPS
VCPCNNFlattenBlock
VCPCNNFullConnectionBlock
VCPCNNFullConnectionBlockGPU
VCPCNNFullConnectionBlockScalar
VCPCNNGazeAnalysis
VCPVideoGyroStabilizer
VCPCNNHandKeypointsDetector
VCPCNNMetalContext
VCPHumanPoseVideoRequest
VCPCNNModel
VCPCNNModelEspresso
VCPCNNPetsDetector
VCPProtoMovieApplauseResult
VCPCNNPetsDetectorEspresso
VCPCNNPoolingBlock
VCPCNNPoolingBlockGPU
VCPCNNPoolingBlockScalar
VCPVideoProcessor
PVPersonProtocol
VCPCNNPoolingBlockVector
VCPCNNPoseEstimator
VCPVideoProcessorSession
VCPProtoLivePhotoKeyFrameFaceResult
VCPCNNPoseEstimatorMPS
VCPCNNSmileDetector
VCPCNNSmileDetectorMPS
VCPDatabaseBatchIterator
VCPDatabaseReader
VCPHuman
VCPDeviceInformation
VCPProtoMovieStabilizationResult
VCPProtoMovieHumanActionResult
VCPEdgeDetector
VCPEffectsAnalyzer
VCPImageExposurePreAnalyzer
VCPTimer
VCPExifAnalyzer
VCPFace
VCPFaceDetectionRange
VCPTimeMeasurement
VCPEvent
NSSecureCoding
NSCoding
VCPVisualIntelligenceAnalysisService
VCPHomeFaceIdentificationTask
PVPhotoLibraryProtocol
VCPFingerprint
VCPFaceAnalyzer
VCPFrameScoreFilter
FullAnalysis
VCPProtoLivePhotoKeyFrameStillResult
VCPProtoImageSceneprintResult
VCPFullVideoAnalyzer
VCPGaborFilter
VCPHoughTransform
VCPCNNPersonKeypointsDetector
VCPImageAnalyzer
VCPImageBlurAnalyzer
VCPMABaseTask
VCPMADTaskProtocol
VCPImageCompositionAnalyzer
VCPImageConverter
VCPImageDescriptor
VCPDistanceDescriptorProtocol
VCPImageExposureAnalyzer
VCPAnalysisProgressQuery
VCPImageFaceDetector
VCPImageFaceExpressionAnalyzer
VCPVideoStabilizationAssetProcessingTask
VCPImageFaceQualityAnalyzer
VCPImageLivePhotoBlurAnalyzer
VCPPhotosQuickFaceIdentificationLibraryProcessingTask
VCPKeypoint
VCPPersonObservation
VCPHandObservation
VCPImageManager
VCPProtoMovieHumanPoseResult
PFPhotosFaceRepresentation
VCPPhotosPersistenceDelegateAdditions
MediaAnalysis
VCPMergeCandidatePair
VCPPhotosPersistenceDelegate
PVPersistenceDelegate
PVPersonPromoterDelegate
VCPCNNPersonDetector
VCPImagePetsAnalyzer
VCPImageQualityAnalyzer
VCPImageSaliencyAnalyzer
VCPImageSaliencyAnalyzerFull
VCPSceneProcessingImageManager
VCPPreAnalyzer
VCPInterAssetAnalyzer
VCPShareSheetAssetProcessingTask
VCPMAImageProcessingTaskProtocol
VCPJunkAnalyzer
VCPLightMotionAnalyzer
VCPLightVideoAnalyzer
VCPLogManager
VCPCNNHandsDetectorEspresso
VCPMovieCurationAnalyzer
VCPVideoKeyFrameResult
VCPMovieHighlightResult
VCPMovieCurationResults
VCPMovieHighlight
VCPExpressionSegment
VCPMovieHighlightAnalyzer
VCPMediaAnalysisServerProtocol
VCPMediaAnalysisClientProtocol
VCPMediaAnalysisService
FaceSuggestions
PersonBuilderAndPromoter
InternalTools
VCPStorageServiceProtocol
VCPMediaAnalyzer
VCPMetaSegment
VCPMetaTrackDecoder
PVFaceProtocol
VCPMovieAnalyzer
VCPProtoImageHumanPoseResult
PVFetchResultProtocol
NSFastEnumeration
PHAssetResource
VCPMediaAnalysis
Exif
MediaAnalysisResults
MediaAnalysisPauseResume
VCPLivePhotoKeyFrameAnalyzer
VCPPHFaces
VCPPhotosQuickFaceIdentificationManager
MediaAnalysisPhoto
MediaAnalysisMovie
MediaAnalysisSceneProcessing
MovieResource
VCPPhotoAnalyzer
VCPSceneprintDescriptor
VCPSceneChangeAnalyzer
VCPSceneChangeSegment
VCPVideoPixelStabilizer
VCPTaskProcessingClientProtocol
VCPTaskProcessingServerProtocol
VCPTaskProcessingService
VCPVoiceOverAssetProcessingTask
VCPMotionFlowSubtleMotionAnalyzer
VCPVideoProcessorNode
VCPVanishingPointDetector
VCPActionAnalyzer
VCPAsset
Image
LivePhoto
Movie
VCPFaceGeometry
VCPFaceAnchor
VCPCaptureAnalysisSession
VCPClientDatabaseManager
VCPContentAnalysis
VCPDefaultPhotoLibraryManager
VCPDownloadManager
VCPVoteStats
VCPFaceRecognitionTask
VCPFullAnalysisURLProcessingTask
VCPFaceTimeFace
VCPProcessingStatusEntry
VCPCNNFastGestureRecognition
NSManagedObject
VCPProtoMovieSceneprintResult
VCPFaceTimePersistentStore
VCPFaceTimeSession
VCPProtoMoviePetsResult
VCPFrameAnalysisStats
VCPHomeKitAnalysisServerProtocol
VCPHomeKitAnalysisClientProtocol
VCPHomeKitAnalysisService
Client
Resident
VCPInMemoryAVAsset
AVAssetResourceLoaderDelegate
VCPInternetReachability
VCPGeneralCanceller
VCPFaceCropSourceDescriptor
VCPFaceCropGenerator
VCPFaceCropManager
VCPPhotosAsset
VCPPriorityAnalysis
VCPProtoAssetAnalysis
VCPProtoBounds
CGRect
VCPImageMotionFlowAnalyzer
VCPSongDetector
VCPProtoClassification
VCPProtoImageBlurResult
VCPProtoImageCompositionResult
VCPProtoImageExposureResult
VCPLoudnessAnalyzer
VCPProtoImageFaceResult
VCPProtoImageFeatureResult
VCPProtoImageJunkResult
VCPProtoImagePetsFaceResult
VCPVoiceOverServerProtocol
VCPVoiceOverClientProtocol
VCPVoiceOverService
VCPProtoMovieLaughterResult
VCPProtoImagePetsResult
VCPHandPoseVideoRequest
VCPLoaned
VCPObjectPool
VCPProtoImageSaliencyResult
VCPProtoImageShotTypeResult
VCPProtoLine
VCPProtoMovieCheeringResult
CGPoint
VCPProtoLivePhotoEffectsRecipe
VCPProtoLivePhotoEffectsResult
VCPHumanPoseImageRequest
VCPProtoLivePhotoFrameInstruction
VCPProtoLivePhotoRecommendationResult
VCPProtoLivePhotoSharpnessResult
VCPImageHandsAnalyzer
VCPHomeResidentMaintenanceTask
VCPProtoLivePhotoVariationParams
VCPProtoMovieActivityLevelResult
VCPProtoMovieCameraMotionResult
VCPHomeKitAnalysisSessionServerProtocol
VCPHomeKitAnalysisSessionClientProtocol
VCPHomeKitAnalysisSession
VCPHomeKitSessionExportedObject
VCPHomeKitMotionAnalyzer
VCPProtoMovieClassificationResult
VCPHandPoseImageRequest
VCPProtoMovieFaceprintResult
VCPRequest
VCPProtoMovieFaceResult
VCPProtoMovieFeatureResult
PVAssetProtocol
VCPProtoMovieFineSubjectMotionResult
VCPProtoMovieHighlightResult
VCPProtoMovieInterestingnessResult
PVMomentProtocol
VCPImageHumanPoseAnalyzerTopDown
VCPProtoMovieLoudnessResult
VCPProtoMovieMovingObjectResult
VCPProtoMovieMusicResult
VCPProtoMovieObstructionResult
VCPCNNHandsDetector
VCPFaceProcessingServiceWorker
VCPFaceUtils
VCPFaceVisionIntegrating
PVVisionIntegrating
VCPPersonBuilder
VCPVideoHumanActionAnalyzer
VCPPhotosSceneprintAssetProcessingTask
VCPProtoMovieOrientationResult
VCPProtoMoviePreEncodeResult
VCPProtoMovieQualityResult
VCPProtoMovieSaliencyResult
VCPProtoMovieSceneResult
VCPProtoMovieSubjectMotionResult
VCPFaceClusterer
PVFaceGroupProtocol
VCPProtoMovieSummaryResult
VCPProtoMovieUtteranceResult
VCPProtoMovieVoiceResult
VCPProtoPoint
VCPProtoMoviePetsFaceResult
VCPProtoTime
CMTime
VCPProtoTimeRange
CMTimeRange
VCPProtoVideoKeyFrame
VCPCallerIdentificationResult
VCPRealTimeAnalysisServerProtocol
VCPRealTimeAnalysisClientProtocol
VCPRealTimeAnalysisService
VCPRTLandmarkDetector
VCPProtoMovieStabilizationRecipe
VCPSceneTaxonomy
VCPSegment
VCPMovieAssetWriter
VCPSharedInstanceManager
VCPTrimAnalyzer
VCPURLAsset
VCPVideoChatAnalysis
VCPVideoActivityAnalyzer
VCPCompactResult
VCPVideoActivityDescriptor
VCPVideoHumanActionClassifier
VCPProtoMovieSubtleMotionResult
VCPVideoAnalyzer
VCPVideoFaceDetector
VCPVideoFaceMeshAnalyzer
VCPFacePair
VCPFaceMerger
VCPPetsRegion
VCPVideoPetsAnalyzer
VCPVideoFacePoseAnalyzer
BackwardCompatability
VCPVideoFullFaceDetector
VCPCNNHandKeypointsDetectorEspresso
VCPVideoGlobalAnalyzer
VCPVideoKeyFrame
VCPVideoKeyFrameAnalyzer
VCPVideoLightFaceDetector
VCPVideoMetaAnalyzer
VCPVideoMetaFaceAnalyzer
VCPVideoMetaFocusAnalyzer
VCPVideoMetaFocusSegment
VCPVideoMetaLensSwitchAnalyzer
VCPVideoMetaLivePhotoMetaAnalyzer
VCPVideoMetaMotionAnalyzer
VCPVideoMetaMotionSegment
VCPVideMetaOrientationAnalyzer
VCPVideoObjectTracker
VCPSaliencyRegion
VCPVideoSaliencyAnalyzer
VCPClassification
VCPVideoSceneClassifier
VCPVideoTrackDecoder
VCPVideoTrackStandardDecoder
VCPVideoTrackSubsamplingDecoder
VCPVideoTrackSyncDecoder
VCPVoiceDetector
VCPVoiceDetectorV2
Face
CoreDataProperties
VCPCtrTracker
VCPBaseTracker
init
detector
initWithTypes:
dealloc
dictionaryWithObjects:forKeys:count:
setupWithSample:andSampleBatchSize:
processAudioSamples:timestamp:
finalizeAnalysisAtTime:
dictionary
vcp_enabledTracksWithMediaType:
countByEnumeratingWithState:objects:count:
timeRange
trackID
initWithAsset:error:
audioFormatRequirements
assetReaderTrackOutputWithTrack:outputSettings:
addOutput:
startReading
copyNextSampleBuffer
setupWithSample:
processSampleBuffer:
status
results
addEntriesFromDictionary:
voiceDetections
initWithAnalysisTypes:forStreaming:
analyzeAsset:cancel:results:
analyzeSampleBuffer:
.cxx_destruct
_inputBuffer
_audioTimestamp
_audioBufferList
_sampleBatchSize
_voiceDetector
_audioClassifier
_loudnessAnalyzer
_songDetector
_bufferedSamples
_initialized
array
objectForKey:
numberWithFloat:
addObject:
confidence
addDetectionFromTime:toTime:confidence:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
initWithTrackStart:threshold:resultsKey:
_results
_activeStart
_activeEnd
_length
_sampleRate
_trackStart
_activeConfidence
_threshold
_minDetections
_resultsKey
initStandardFormatWithSampleRate:channels:
initWithFormat:
initWithPCMFormat:frameCapacity:
setFrameLength:
arrayWithObjects:count:
initWithSoundIdentifier:
objectForKeyedSubscript:
floatValue
addRequest:withObserver:error:
frameLength
mutableAudioBufferList
analyzeAudioBuffer:atAudioFramePosition:
_analysisTypes
_SNAnalyzer
_pcmBuffer
_framePosition
_detectors
enable
isEnabled
vcp_isShortMovie
vcp_mediaAnalysisBundle
resourceURL
URLWithString:relativeToURL:
configForAspectRatio:
sharedModel:
numberWithBool:
initWithParameters:inputNames:outputNames:properties:
createModelWithHeight:srcWidth:
sharedManager
sharedInstanceWithIdentifier:andCreationBlock:
outputBlob
objectAtIndexedSubscript:
setObject:atIndexedSubscript:
numberWithInt:
count
intValue
flagsFromKeypoints:withMinConfidence:
setObject:forKeyedSubscript:
numberWithUnsignedInteger:
espressoForward:
parsePersons:width:height:
processPersons:width:height:
prepareModelWithConfig:
inputBlob
copyImage:toData:withChannels:
removeAllObjects
reInitModel
createInput:withBuffer:modelInputHeight:modelInputWidth:
generateHumanPose:
saveKeypoints
initWithKeypointsOption:aspectRatio:lightweight:forceCPU:sharedModel:flushModel:
updateModelForAspectRatio:
preferredInputFormat:height:format:
analyzePixelBuffer:flags:results:cancel:
trackingMode
setTrackingMode:
_modelEspresso
_netFileUrl
_inputData
_resConfig
_persons
_saveKeypoints
_inputWidth
_inputHeight
_heatmapNms
_forceCPU
_sharedModel
_flushModel
_trackingMode
convertToOriginalTimeFromScaledTime:forExport:
vcp_convertToOriginalTimerangeFromScaledTimerange:
scaleTimeRange:toDuration:
vcp_scaleSlowmoTimeRange:withTimeMapping:inComposition:
hasSlowMotionAdjustments
initWithVideoAsset:videoAdjustments:
composition
insertTimeRange:ofAsset:atTime:error:
rampDown
rampUp
slowMotionRate
computeRampToTargetRate:forExport:outTimeSteps:outIntermediateRates:
slowMotionRampInRangeForExport:
slowMotionRampOutRangeForExport:
slowMotionTimeRange
vcp_scaleRampWithIntervals:andRates:inSlowmoTimerange:withTimeMapping:inComposition:
tracks
removeTrack:
vcp_fullFrameSize
vcp_cleanApertureRect
objectAtIndex:
dictionaryRepresentation
stringWithFormat:
numberWithDouble:
setObject:forKey:
initWithCapacity:
addFaceResults:
faceResultsCount
clearFaceResults
faceResultsAtIndex:
allocWithZone:
copyWithZone:
faceResultsType
setGlobalQualityScore:
setHasGlobalQualityScore:
hasGlobalQualityScore
setContentScore:
setHasContentScore:
hasContentScore
readFrom:
writeTo:
copyTo:
mergeFrom:
timestamp
setTimestamp:
qualityScoreForLivePhoto
setQualityScoreForLivePhoto:
visualPleasingScore
setVisualPleasingScore:
overallFaceQualityScore
setOverallFaceQualityScore:
exposureScore
setExposureScore:
penaltyScore
setPenaltyScore:
textureScore
setTextureScore:
sharpness
setSharpness:
faceResults
setFaceResults:
globalQualityScore
contentScore
_timestamp
_contentScore
_exposureScore
_faceResults
_globalQualityScore
_overallFaceQualityScore
_penaltyScore
_qualityScoreForLivePhoto
_sharpness
_textureScore
_visualPleasingScore
_has
setMinX:
setMinY:
setMaxX:
setMaxY:
initWithXYAndSize:y:width:height:confidence:
intersect:
union:
area
initWithCenterAndSize:y:width:height:confidence:
computeIntersectionOverUnion:
getCGRectWithClipWidth:height:
flag
setFlag:
_minX
_maxX
_minY
_maxY
_flag
timeRangeWithCMTimeRange:
timeRangeValue
resultFromLegacyDictionary:
inputSize
setInputSize:
outputSize
setOutputSize:
input
setInput:
setOutput:
generateOutput
setGenerateOutput:
_inputSize
_outputSize
_output
_generateOutput
_executedOnGPU
analyzer
sdof
objectPoolWithAllocator:
initWithRevision:
sharedModelPoolWithRevision:
getObject
object
getRevision
calculateScoreFromNetworkOutputV2:
calculateScoreFromNetworkOutput:outChannel:outHeight:outWidth:textureness:contrast:imgWidth:
copyBufferFrom:fromStride:toPtr:toStride:toWidth:toHeight:
prepareModelForSourceWidth:andSourceHeight:
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:
computeSharpnessScore:textureness:contrast:imgWidth:cancel:
_srcWidth
_srcHeight
dynamicForward:paramFileUrl:cancel:
_modelURL
supportGPU
supportVectorForward
convBlockClass:
initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
cnnDataWithGPUContext:
cnnData
setSize:
allocBuffers:
size
convBlockWithFilterSize:filterNum:chunk:reLU:padding:
convBlockWithFilterSize:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
constructBlock:context:
useGPU
_filterSize
_filterNum
_filter
_bias
_chunk
_reLU
_padding
_padSize
_stride
_groups
_batchNorm
isFilterSizeSupported:
readFromDisk:quantFactor:
data
straightForwardForChunkFour
chunkFourForward
forward
CalculateDotProductOfChunk
cnnDataClass
initWithGPUContext:
initWithParameters:height:width:context:
bufferAllocCPU
cnnDataWithPlane:height:width:context:
randInit
convertCPUData2GPU
convertGPUData2CPU
reallocGPUTemporalBuffers
copyImage:withChunk:
normalization
softmax
setData:
isInputOutput
setIsInputOutput:
context
setContext:
_isInputOutput
_size
_data
_context
createContextWithForceCPU:
sharedEspressoContext:
initWithForceCPU:shared:
espressoContext
_espressoContext
computeLandmarks:
analyzeFrame:withFaceBounds:
_landmarks
_modelLandmarks
initWithParameters:
initWithParameters:NeuronType:
_weight
_numNeurons
_neuronType
readWeightsBias:weights:bias:inputDim:outputDim:quantFactor:
loadWeights:inputDim:outputDim:quantFactor:
copyImage:toData:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:faceBounds:
detectEyeOpennessForFace:inBuffer:eyeOpenness:
initWithMetadata:sourceSize:cropRect:
storeAnalytics:isLivePhoto:
init:sharedModel:modelName:
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:offset:
generateHandKeypoints:keypointConfidence:offset:
cvtHeatmaps2Keypoints:outHeight:outWidth:inHeight:inWidth:outChannel:keypoints:keypointConfidence:offset:
initNewContext:
execute
device
setDevice:
commandQueue
setCommandQueue:
commandBuffer
setCommandBuffer:
_device
_commandQueue
_commandBuffer
initWithOptions:
location
parseResults:observations:
associatePersons:withExisingPersons:
arrayWithArray:
personID
removeLastObject
insertObject:atIndex:
computeActionScoreForPerson:
errorWithDomain:code:userInfo:
keypoints
normDistance:point2:
computeVarWithID:index1:index2:interVar:intraVar:
setRelativeActionScore:
setAbsoluteActionScore:
setPersonID:
bodyDistance:withBodyB:
removeObject:
processSampleBuffer:withOptions:error:
preferredInputSizeWithOptions:error:
preferredPixelFormat
cleanupWithOptions:error:
_personID
_preferredWidth
_preferredHeight
_preferredFormat
_analyzer
_existingPersons
_existingPersonsArray
_blocks
_quantFactor
boolValue
path
UTF8String
getPlanPhase
isEqualToString:
prepareModelInput:
prepareModelInputs:
numberWithUnsignedLong:
espressoForwardInputs:
normalization:
getEspressoContext
inputBlobs
setInputBlobs:
outputBlobs
setOutputBlobs:
setInputBlob:
setOutputBlob:
resConfig
.cxx_construct
_net
_plan
_inputNames
_outputNames
_inputBlobs
_outputBlobs
_inputBlob
_outputBlob
postProcBoxes:maxNumRegions:
detector:
petsDetection:petsRegions:petsFaceRegions:cancel:
setTimeRange:
setConfidence:
_confidence
_timeRange
boundsWithCGRect:
rectValue
generatePetsRegions:outHeight:outWidth:boxes:faceBoxes:maxNumRegions:
initWithMaxNumRegions:
createModel:srcWidth:
generatePetsBoxes:faceBoxes:cancel:
initWithParameters:poolY:chunk:
poolingBlockWithPoolX:poolY:chunk:
vcp_imageOrientation
progressHandler
_analyzeWithStart:andDuration:error:
initWithURL:
analyzeWithStart:andDuration:error:
_session
setVerifiedType:
setManualOrder:
keyFace
anonymizedName
favorite
setIsVerified:
pv_addMergeCandidatePersons:
personLocalIdentifiers
isVerified
manualOrder
dataUsingEncoding:allowLossyConversion:
base64EncodedStringWithOptions:
completionHandler
validateConfiguration:withError:
request
nodeWithRequest:andConfiguration:
orientation
initWithCMSampleBuffer:orientation:options:
containsObject:
frameInterval
timeInterval
shouldProcessSampleWithTimeRange:atSamplingInterval:
performRequests:error:
processSampleBuffer:withEndTime:error:
copy
addRequest:withConfiguration:error:
removeRequest:error:
processSampleBuffer:error:
flushWithEndTime:error:
setOrientation:
_queue
_nodes
_modified
_startTime
_nextSampleBuffer
_frameCount
_orientation
setFaceBounds:
faceBounds
_faceBounds
initWithParameters:useGPU:
getGPUContext
add:
fcBlockWithNumNeurons:NeuronType:
prepareNetworkFromURL:withInputSize:
forward:
output
getInputBuffer
computePoseScore:
_model
_input
computeSmileScore:
initWithDatabaseReader:forAssets:resultsTypes:batchSize:
nextBatch
localIdentifier
subarrayWithRange:
queryAnalysesForAssets:withTypes:
iteratorForAssets:withDatabaseReader:resultTypes:batchSize:
next
asset
analysis
_reader
_assets
_resultsTypes
_batchSize
_idxLast
_idxCurrent
_batchAnalyses
_asset
_analysis
vcp_mediaAnalysisDatabaseFilepath
shouldQueryInternalFields
stringWithString:
parseHeader:startColumn:analysis:
parseResults:typeColumn:dataColumn:results:
closeDatabase
openDatabase
executeDatabaseBlock:
queryHeaderForAsset:analysis:assetId:
queryResultsForAssetId:analysis:
queryResultsForAssetId:withTypes:analysis:
queryHeadersForAssets:analyses:idMap:
queryResultsForAssets:withTypes:batchResults:
entryWithLocalIdentifier:andTaskID:andStatus:andAttempts:andNextRetryDate:
queryBlacklistedLocalIdentifiers
queryAnalysisPropertiesForAsset:
queryLocalIdentifiersForTaskID:withStatus:
_sqlSerialQueue
_filepath
dateWithTimeIntervalSinceReferenceDate:
propertyListWithData:options:format:error:
timeIntervalSinceReferenceDate
flags
setFlags:
bounds
setBounds:
_flags
_bounds
canRenderVariation
isHomePod
analysisConfidence
setAnalysisConfidence:
gyroStabilization
setGyroStabilization:
_analysisConfidence
_gyroStabilization
absoluteScore
setAbsoluteScore:
relativeScore
setRelativeScore:
humanScore
setHumanScore:
_absoluteScore
_humanScore
_relativeScore
noiseReduction:sigma:imageFiltered:
gradientEstimation:width:height:gradient:gradientMag:
isInImage:width:height:
initWithImage:edgeMap:width:height:widthExtension:heightExtension:
detectWithSigma:lowThreshold:highThreshold:
_widthPadded
_heightPadded
_width
_height
_widthExt
_heightExt
_gradient
_image
_imageFiltered
_nonMaxSuppressed
_gradientX
_gradientY
_gradientMag
_edgeMap
initWithFlagHasFaceOrPet:
usePHAssetScene
initWithAnalysisResults:
analyzeAsset:onDemand:cancel:statsFlags:results:
_hasFaceOrPet
initWithIntervalNanoseconds:isOneShot:andBlock:
timerWithInterval:unit:oneShot:andBlock:
destroy
timerWithIntervalSeconds:isOneShot:andBlock:
_source
_active
_isOneShot
transformUprightAboutTopLeft:
numberWithInteger:
addFaceResults:flags:
initWithProperties:forAnalysisTypes:
analyzeAsset:results:
_properties
_requestedAnalyses
faceBounds:height:
flagsForOrientation:width:height:
faceBoundsWithTransform:height:transform:
leftEyeClosed
setLeftEyeClosed:
rightEyeClosed
setRightEyeClosed:
smile
setSmile:
setYaw:
setTrackID:
faceQuality
setFaceQuality:
observation
setObservation:
_leftEyeClosed
_rightEyeClosed
_smile
_trackID
_faceQuality
_yaw
_observation
start
setStart:
last
setLast:
position
setPosition:
faceID
setFaceID:
_position
_faceID
_start
_last
stop
elapsedTimeSeconds
started
_timebase
_elapsedTimeSeconds
encodeObject:forKey:
encodeBool:forKey:
decodeObjectOfClass:forKey:
decodeBoolForKey:
appendFormat:
appendString:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
startDate
setStartDate:
endDate
setEndDate:
timeZone
setTimeZone:
allDay
setAllDay:
title
setTitle:
setLocation:
setUrl:
notes
setNotes:
_allDay
_startDate
_endDate
_timeZone
_title
_location
_url
_notes
service
requestImageProcessingTask:forPixelBuffer:withOptions:andCompletionHandler:
requestImageProcessingTask:forAssetURL:withOptions:andCompletionHandler:
requestShareSheetProcessingForPixelBuffer:withOptions:andCompletionHandler:
requestShareSheetProcessingForAssetURL:withOptions:andCompletionHandler:
_service
initWithFaceCrop:andCompletionHandler:
configureRequest:withRevision:
initWithData:options:
_faceCropData
setWantsIncrementalChangeDetails:
_defaultFetchOptions
_defaultAssetPropertySets
processInfo
processName
urlForApplicationDataFolderIdentifier:
URLForDirectory:inDomain:appropriateForURL:create:error:
fileExistsAtPath:isDirectory:
_phPeopleSortDescriptors
setPersonContext:
fetchAssetsForPersons:options:
fetchPersonsForAssetCollection:options:
fetchPersonsGroupedByAssetLocalIdentifierForAssets:options:
_defaultFacePropertySets
_phFaceSortDescriptors
pv_fetchFacesForPersonLocalIdentifiers:inMoment:
fetchedObjectIDs
andPredicateWithSubpredicates:
fetchFacesGroupedByAssetLocalIdentifierForAssets:options:
momentSortDescriptors
fetchMomentsWithOptions:
fetchAssetCollectionsWithLocalIdentifiers:options:
fetchMomentsForAssetsWithLocalIdentifiers:options:
_defaultAssetFetchOptions
fetchAssetsForFaceGroups:options:
_progressFromWorkerStatesDictionary:
requestTotalProgressCountsForWorkerType:states:completion:
fetchAssetCollectionsWithType:subtype:options:
setIncludeAssetSourceTypes:
pv_performChangesAndWait:error:
pv_persistentStorageDirectoryURL
pv_fetchPersonsWithLocalIdentifiers:
pv_fetchPersonsWithType:
pv_fetchPersonsInMoment:
pv_fetchCandidatePersonsForPerson:
pv_fetchInvalidCandidatePersonsForPerson:
pv_fetchPersonsGroupedByAssetLocalIdentifierForAssets:
pv_numberOfFacesWithFaceprints
pv_fetchFacesWithLocalIdentifiers:
pv_fetchFacesForPerson:
pv_fetchFacesForPerson:inMoment:
pv_fetchFacesForFaceGroup:
pv_fetchFacesGroupedByAssetLocalIdentifierForAssets:
pv_fetchMoments
pv_fetchMomentsWithLocalIdentifiers:
pv_fetchMomentsForPerson:
pv_fetchMomentsForAssetsWithLocalIdentifiers:
pv_fetchAssetsWithLocalIdentifiers:
pv_fetchAssetsInMoment:
pv_fetchAssetsForPerson:
pv_fetchAssetsForFaceGroup:
pv_fetchFaceGroups
pv_fetchFaceGroupsForPerson:
pv_fetchInvalidAssetIdentifiersForCommonComparison
pv_lastAssetDate
initWithMaster:adjusted:
master
adjusted
fingerprintWithMaster:adjusted:
isEqualToFingerprint:
_master
_adjusted
initWithContext:
globalSession
releaseCachedResources
pointCount
normalizedPoints
setRevision:
setMetalContextPriority:
setPreferBackgroundProcessing:
_allowANE
defaultANEDevice
setProcessingDevice:
_configureRequest:withRevision:
boundingBox
landmarks
leftEye
_addRegion:toBoundingBox:
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
outerLips
innerLips
_rectFromMappingNormalizedRect:toBounds:
setBlurDeterminationMethod:
setMaximumIntermediateSideLength:
setRegionOfInterest:
warnings
addObjectsFromArray:
sourceWidth
sourceHeight
isLeftEyeClosed
isRightEyeClosed
hasSmile
blurScore
initWithLocalIdentifier:
setSourceWidth:
setSourceHeight:
setManual:
setFaceAlgorithmVersion:
setCenterAndSizeFromNormalizedFaceRect:
uuid
roll
setRoll:
faceCaptureQuality
doubleValue
setQuality:
pointFromNormalizedPoint:inBounds:
setLeftEyeX:
setLeftEyeY:
setRightEyeX:
setRightEyeY:
setMouthX:
setMouthY:
pose
computeYawPitchRollFromPoseMatrix:outputYaw:outputPitch:outputRoll:
setPoseYaw:
expressionsAndConfidence
setHasSmile:
faceTorsoprint
faceprint
serializeStateAndReturnError:
faceprintWithFaceprintData:faceprintVersion:
setFaceprint:
faceAttributes
ageCategory
label
identifier
setAgeType:
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
setSexType:
eyesCategory
setEyesState:
smilingCategory
setSmileType:
faceHairCategory
setFacialHairType:
hairColorCategory
setHairColorType:
baldCategory
setBaldType:
glassesCategory
setGlassesType:
eyesState
setIsLeftEyeClosed:
setIsRightEyeClosed:
_createFaceRectanglesRequest:andFaceprintRequest:
_createFaceRectanglesRequest:andFaceLandmarksRequest:andFaceExpressionsRequest:andFacePoseRequest:andFaceprintRequest:andClassifyFaceAttributesRequest:andFaceCaptureQualityRequest:
_checkAnalysisRequests:forTooSmallFaceObservations:withAnalysisResults:
_createBlurRequests:andExposureRequests:forFaceObservations:
firstObject
getPVFaceFromVNFaceObservation:withSourceWidth:andSourceHeight:andVisionRequests:andAlgorithmVersion:andError:
setIsTooSmall:
setBlurScore:
_qualityMeasureForFace:countOfFacesOnAsset:
setQualityMeasure:
photoLibrary
setPhotoLibrary:
setIncludeNonvisibleFaces:
fetchFacesInAsset:options:
arrayWithCapacity:
pvFaceFromPHFace:copyPropertiesOption:
predicateWithFormat:
setPredicate:
setMinimumVerifiedFaceCount:
fetchPersonsWithLocalIdentifiers:options:
mutableCopy
removeObjectForKey:
_pvFaceArrayFromAsset:
valueForKey:
null
predicateWithBlock:
filteredArrayUsingPredicate:
_verifiedPersonsFetchResultWithLocalIdentifiers:andPhotoLibrary:andError:
personLocalIdentifier
setPersonLocalIdentifier:
mergeExistingFaces:withDetectedFaces:forImage:
imageURL
initWithURL:orientation:options:session:
imageData
initWithData:orientation:options:session:
assetWidth
assetHeight
_performAnalysis:withRequestHandler:options:sourceWidth:sourceHeight:
_refineAnalysis:forAsset:andImage:
analyzeWithImage:andAsset:andOptions:andResults:
_faceMerger
_processingGroup
_processingQueue
_sessionPool
_numFilterTabs
_scoreArray
_distanceVariance
_diffVariance
_numOfScores
vcp_isLivePhoto
vcp_fullAnalysisTypes
vcp_fullAnalysisTypesForAssetType:
textureness
setTextureness:
hasFlash
setHasFlash:
stillTime
setStillTime:
_stillTime
_textureness
_hasFlash
setSceneprintBlob:
sceneprintBlob
_sceneprintBlob
useSceneprintInSceneAnalysis
initWithFilterTabs:distanceVariance:diffVariance:
vcp_orientation
preferredTransform
initWithFrameWidthInMb:heightInMb:
setVideoActivityDescriptor:
videoActivityDescriptor
analyzeFrame:withTimestamp:andDuration:properties:flags:
seedAnalyzersWithPixelBuffer:startTime:
analyzePixelBuffer:withFrame:withTimestamp:andDuration:hasSubtleScene:
detectedFaces
estimateExpressionScore:encodeStats:frameWidth:frameHeight:
isStableMetaMotion:
frameExpressionScore
setFrameExpressionScore:
salientRegionsFromPixelBuffer:
reviseFrameTrackScore:saliencyRegions:
processAndEstimateQualityScore:
process:
ExtractActivityDescriptorFromStats:
setCameraMotionScore:
setSubjectActionScore:
setInterestingnessScore:
setColorfulnessScore:
setFrameProcessedByVideoAnalyzer:
setSubMbMotionAvailable:
computeExposureScoreOfFrame:
processFrameScore:validScore:
interestingnessScore
addSceneAnalysisResult:to:optional:
estimateQualityScore:
addResult:to:forKey:optional:
bound
initWithTransform:
initWithVideoTrack:withMetaOrientation:withPrivateResults:withFrameStats:isTimelapse:isIris:irisPhotoOffsetSec:irisPhotoExposureSec:slowMoRate:faceDominated:
prepareVideoAnalysisByScenes:
prepareLivePhotoAnalysisByScenes:
analyzeFrame:withTimestamp:andDuration:flags:
finishAnalysisPass:
privateResults
getSceneSwichFrequency
setNextCaptureFrame:
qualityScore
setQualityScore:
actionScore
setActionScore:
obstructionScore
setObstructionScore:
trackingScore
setTrackingScore:
objectsMotion
globalMotion
_encodeAnalysis
_preencodeAnalysis
_obstructionAnalysis
_sceneAnalysis
_motionFilter
_metadataAnalysis
_irisAnalysis
_frameBuffer
_idealHistogram
_isTimelapse
_isIris
_isSlowMo
_finalized
_hasInterestingScene
_isCaptureAnalysis
_privateResults
_videoFrameAnalysis
_trackScoreFilter
_metaMotionResults
_faceDominated
_subtleMotionAnalyzer
_sceneType
_qualityScore
_actionScore
_interestingnessScore
_obstructionScore
_trackingScore
_objectsMotion
_globalMotion
createGaborFilterKernel:sigmaX:sigmaY:lambda:thetaInDegree:phaseInDegree:
initWithNumberOfScales:numOfOrientations:width:height:
processWithFilterScaleIdx:orientIdx:srcImage:outImage:width:height:
_filterBanks
_numScales
_numOrientations
_num
Transform
integerValue
sortUsingComparator:
initWithEdgeMap:mapWidth:mapHeight:angleStep:
DetectLinesWithThreshold:output:
_mapWidth
_mapHeight
_accumulator
_accWidth
_accHeight
_accHalfHeight
_angleStep
_verbose
minX
minY
maxX
maxY
createInput:withBuffer:cnnInputHeight:cnnInputWidth:box:
parseKeypoints:
initWithForceCPU:sharedModel:
analyzeFrame:withBox:keypoints:
processTile:results:cancel:
aggregateTileResults:tileRect:imageSize:landscape:results:
analyzePixelBufferInTiles:results:cancel:
calculateTextureness:height:width:sdof:result:
analyzerWithRevision:
setSdof:
initWithFaceResults:sdof:revision:
prepareFaceBlurModel:
scaleRegion:ofImage:toData:withWidth:andHeight:
getFaceScoreFromOutput:ratio:
computeSharpnessScore:forObjects:inImage:
computeRegionSharpness:width:height:stride:
estimateDistance:prevHomography:
analyzePixelBuffer:flags:withPreAnalysisScore:results:cancel:
computeLocalSharpness:
spatialPooling
computeCNNBasedSharpness:sharpnessScore:textureScore:contrast:cancel:
computeCNNFaceSharpness:result:cancel:
computeSharpnessScore:forFacesInImage:
computeGyroSharpness:
initWithFaceResults:sdof:
setGyroSharpnessParam:homographyResults:livePhotoStillDisplayTime:imageExposureTime:
_sharpnessBlocks
_faces
_framePTSResults
_homographyResults
_faceModel
_faceInput
_livePhotoStillDisplayTime
_imageExposureTime
_useGPU
_sdof
_contrast
_blurAnalyzer
run:
code
resourceRequirement
cancel
initWithCompletionHandler:
isCanceled
cancelBlock
setCancelBlock:
_started
_canceled
_cancelBlock
_completionHandler
initWithImage:
detect:withConfidence:dominantLine:
arrayWithObjects:
resize:height:
_pixelFormat
_rgbColorSpace
_cgContext
_rgbFrame
_yuvFrames
_rgbToYuv
initWithData:
initWithCVPixelBuffer:options:
setTimeStamp:
imageprint
initWithState:error:
distanceToImageprint:error:
usePHAssetData
descriptorWithImage:
descriptorWithData:
serialize
computeDistance:toDescriptor:
_imagePrint
computeRegionNoise:blockTextureness:average:width:height:stride:
computeNoiseLevel:width:height:stride:textureness:
queryAnalysisPropertiesForAssets:
vcp_dateModified
vcp_modificationDate
isEqualToDate:
vcp_version
faceAdjustmentVersion
adjustmentVersion
vcp_needSceneProcessing
_countMediaAnalysisWithAssetBatch:andDatabase:
_countFaceAnalysisWithAssetBatch:
_countSceneAnalysisWithAssetBatch:
blacklistedLocalIdentifiersFromAssets:
queryFailedProcessingStatusFromAssets:forTaskID:
databaseForPhotoLibrary:
vcp_fetchOptionsForLibrary:forTaskID:
addFetchPropertySets:
fetchAssetsWithOptions:
_countAnalysisWithAssetBatch:andDatabase:andTaskID:
_countFailuresWithAssetBatch:andDatabase:andTaskID:
vcp_assetCountForTaskID:
_processedPredicateForTaskID:
vcp_assetCountWithInternalPredicate:forTaskID:
countForTaskID:withProcessingStatus:
_screenProgress
_queryProgressDetailExpress:forPhotoLibrary:andTaskID:
_scanPhotoLibrary:withTaskID:andStatistics:
queryProgressDetail:forPhotoLibrary:andTaskID:
unsignedIntegerValue
queryProgress:forPhotoLibrary:andTaskID:
setInputFaceObservations:
estimator
detectSmileForFace:inBuffer:smile:
detectPoseForFace:inBuffer:yaw:
faceDetection:faces:cancel:
isDuplicate:withRect:
removeObjectsInArray:
faceDetector
initWithFaceResults:
initWithAssets:andOptions:andCompletionHandler:
queryAnalysisForAsset:
vcp_results
initWithPHAsset:withExistingAnalysis:forAnalysisTypes:
analyzeAsset:streamed:
exportToLegacyDictionary
main
taskWithAssets:andOptions:andCompletionHandler:
_photoLibrary
_database
_cancel
_stabilizationType
_onDemandPixel
_onDemandGyro
analyzeDetectedFaces:faceResults:cancel:
faceQualityScores
setFaceQualityScores:
_faceQualityScores
initWithMovingObjectsResults:
_movingObjects
initWithPhotoLibraries:andCompletionHandler:
deferredProcessingNeeded
processAsset:
fetchAssetsFromCameraSinceDate:options:
_concurrentFaceProcessing
_analyzeAsset:withManager:
fetchLimit
_photoLibraries
setKeypoints:
relativeActionScore
absoluteActionScore
revision
_relativeActionScore
_absoluteActionScore
_revision
_keypoints
handID
setHandID:
_handID
setNetworkAccessAllowed:
appendData:
defaultManager
requestDataForAssetResource:options:dataReceivedHandler:completionHandler:
privateFileURL
dataWithContentsOfURL:
createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
setValue:forKey:
longValue
convertPixelBuffer:toPixelFormat:
loggingEnabled
drawImage:withOrientation:maxDimension:pixelBuffer:
canDecodeAcceleratedUniformTypeIdentifier:
acceleratedDecodeImageData:pixelFormat:maxDimension:pixelBuffer:flushCache:
decodeImageSource:pixelFormat:maxDimension:pixelBuffer:
dataForResource:
uniformTypeIdentifier
pixelBufferWithFormat:andMaxDimension:fromData:withUniformTypeIdentifier:flushCache:
getResourceValue:forKey:error:
sharedImageManager
imageForResource:pixelFormat:
imageForResource:pixelFormat:maxDimension:
pixelBufferWithFormat:fromImageURL:flushCache:
pixelBufferWithFormat:andMaxDimension:fromImageURL:
flushCache
_decodeSession
_transferSession
_decodeQueue
unsignedIntValue
centerX
centerY
qualityMeasure
clusterSequenceNumber
quality
photosFaceRepresentationSourceWidth
photosFaceRepresentationSourceHeight
photosFaceRepresentationCenterX
photosFaceRepresentationCenterY
photosFaceRepresentationSize
photosFaceRepresentationBlurScore
photosFaceRepresentationHasSmile
photosFaceRepresentationIsLeftEyeClosed
photosFaceRepresentationIsRightEyeClosed
photosFaceRepresentationQualityMeasure
photosFaceRepresentationClusterSequenceNumber
photosFaceRepresentationLocalIdentifier
photosFaceRepresentationRoll
photosFaceRepresentationQuality
indexSetWithIndexesInRange:
objectsAtIndexes:
persistenceDelegate_enumerateInChunksOfSize:withOverageAllowance:usingBlock:
enumerateObjectsUsingBlock:
setWithCapacity:
resultsAsArray
resultsAsSet
initWithPerson:andPerson:reason:
person1LocalIdentifier
person2LocalIdentifier
mergeCandidatePairWithPerson:andPerson:reason:
reason
_hash
_person1LocalIdentifier
_person2LocalIdentifier
_reason
librarySpecificFetchOptions
setMinimumUnverifiedFaceCount:
setFetchPropertySets:
sortDescriptorWithKey:ascending:
newAllFacesFetchOptionsWithPhotoLibrary:
setShouldPrefetchCount:
fetchFacesWithOptions:
countOfClusteringEligibleFaces
countOfUnclusteredFaces
newUnclusteredFacesFetchOptions
newFacesDeterministicSortDescriptors
setInternalSortDescriptors:
setInternalPredicate:
fetchFacesWithLocalIdentifiers:options:
fetchedObjects
fetchAssetsGroupedByFaceUUIDForFaces:
allValues
fetchMomentUUIDByAssetUUIDForAssets:options:
fetchPropertySetsIfNeeded
faceClusteringProperties
uuidFromLocalIdentifier:
nonGroupedGroupID
initWithUUIDString:
canceled
updateBlock
faceClusterSequenceNumbersOfFacesWithClusterSequenceNumbers:error:
minusSet:
allObjects
fetchFaceGroupsGroupedByFaceLocalIdentifierForFaces:options:
enumerateKeysAndObjectsUsingBlock:
enumerateFetchResult:withBatchSize:handler:
unionSet:
_ungroupFaceClusterSequenceNumbers:canceler:error:
strongToStrongObjectsMapTable
_categorizeGroupedFacesInFetchResult:intoFaceLocalIdentifiersByFaceGroup:ungroupedFaceLocalIdentifiers:canceler:photoLibrary:
_resetFaceClusterSequenceNumberOfFacesInFetchResult:inPhotoLibrary:canceler:error:
domain
keyEnumerator
changeRequestForFace:
setClusterSequenceNumber:
changeRequestForFaceGroup:
removeFaces:
performCancellableChangesAndWait:error:
setIncludeOnlyFacesInFaceGroups:
_fetchResultForUngroupedFacesWithNonZeroClusterSequenceNumberInPhotoLibrary:
_fetchResultForGroupedFacesWithClusterSequenceNumberSetToZeroInPhotoLibrary:
fetchFaceGroupsForPerson:options:
fetchFacesForPerson:options:
fetchFacesInFaceGroup:options:
newAllPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
fetchAssociatedPersonsGroupedByFaceGroupLocalIdentifierForFaceGroups:options:
objectEnumerator
allKeys
dictionaryWithCapacity:
setWithArray:
creationRequestForFaceGroup
placeholderForCreatedFaceGroup
fetchKeyFaceForFaceGroup:options:
setPersonBuilderState:
addFaces:
setKeyFace:
removeObjectsForKeys:
deleteEmptyGroupsAndReturnError:
_localIdentifiersOfUnverifiedPersonsAssociatedWithFaceGroups:withCanceler:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:
fetchFaceGroupsWithOptions:
deleteFaceGroups:
cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:
fetchEmptyFaceGroupsWithOptions:
performChangesAndWait:error:
localizedDescription
newVisibleFacesFetchOptionsWithPhotoLibrary:
fetchKeyFaceForPerson:options:
bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:
verifiedType
changeRequestForPerson:
setKeyFace:forCluster:
bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:
_facesFromFaceGroupWithMostNumberOfFacesOnPerson:options:error:
_faceToFaceCountMapForFaces:
qualityMeasureForFace:countOfFacesOnAsset:
_representativenessByFaceCSNFromFaces:canceler:
selectRepresentativeFromFaces:qualityMeasureByLocalIdentifier:representativenessByCSN:candidateFaces:
faceprintData
faceprintFromFaceprintArchive:error:
setFaceId:
setFaceTorsoprint:
representativenessFromFaceObservations:error:
newAssetFetchOptionsWithPhotoLibrary:
fetchAssetsForFaces:options:
setFetchLimit:
fetchMergeCandidatePersonsForPerson:options:
intersectSet:
removeMergeCandidatePersons:
fetchPersonsWithOptions:
_cleanupMergeCandidatesForVerifiedPersons:minimumFaceGroupSize:canceler:error:
minimumVerifiedFaceCount
minimumUnverifiedFaceCount
faceCount
predicate
evaluateWithObject:
newAllPersonsFetchOptionsWithPhotoLibrary:
_enumeratePersonsWithLocalIdentifiers:fetchOptions:personCache:usingBlock:
deletePersons:
changeRequestForDedupingGraphPersons:
fetchInvalidMergeCandidatePersonsForPerson:options:
nameSource
trainingType
isConfirmedFaceCropGenerationPending
newVerifiedPersonsFetchOptionsWithPhotoLibrary:
fetchRejectedPersonsForFace:options:
_getMergeCandidates:invalidMergeCandidates:forPersonsWithLocalIdentifiers:
fetchRejectedFacesForPerson:options:
progressWithTotalUnitCount:
filterUsingPredicate:
becomeCurrentWithPendingUnitCount:
setNameSource:
resignCurrent
personBuilderMergeCandidatesDisabled
addMergeCandidatePersons:
addInvalidMergeCandidatePersons:
fetchFacesOnAssetWithFace:options:
removeObjectAtIndex:
otherFacesOnAssetWithFace:options:
_duplicateFaceCSNsOnAssetForPerson:faceCSNsOnPerson:faceByCSNCache:
dedupeGraphVerifiedPersonsInFaceGroup:personCache:
minimumFaceGroupSizeForCreatingMergeCandidates
_getTrainingFacesByPerson:confirmedFaceCSNs:faceCSNsByPerson:faceCSNsByMigratedPerson:faceCSNsByQuickClassificationPerson:mergeCandidates:invalidMergeCandidates:rejectedPersonsByPerson:faceInFaceGroupByCSN:inFaces:personCache:canceler:
_getRejectedTrainingFaceCSNs:rejectedFaceCSNs:rejectedPersonLocalIdentifiers:forPerson:faceInFaceGroupByCSN:
_completePersonBuildingWithPersonsToUpdate:facesToRemoveByPerson:facesToAddByPerson:updateFaceGroup:newMergeCandidatePairs:newInvalidMergeCandidatePairs:faceInFaceGroupByCSN:personCache:keyFaceUpdateBlock:canceler:context:error:
nextObject
anyObject
level0ClusterAsFaceCSNsByLevel0KeyFaceCSNForClusterIdentifiedByFaceCSN:error:
_level0ClusterIdForFaceCSN:level0Clusters:
setWithSet:
intersectsSet:
quarantineTwinsOnAssetEnabled
_updateFaceCSNsToAddByPerson:faceCSNsToRemoveByPerson:faceInFaceGroupByCSN:faceCSNsByPersonLocalIdentifier:faceCSNsByMigratedPersonLocalIdentifier:personsToUpdate:
personBuildingDisabled
_updatedFaceGroupByFGLocalIdentifierFromClusterCSNsWithCanceler:fetchLimit:
_buildPersonsFromUpdatedFaceGroups:faceClusterer:keyFaceUpdateBlock:canceler:context:
cancelerWithUpdateBlock:
suggestedMeIdentifierWithPersonClusterManager:forPersons:updateBlock:
socialGroupsOverTheYearsWithPersonClusterManager:forPersons:updateBlock:
multiLevelSocialGroupsWithPersonClusterManager:forPersons:updateBlock:
densityClusteringForObjects:maximumDistance:minimumNumberOfObjects:withDistanceBlock:
newVerifiedPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
countOfFaces
countOfUnclusteredClusteringEligibleFaces
countOfClusteredFaces
unclusteredClusteringEligibleFaceLocalIdentifiers:
facesForClusteringWithLocalIdentifiers:faceprintVersion:groupingIdentifiers:
deterministicallyOrderedFaceIdentifiersWithLocalIdentifiers:faceprintVersion:
facesFromAsset:
invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:
persistFaces:deleteFaces:forAsset:persistedFaces:error:
ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:
cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:
updateFaceprint:ofPersistedFace:error:
persistGeneratedFaceCrops:error:
dirtyFaceCropsWithLimit:
clearDirtyStateOnFaceCrops:error:
associateFace:withFaceCrop:error:
faceAssociatedWithFaceCrop:
groupedClusterSequenceNumbersOfFacesInFaceGroupsOfMinimumSize:error:
persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:
resetLibraryClustersWithCanceler:error:
recordNeedToPersonBuildOnFaceGroupContainingFace:error:
needsPersonBuilding
buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:
suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:
logPVErrorMessage:
logPVWarningMessage:
logPVInfoMessage:
logPVDebugMessage:
faceAlgorithmUmbrellaVersion
setFaceAlgorithmUmbrellaVersion:
sceneAlgorithmUmbrellaVersion
setSceneAlgorithmUmbrellaVersion:
keyFaceForPerson:qualityMeasureByFace:updateBlock:
performSocialGroupsIdentifiersWithPersonClusterManager:forPersons:overTheYearsComputation:updateBlock:
initWithPhotoLibrary:
cleanupMergeCandidatesWithMinimumFaceGroupSize:canceler:error:
fetchFaceWithLocalIdentifier:error:
fetchFaceWithClusterSequenceNumber:error:
fetchPersonWithLocalIdentifier:options:error:
removeAutoAssignedFacesFromVerifiedPersonsAndPrepareForPersonBuilding:canceler:error:
setPersonBuilderMergeCandidatesDisabled:
setUpdateBlock:
_faceAlgorithmUmbrellaVersion
_sceneAlgorithmUmbrellaVersion
_personBuilderMergeCandidatesDisabled
_updateBlock
generatePersonRegions:boxes:maxNumRegions:
createInput:withBuffer:inputHeight:inputWidth:
generatePersonBoxes:
personDetection:personRegions:cancel:
_outputsData
convertResultsToDict:results:
_petsDetector
vcp_quality
analyzeImageQuality:irisPhotoOffsetSec:cancel:
initWithMaxNumRegions:prune:
copyImage:toData:withChunk:
outputScaling
computeScore:width:height:posX:posY:
scaleImage:toData:withWidth:andHeight:
getSalientRegions:
saliencyDetection:salientRegions:cancel:
pruneRegions:
analyzerWith:prune:
generateSalientRegion:outHeight:outWidth:
_region
_score
_maxNumRegions
_prune
_createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
_createPixelBufferPool
imageManager
loadFullPixelBuffer:scaledPixelBuffer:fromImageURL:isPano:
_pixelBufferPoolBGRA
sharedTaxonomy
numberWithUnsignedInt:
_createPixelBufferPool:withPixelFormat:
_convertFromBuffer:toLumaPixelBuffer:isPano:
_panoVNRequestMethod
initWithURL:options:session:
initWithCVPixelBuffer:options:session:
maximumLeafObservations
setMaximumLeafObservations:
maximumHierarchicalObservations
setMaximumHierarchicalObservations:
setPrivateRevision:error:
_useR14J9
_includeDO
_includeSO
_includeLM
_includeNSFW
_getNSFWModelRevision
_includeSE
_getSERevision
_includeSDG
_getSDGModelRevision
stringValue
nodeForName:
highPrecisionThreshold
highRecallThreshold
threshold
sceneClassId
labels
_parseClassificationObservations:toClassificationResults:
_generateSceneClassifications:withClassificationResults:andDOResults:andJunkImageResults:andLMResults:andNSFWResults:andSEResults:andSDGResults:
aestheticScore
wellFramedSubjectScore
wellChosenBackgroundScore
tastefullyBlurredScore
sharplyFocusedSubjectScore
wellTimedShotScore
pleasantLightingScore
pleasantReflectionsScore
harmoniousColorScore
livelyColorScore
pleasantSymmetryScore
pleasantPatternScore
immersivenessScore
pleasantPerspectiveScore
pleasantPostProcessingScore
noiseScore
failureScore
pleasantCompositionScore
interestingSubjectScore
intrusiveObjectPresenceScore
pleasantCameraTiltScore
lowKeyLightingScore
narrowedBoundingBox
salientObjects
sceneprints
archivedDataWithRootObject:requiringSecureCoding:error:
_createAestheticsRequest:andClassificationRequest:andSceneprintRequest:andJunkImageRequest:andSaliencyImageRequest:andDORequest:andLMRequest:andNSFWRequest:andSERequest:andSDGRequest:andSORequest:andRawSceneprintRequest:
_collectSceneAnalysisResults:withClassificationResults:andJunkImageResults:andAestheticsResults:andSaliencyResults:andSceneprintResults:andDOResults:andLMResults:andNSFWResults:andSEResults:andSDGResults:andSaliencyObjectnessResults:
_getSHRevision
_performBlurAnalysis:withPixelBuffer:usingAnalyzer:
_performSceneAnalysis:withRequestHandler:
_performBlurAnalysis:withLumaPixelBuffer:isPano:isSDOF:
_performExposureAnalysis:withLumaPixelBuffer:
_loadImageURL:isPano:withRequestHandler:session:andLumaPixelBuffer:
_enableSceneAssetConcurrency
_performAnalysis:isPano:isSDOF:withRequestHandler:andLumaPixelBuffer:
analyzeWithImageURL:isPano:isSDOF:completionHandler:
analyzeWithPixelBuffer:isPano:isSDOF:results:cancel:
_imageManager
_sceneTaxonomy
_pool8Y
vcp_hasLocalMovie:
vcp_isVideoSlowmo
vcp_thumbnailResource
vcp_size
pixelWidth
pixelHeight
vcp_avAsset:
assetImageGeneratorWithAsset:
thumbnailSizeForAsset:withResources:
setMaximumSize:
setAppliesPreferredTrackTransform:
copyCGImageAtTime:actualTime:error:
initWithPixelFormat:
convertImage:yuvFrame:
vcp_isLocallyAvailable
vcp_localPhotoResourcesSorted:
_generateLastFrameDistanceDescriptor:withDescriptorClass:forAsset:
_getThumbnailForAsset:withResouces:andPixelFormat:
string
topCandidates:
stringByAppendingFormat:
length
initWithScannerType:passiveIntent:
category
type
getMailValue:label:
getPhoneValue:label:
value
localTimeZone
dateFromReferenceDate:referenceTimezone:timezoneRef:allDayRef:
extractStartDate:startTimezone:endDate:endTimezone:allDayRef:referenceDate:referenceTimezone:
subResults
URLWithString:
scanString:range:configuration:completionBlock:
setRecognitionLevel:
setMinimumTextHeight:
initWithURL:options:
processObservations:
taskWithPixelBuffer:options:andCompletionHandler:
taskWithAssetURL:options:andCompletionHandler:
_pixelBuffer
_assetURL
cameraMotionDetection:
generateThresholds:withConfidences:
autoLiveMotionScore:
initWithQueue:turbo:
prewarmWithWidth:height:
analyzeFrame:withTimestamp:andDuration:completion:
_frame
_stats
_cameraMotionParams
_cameraMotionConfidences
_turbo
vcp_firstEnabledTrackWithMediaType:
formatDescriptions
findMetaTrackforType:
initWithTrack:
analyzerForTrackType:withTransform:requestAnalyses:formatDescription:
copyNextMetadataGroup
processMetadataGroup:flags:
finalizeAnalysis
publicResults
lastObject
processMetaTrackForType:cancel:flags:
checkTimeRangeConsistency
postProcessOrientationResults
initWithAVAsset:forAnalysisTypes:
analyzeAsset:flags:
_avAsset
_transform
_metaTracks
_publicMutableResults
_privateMutableResults
timeWithCMTime:
standardUserDefaults
persistentDomainForName:
currentLocale
setLocale:
sharedLogManager
dateFormatter
logLevel
_logLevel
createModelWithResConfig:
substringToIndex:
assetResourcesForAsset:
initWithTransform:timeRange:isLivePhoto:frameStats:keyFrameResults:
initWithAnalysisType:isLivePhoto:hadFlash:hadZoom:
setMaxHighlightDuration:
analyzeFrame:withTimestamp:
preparePostProcessingStatsFromFaceRange:junkResults:
postProcess
postProcessKeyFrames
keyFrames
prepareRequiredQualityResult:junkDetectionResult:descriptorResult:faceResult:saliencyResult:actionResult:subtleMotionResult:voiceResult:keyFrameResult:sceneResults:humanActionResults:humanPoseResults:cameraMotionResults:orientationResults:frameSize:
generateHighlights
timerange
score
keyFrame
bestPlaybackCrop
isTrimmed
isAutoPlayable
reportMovieCurationAnalysisResults:withSummaryAnalytics:
addHighlight:to:
movieSummary
addSummary:to:
keyFrameScores
initWithAnalysisTypes:transform:timeRange:isLivePhoto:frameStats:hadFlash:hadZoom:keyFrameResults:
analyzeKeyFrame:withTimestamp:andDuration:flags:
loadVideoAnalysisResults:audioAnalysisResults:andFaceRanges:frameSize:
generateMovieCurations
_keyFrameAnalyzer
_highlightAnalyzer
_descriptorResults
_qualityResuls
_junkResults
_actionResults
_subtleMotionResults
_voiceResults
_sceneResults
_humanActionResults
_humanPoseResults
_cameraMotionResults
_saliencyResults
_orientationResults
_faceRanges
_frameSize
_frameStats
_isLivePhoto
_hadFlash
_hadZoom
initWithTime:andScore:
timeStamp
_timeStamp
initWithTimeRange:score:andKeyFrame:
_keyFrame
_timerange
initWithPHAsset:
phAsset
highlights
_phAsset
_highlights
descriptor
junkScore
expressionScore
voiceScore
humanActionScore
humanPoseScore
initWithTimeRange:
mergeSegment:
isShort
copyScoresFrom:
checkAutoPlayable
setTimerange:
setScore:
setJunkScore:
setExpressionScore:
setVoiceScore:
setHumanActionScore:
setHumanPoseScore:
setBestPlaybackCrop:
setIsAutoPlayable:
setIsTrimmed:
setDescriptor:
setKeyFrame:
_isAutoPlayable
_isTrimmed
_junkScore
_expressionScore
_voiceScore
_humanActionScore
_humanPoseScore
_descriptor
_bestPlaybackCrop
generateInitialSegments
computeHighlightScoreWithConstraint
computeQualityTrimFor:withKeyFrame:
computeActionFaceTrimFor:
computeSteadyTranslationTrimFor:
checkCameraZoom:
generateExpressionSegments:
analyzeOverallQuality:
pickKeyFramesInRange:
computeBestPlaybackCrop:
junkScoreForTimerange:
qualityScoreForTimerange:
SetKeyFramesForSegments:
computeExpressionScoreInTimerange:
computeActionScoreInTimerange:
computeVoiceScoreInTimeRange:
pickHighlightsFrom:
searchFeatureVectorOfSegment:
computeHighlightScoreOfSegment:
evaluateSegment:
addSegment:
computeHumanActionScoreInTimerange:
computeHumanPoseScoreInTimerange:
expressionChangeScore
actionScoreForTimerange:
subtleMotionScoreForTimerange:
expressionScoreForTimerange:
voiceScoreForTimerange:
cameraMotionScoreForTimerange:
visualPleasingScoreForTimerange:
computeHighlightScoreOfRange:
mergeShortSegments
mergeSimilarSegments
_qualityResults
_featureResults
_keyFrameResults
_expressionSegments
_internalResults
_internalConstraintResults
_maxDurationInSeconds
requestURLAssetAnalysis:forAssetWithResourcePaths:withOptions:analysisTypes:sandboxTokens:withReply:
requestAssetAnalysis:forPhotoLibraryURL:withLocalIdentifiers:realTime:withReply:
requestLibraryProcessing:withTaskID:forPhotoLibraryURL:withOptions:andReply:
requestAssetProcessing:withTaskID:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:andReply:
cancelRequest:
cancelAllRequests
cancelBackgroundActivityWithReply:
notifyLibraryAvailableAtURL:
requestSuggestedPersons:withPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:andPhotoLibraryURL:andReply:
requestUpdateKeyFacesOfPersons:withLocalIdentifiers:andForceUpdate:andPhotoLibraryURL:andReply:
requestFaceCandidatesforKeyFace:withPersonsWithLocalIdentifiers:andPhotoLibraryURL:andReply:
requestResetFaceClassificationModel:withPhotoLibraryURL:andReply:
requestSuggestedMePersonIdentifier:withContext:andPhotoLibraryURL:andReply:
requestPersonPromoterStatus:withAdvancedFlag:andPhotoLibraryURL:andReply:
requestClusterCacheValidation:withPhotoLibraryURL:andReply:
requestResetFaceClusteringState:withPhotoLibraryURL:andReply:
requestReclusterFaces:withPhotoLibraryURL:andReply:
requestRebuildPersons:withLocalIdentifiers:andPhotoLibraryURL:andReply:
requestPersonPreferenceForPhotoLibraryURL:andReply:
requestVIPModelStorageFilepathForPhotoLibraryURL:andReply:
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
initWithMachServiceName:options:
setExportedObject:
setRemoteObjectInterface:
reportProgress:forRequest:
setExportedInterface:
setInterruptionHandler:
setInvalidationHandler:
resume
taskForURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
stringWithUTF8String:
connection
remoteObjectProxyWithErrorHandler:
vcp_defaultURL
vcp_url
requestProcessingWithTaskID:forPhotoLibrary:withOptions:progessHandler:andCompletionHandler:
errorWithDescription:
requestProcessingWithTaskID:forAssets:withOptions:progressHandler:andCompletionHandler:
vcp_defaultPhotoLibrary
taskWithPhotoLibraries:andCompletionHandler:
taskWithAssets:andCompletionHandler:
synchronousRemoteObjectProxyWithErrorHandler:
invalidate
sharedAnalysisService
analysisService
queryProgressDetail:forPhotoLibraryURL:andTaskID:
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:progressHandler:andCompletionHandler:
requestBackgroundAnalysisForAssets:realTime:progessHandler:completionHandler:
requestBackgroundProcessingWithTaskID:forPhotoLibrary:progessHandler:completionHandler:
requestSceneProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestFaceProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestMultiWorkerProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestFullProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestLivePhotoEffectsForAssets:withOptions:progressHandler:andCompletionHandler:
requestSceneProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestFaceProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestQuickFaceIdentificationForPhotoLibraryURL:withOptions:andCompletionHandler:
requestSceneprintProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestVideoStabilizationForAssets:withOptions:progressHandler:andCompletionHandler:
cancelBackgroundActivity
requestPersonPreferenceForPhotoLibraryURL:completionHandler:
requestVIPModelFilepathForPhotoLibraryURL:completionHandler:
_connection
_managementQueue
_handlerQueue
_progressBlocks
_nextRequestID
requestSuggestedPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:photoLibraryURL:progessHandler:completionHandler:
requestUpdateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:photoLibraryURL:progessHandler:completionHandler:
requestFaceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:photoLibraryURL:progessHandler:completionHandler:
requestResetFaceClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:
requestSuggestedMePersonIdentifierWithContext:photoLibraryURL:progressHandler:completionHandler:
requestPersonPromoterStatusWithAdvancedFlag:photoLibraryURL:progressHandler:completionHandler:
requestClusterCacheValidationWithPhotoLibraryURL:progressHandler:completionHandler:
requestResetFaceClusteringStateWithPhotoLibraryURL:progressHandler:completionHandler:
requestReclusterFacesWithPhotoLibraryURL:progressHandler:completionHandler:
requestRebuildPersonsWithLocalIdentifiers:photoLibraryURL:progressHandler:completionHandler:
longLongValue
storeAnalysis:forAsset:fromPhotoLibraryURL:withReply:
registerClient:forPhotoLibraryURL:withReply:
sharedDatabaseForPhotoLibrary:
sceneClassifications
sceneIdentifier
vcp_setVersion:
vcp_setDateModified:
date
vcp_setDateAnalyzed:
vcp_setFlags:
vcp_fingerprint:
vcp_setFingerprint:
vcp_setResult:forKey:
vcp_addTypes:
mediaType
vcp_allResourcesForAsset:
vcp_fullAnalysisTypesForResources:
sharedInstance
hasWifiOrEthernetConnection
vcp_eligibleForStreaming:
vcp_eligibleForVideoDownload:
isVideo
canAnalyzeUndegraded:withResources:
setAllowStreaming:
hasAdjustments
vcp_hasLocalPhoto:
analyzeAsset:
isPhoto
vcp_types
absoluteString
pathExtension
movieAssetWithURL:
analyzerWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
livePhotoAssetWithImageURL:andMovieURL:
imageAssetWithURL:
analyzerWithVCPAsset:forAnalysisTypes:
isAssetBlacklisted:blacklistDate:
_addClassificationResults:analysis:
vcp_degraded
_metaAnalysisTypesForAsset:
_analyzeOndemand:forAnalysisTypes:withExistingAnalysis:andOptions:storeAnalysis:
sharedMediaAnalyzer
_databaseForPhotoLibrary:
requestAnalysis:forAsset:withExistingAnalysis:andDatabase:andOptions:
queryAssetsAnalyzedSince:
setSortDescriptors:
fetchAssetsWithLocalIdentifiers:options:
assetsFromPhotoLibrary:analyzedSinceDate:completionHandler:
sceneprintProperties
sceneprint
distanceIdentity
setWithObject:
queryAnalysisForAsset:withTypes:
_getSceneDescriptors:asDescriptorClass:withSceneRange:andAnalysisResults:
_getDistanceDescriptorClass
_checkDuplicate:withAsset:duplicate:
_queryDistanceDescriptor:ofAsset:withExistingAnalysis:andDatabase:timeRange:lastFeature:isDegraded:
computeDistance:fromArray:toArray:
computeDistance:withDescriptorClass:fromAsset:toAsset:
vcp_flags
canUseLastFrameOfAsset:withResources:
generateDistanceDescriptor:withDescriptorClass:forAsset:withResources:lastFrame:
arrayWithObject:
dictionaryWithDictionary:
_typesToRemove:requested:
requestAnalysis:forAssets:withOptions:andProgressHandler:andCompletionHandler:
requestAnalysisTypes:forAssets:withOptions:andProgressHandler:analyses:
requestAnalysis:forAssets:withOptions:andProgressHandler:andError:
fetchAssetsInAssetCollection:options:
compare:
sortedArrayUsingSelector:
reverseObjectEnumerator
recognizeFaces:
_getDatabaseSandboxExtensionForPhotoLibraryURL:
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:error:
analyzeOndemand:pairedURL:forAnalysisTypes:error:
requestAnalysisForAsset:analysisTypes:progressHandler:completionHandler:
cancelAnalysisWithRequestID:
assetsAnalyzedSinceDate:completionHandler:
distanceFromAsset:toAsset:duplicate:distance:
distanceFromAsset:timeRange:toAsset:timeRange:duplicate:distance:
requestAnalysesForAssets:analysisTypes:allowOndemand:progressHandler:completionHandler:
requestAnalysisTypes:forAssets:allowOndemand:progressHandler:error:
curateMovieAssetsForCollection:withAlreadyCuratedAssets:andDesiredCount:allowOnDemand:
requestCallerIdentificationForFaces:
requestMovieHighlightsForAssets:withOptions:
requestLivePhotoEffectsForAssets:allowOnDemand:flags:
completeStorage
_analysisQueue
_storageQueue
_storageGroup
_standalone
_noResultStrip
_sandboxQueue
_sandboxHandles
numOfFrames
updateSegment:
resetSegment:
finalizeAtTime:
_numOfFrames
assetReaderOutputMetadataAdaptorWithAssetReaderTrackOutput:
nextTimedMetadataGroup
_readerOutput
_readerOutputAdaptor
getMaximumHighlightInSec
vcp_setStatsFlags:
initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
vcp_setTypes:
vcp_statsFlags
vcp_addEntriesFromResults:
vcp_syncPoint
vcp_setSyncPoint:
tracksWithMediaType:
loadValuesAsynchronouslyForKeys:completionHandler:
vcp_addFlags:
processExistingAnalysisForTimeRange:analysisTypes:
createDecoderForTrack:timerange:forAnalysisTypes:
createVideoAnalyzer:withFrameStats:
videoStabilizerforAnalysisType:withMetadata:sourceSize:cropRect:
convertAnalysisResult
vcp_appendResults:
vcp_endTime
analyzeVideoSegment:timerange:forAnalysisTypes:cancel:
allowStreaming
loadPropertiesForAsset:
vcp_setQuality:
performMetadataAnalysisOnAsset:withCancelBlock:
vcp_startTime
analyzeVideoTrack:start:forAnalysisTypes:cancel:
generateKeyFrameResource:
vcp_removeSyncPoint
analyzeOverallQuality:withFpsRate:
generateLivePhotoRecommendationForResults:andPrivateResults:usingFaceAction:
setActivityLevel:
vcp_addStatsFlags:
setRequestedTimeToleranceAfter:
setRequestedTimeToleranceBefore:
vcp_appendResult:forKey:
initWithPHAsset:withPausedAnalysis:forAnalysisTypes:
maxHighlightDuration
faceDominated
setFaceDominated:
_supportConditionalAnalysis
_existingAnalysis
_prepareLivePhotoScenes
_allowStreaming
_maxHighlightDuration
vcp_sortBySize
vcp_isPhotoResourceUsable:
vcp_isMovie
vcp_isVideoResourceUsable:
vcp_isOriginalLocal
vcp_hasLocalAdjustments
vcp_resourceWithType:
vcp_smallResourceMeetingCriteria:
vcp_isPhoto
vcp_localMovieResourcesSorted:
vcp_photoResourcesSorted:
bundleWithIdentifier:
unsignedLongValue
vcp_dateAnalyzed
vcp_fingerprint
vcp_streamedVideo
vcp_mutableResults
vcp_setResults:
vcp_time
vcp_timerange
vcp_setTimerange:
vcp_imagesPredicate:
vcp_stillImagesPredicate:
vcp_livePhotosPredicate:
vcp_moviesPredicate:
createFaceHeatMap:imageFaces:
computeOverallFaceQualityScore:
selectKeyFrameRangeWithMotion:stillTimestamp:isMetaMotion:
fetchAndComputeScoreForKeyFrame:withResult:
semanticScore
setSemanticScore:
copyFrom:
computeScoreForPhoto:withRefKeyFrame:
reportLivePhotoKeyFrameAnalysisResults:selectedKeyFrame:originalStillKeyFrame:stillScore:stillFQScore:stillTimestamp:useSemanticOnly:isKeyFrameSuggested:
getFaceHeat:
updateFaceHeatMap:
initWithWidth:height:
analyzeLivePhotoKeyFrame:irisPhotoOffsetSec:originalIrisPhotoOffsetSec:photoTextureScore:hadFlash:cancel:
_photoSharpnessReliable
_photoSharpness
_petsDominant
_ignoreFace
_faceHeatMap
vcp_faceRectFrom:
vcp_flagsForPHFace:withFaceRect:
objectID
_computeFingerPrintsOfAsset:completionHandler:
fetchAssetsMatchingAdjustedFingerPrint:photoLibrary:
fetchAssetsMatchingMasterFingerPrint:photoLibrary:
vcp_fetchAssetsMatchingFingerprint:forPhotoLibrary:
loadModelAtPath:error:
creationDate
imageWithURL:assetWidth:assetHeight:imageCreationOptions:adjustmentVersion:creationDate:
faceObservationFromFaceprintData:
classifyFaceObservation:withModel:error:
quickClassificationFaceAdjustmentVersion
_loadPersonsModel
_loadPVImage:forAsset:
_detectFacesWithPVImage:forAsset:withAnalysis:
_classifyFaces:forAsset:withResults:
_persistResults:withFaces:forAsset:
vcp_analysisPreferences
faceIDModelRebuildPeriod
persistModel:toPath:error:
fetchPersonsForFaceIDModel
setIncludeOnlyFacesWithFaceprints:
newMutablePersonsModel
UUIDString
addFaceObservations:forPersonIdentifier:toModel:error:
_persistPersonsModel:error:
trainingFaceObservationsForPersonWithUniqueIdentifier:canceller:error:
arrayByAddingObjectsFromArray:
setIsInVIPModel:
_needToGeneratePersonsModel
_generatePersonsModelShouldForce:extendTimeoutBlock:cancel:
_personsModelLastGenerationDidExceedTimeInterval
generatePersonsModelWithExtendTimeout:cancel:
_personsModel
_management
adjustmentTimestamp
setExcludeMontageAssets:
vcp_typeDescription
vcp_isSdofPhoto
vcp_isVideoTimelapse
sceneAnalysisProperties
sceneAnalysisVersion
sceneAnalysisTimestamp
instancesRespondToSelector:
attributesOfItemAtPath:error:
resourceForAsset:withResources:
vcp_originalSize
processExistingAnalyses:
mediaAnalysisProperties
blurrinessScore
vcp_usePHFace
vcp_needFaceProcessing
vcp_queryPHFaces:results:
dictionaryWithObjectsAndKeys:
updateDegradedFlagForMajorDimension:
downscaleImage:scaledImage:majorDimension:
vcp_usePHFaceExpression
existingAnalysisForMovieAnalyzer
checkFaceDominant
initWithDictionary:
analyzeImage:performedAnalyses:cancel:
vcp_removeResultForKey:
_irisAnalyses
_phFaceResults
_phFaceFlags
_imageBlurTextureScore
_preAnalysisSharpnessScore
vcp_mediaAnalysisDirectory
fetchAssetsWithMediaType:options:
internalPredicate
isCloudPhotoLibraryEnabled
cplStatus
lastSuccessfulSyncDate
isExceedingQuota
lastCompletePrefetchDate
vcp_isCPLEnabled
vcp_isCPLDownloadComplete
_vcp_analysisPreferencesURL
dataWithPropertyList:format:options:error:
writeToURL:options:error:
_vcp_updateAnalysisPreferencesWithEntries:keysToRemove:
modelFileName
vcp_assetCountWithMediaType:forTaskID:
vcp_isCPLSyncComplete
vcp_canStreamingForFaceAnalysis
unarchivedObjectOfClass:fromData:error:
computeDistance:withDistanceFunction:error:
_sceneprint
ComputeSceneDelta:
decideLensSwitchPoint:
PrintSegments
finalizeAnalysisPass:
isSegmentPoint
_sceneDeltaBuffer
_activeSegment
_sceneSegments
_firstFrame
_frameTimeRange
_currentStatus
_isSegmentPoint
requestImageProcessingTask:forIOSurface:withOptions:andReply:
requestImageProcessingTask:forAssetURL:withSandboxToken:options:andReply:
sandboxExtensionForURL:error:
initWithProcessingTypes:forPixelBuffer:withOptions:andCompletionHandler:
_analyzeFace:error:
_analyzeScene:error:
taskWithProcessingTypes:forPixelBuffer:withOptions:andCompletionHandler:
_processingTypeScene
_processingTypeFace
_analysisFlags
_options
convertPixelBuffer:toPixelBuffer:withPixelFormat:
analyzeImages:secondImage:cancel:
getFlowWithHeight:andWidth:
prepareAnalyzerWithCVPixelBuffer:
preProcessing:
generateMotionFlow
generateSubleMotionScore:
subtleMotionScore
_flow
_block
_scale
_scaler
_motionFlowAnalyzer
_frameArray
_frameWidth
_frameHeight
_downScaleWidth
_downScaleHeight
_flowWidth
_flowHeight
_blockSize
_frameNum
_subtleMotionScore
initWithRequest:andConfiguration:
_request
_frameInterval
_timeInterval
prepareImage:
calculateOrientationResponses
generateOrientationMap
generateLineWeightMap:weightMap:
voteVanishingPoint:
searchVanishingPointandDominantLine:lineGroup:vanishingPoint:vanishingPointConfidence:dominantLine:
extractUsefulAreaFrom:to:withOffset:stridePadded:width:height:
averageOrientationResponses:withCurrentMap:
smoothFiltering:width:height:
calculateConfidence:lineDistance:vaninshingPoint:vanishingPointConfidence:
isVerticalOrHorizontal:
_orientationResponses
_orientionMap
_confidenceMap
_edgeWeightMap
_stridePadded
_offset
_validDimension
_pixelMean
_pixelVar
_gaborFilter
isScoreValid:
decideSegmentPointUsingHinkleyDetector:
isActive:
updateActiveThreshold
mergeSameTypeSegments
printSegments:
prepareTrimmingWithTrimStart:andTrimEnd:
mergeConsecutiveShortSegments
mergeSparseShortSegments
analyzeFrameWithTimeRange:andActionScore:
decideSegmentPointBasedOnActionScore:
finalizeWithDestructiveTrimStart:trimEnd:
postProcessSegmentsWithCaptureTime:trimStart:
segments
activeSegment
_activeHinkleyDetector
_activeThreshold
_postProcessStart
exceptionWithName:reason:userInfo:
unimplementedExceptionForMethodName:
mediaSubtypes
modificationDate
fingerprint
isImage
isMovie
mainFileURL
scenes
typeDescription
isPano
isLivePhoto
isScreenshot
isHDR
isSDOF
exif
imageWithPreferredDimension:
vcp_flashFired
vcp_scaledExposureTime
hadFlash
exposureTimeSeconds
photoOffsetSeconds
originalPhotoOffsetSeconds
isTimelapse
isSlowmo
duration
slowmoRate
timelapseRate
movie
streamedMovie
originalMovie
originalMovieSize
dataWithBytes:length:
bytes
initWithVertices:vertexCount:
vertices
vertexCount
_vertices
_vertexCount
getBytes:length:
initWithTransform:blendShapes:geometry:
transform
blendShapes
geometry
_blendShapes
_geometry
initWithFocalLengthInPixels:offline:
initWithFocalLengthInPixels:
initWithAnalysisTypes:withPreferredTransform:withFocalLengthInPixels:withAnalysisQueue:withTurbo:
updateFocalLengthInPixels:
frameFaceResults
transformForAngle:pixelBuffer:
flipTransform:
analyzeFrameForPose:withFaceRect:withTimestamp:
rotateTransform:byAngle:
analyzeFrame:withFaceRect:withRotation:withTimestamp:
isTracked
regionsOfInterest
analyzeFrameWithTimeRange:analysisData:
isReady
shouldCutAt:stillPTS:withCut:
analyzerForAnalysisTypes:withPreferredTransform:properties:
aggregateAnalysisForTypes:withFramesMeta:properties:
prewarmWithProperties:
updatePreferredTransform:properties:
analyzePixelBuffer:withTimestamp:andDuration:properties:error:
analyzePixelBuffer:withTimestamp:andDuration:properties:completion:
analyzeAudioBuffer:
aggregatedResults
_poseAnalyzer
_meshAnalyzer
_videoAnalysis
_audioAnalyzer
_faceDetector
_sceneChangeAnalyzer
_lightMotionAnalyzer
_trimAnalyzer
_homeKitMotionAnalyzer
_rotator
_rotatorForFacePose
_preferredTransform
_focalLengthInPixels
_aggregatedResults
_rotationAngleForFacePose
_preferredAngle
_preWarmed
sharedDatabaseManager
_databases
copyBlock:withStride:toBlock:
blockContentDetection:
contentAnalysis
detectPixelBuffer:contentType:
_previousContentType
_argbPixelBuffer
_argbTransferSession
sharedPhotoLibrary
defaultPhotoLibrary
fileSize
assetLocalIdentifier
mutableBytes
initWithBytesNoCopy:length:deallocator:
dataWithLength:
setDownloadIsTransient:
setProgressHandler:
_reportDownload:
cancelDataRequest:
maxSizeBytes
requestDownloadOfResource:
flush
setCancel:
_mutex
_buffer
_localIdentifier
_semaphore
_dataTask
initWithVotes:andCount:
rate
votes
setVotes:
setCount:
_votes
_count
recognizeFace:
_sessions
initWithURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
_pairedAssetURL
_progressHandler
face
_faceprint
initWithLocalIdentifier:andTaskID:andStatus:andAttempts:andNextRetryDate:
taskID
attempts
nextRetryDate
_attempts
_nextRetryDate
createInput:keypoints:cnnInputHeight:cnnInputWidth:
getDetectionScore:
planDestroy
gestureDetection:score:
entityForName:inManagedObjectContext:
initWithEntity:insertIntoManagedObjectContext:
faceFromManagedObject:
vcp_defaultMediaAnalysisDatabaseFilepath
stringByDeletingLastPathComponent
fileExistsAtPath:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
stringByAppendingPathComponent:
fileURLWithPath:
persistentStoreDescriptionWithURL:
bundleForClass:
mergedModelFromBundles:
persistentContainerWithName:managedObjectModel:
setPersistentStoreDescriptions:
viewContext
setMergePolicy:
newBackgroundContext
loadPersistentStoresWithCompletionHandler:
fetchRequestWithEntityName:
executeFetchRequest:error:
sessionFromManagedObject:
performBlockAndWait:
managedObjectForContext:
save:
fetchAllFaceTimeSessions
storeFaceTimeSession:
_persistentContainer
_backgroundContext
initWithSessionID:callerID:andDate:
sessionID
callerID
session
createWithSessionID:callerID:andDate:
faces
addFace:
setSessionID:
setCallerID:
setDate:
_sessionID
_callerID
_date
mutableSetValueForKey:
promoteUnverifiedPersonsWithUpdateBlock:
reset
frameProcessedByVideoAnalyzer
cameraMotionScore
subjectActionScore
colorfulnessScore
subMbMotionAvailable
faceArea
setFaceArea:
frameProcessedByHumanAnalyzer
setFrameProcessedByHumanAnalyzer:
frameProcessedByFaceDetector
setFrameProcessedByFaceDetector:
setDetectedFaces:
_frameProcessedByVideoAnalyzer
_subMbMotionAvailable
_frameProcessedByHumanAnalyzer
_frameProcessedByFaceDetector
_cameraMotionScore
_subjectActionScore
_colorfulnessScore
_frameExpressionScore
_faceArea
_detectedFaces
_videoActivityDescriptor
requestAnalysis:ofFragmentData:withRequestID:properties:andReply:
requestAnalysis:ofFragmentSurface:withRequestID:properties:andReply:
requestIdentification:forFaceCrop:withOptions:andReply:
requestResidentMaintenance:withOptions:andReply:
expectedClasses
allowedClasses
requestAnalysis:ofAssetData:withProperties:progressHandler:andCompletionHandler:
requestAnalysis:ofAssetSurface:withProperties:progressHandler:andCompletionHandler:
taskWithFaceCrop:andCompletionHandler:
requestIdentificationForFaceCrop:withOptions:andCompletionHandler:
requestResidentMaintenanceWithOptions:andCompletionHandler:
resourceLoader
setDelegate:queue:
contentInformationRequest
setContentType:
setContentLength:
setByteRangeAccessSupported:
dataRequest
requestedOffset
requestedLength
dataWithBytesNoCopy:length:freeWhenDone:
respondWithData:
finishLoading
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceLoader:didCancelAuthenticationChallenge:
setReachabilityForFlags:update:
_callbackQueue
_reachability
_hasWifiOrEthernetConnection
setCanceled:
initWithFace:image:
descriptorForFace:image:
image
_face
enumerateObjectsAtIndexes:options:usingBlock:
imageRectForNormalizedRect:
groupingIdentifier
newFaceCropFromImageURL:withFaceRect:groupingIdentifier:error:
newFaceCropFromImageData:withFaceRect:groupingIdentifier:error:
normalizedFaceRect
_faceCropDataForImage:andNormalizedFaceRect:error:
initWithFaceCropData:originatingFace:
_generateFaceCropWithDescriptor:andCancelBlock:error:
_reportCancellationOfRemainingFaceCropSourceDescriptors:withStartingIndex:andFailureBlock:
generateFaceCropsFromSourceDescriptors:withProgressBlock:andFailureBlock:andCancelBlock:
phFacesFromPVFaces:withFetchOptions:
deleteFaces:
changeRequestForAsset:
phFaceFromPVFace:withFetchOptions:
creationRequestForFace
assignPropertiesOfPVFace:toPHFaceChangeRequest:
placeholderForCreatedFace
setFaceAdjustmentVersion:
originatingFace
manual
faceCropData
creationRequestsForFaceCropsWithOriginatingFace:resourceData:
fetchFaceCropsWithLocalIdentifiers:options:
fetchFacesForFaceCrop:options:
isValidFaceCrop:
faceBoundsFromFaceCrop:error:
faceCropDimensionsFromFaceCrop:error:
normalizedRectForRect:inBoundsOfSize:
imageDimensions
initWithData:orientation:options:
_bestFaceForFaceDetectionRequest:withRect:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
setForceFaceprintCreation:
changeRequestForFaceCrop:
setState:
setFace:
_faceFromFaceCrop:error:
_clearDirtyStateOnFaceCrops:error:
_associateFace:withFaceCrop:error:
faceprintVersion
initWithFaceprintData:faceprintVersion:
_updateFaceprint:ofPersistedFace:error:
fetchFaceGroupsWithFace:options:
state
_faceAssociatedWithFaceCrop:
_generateAndAssociateFaceprintedFaceForFaceCrop:error:
faceAlgorithmVersion
_updateFace:withFaceCrop:error:
_recordNeedToPersonBuildOnFaceGroupContainingFace:error:
resourceData
initWithLocalIdentifier:faceCropData:
_persistGeneratedFaceCrops:forAsset:error:
fetchFaceCropsNeedingFaceDetectionWithOptions:
_pvFaceCropFromPHFaceCrop:
_processDirtyFaceCrop:error:
initWithPhotoLibrary:andContext:
_persistFaceAnalysis:forPHAsset:
generateAndPersistFaceCropsForFaces:withAsset:andImage:error:
processDirtyFaceCropsWithCancelBlock:andExtendTimeoutBlock:
_faceAnalyzer
assetResourcesForAsset:includeDerivatives:
resources
vcp_originalResource
fetchSceneClassificationsGroupedByAssetLocalIdentifierForAssets:
sceneNameFromSceneId:
assetWithPHAsset:
_cachedResources
_onceExif
_cachedExif
_onceScenes
_cachedScenes
vcp_isDecodable
vcp_exifFromImageURL:
vcp_fileSize
photoIrisProperties
photoIrisStillDisplayTime
vcp_originalVideoResource
isLocallyAvailable
assetWithURL:
vcp_livePhotoStillDisplayTime
vcp_getFpsRate
vcp_hasAdjustments:
vcp_avAsset
vcp_hasLocalSlowmo:
vcp_adjustmentsResource
vcp_assetWithoutAdjustments:duration:
vcp_smallMovieDerivativeResource
assetWithData:
detector:forceCPU:sharedModel:inputConfig:
detector:sharedModel:modelName:
handsDetection:handsRegions:cancel:
timeIntervalSinceDate:
handKeypointsDetection:box:keypoints:keypointConfidence:
normalizeKeypoints:handCenter:
computeMaxMinDistance:prevFrameKeypoints:
maxPooling:
fastSignLanguageDetection:ofPixelBuffer:withMetadata:
priorityAnalysis
majorityVoting:numClass:
minPooling:
computeIOU:boxB:
calculatePriorityScore:ofPixelBuffer:withMetadata:
_prevComputedScore
_rotationAngle
_frameCounter
_handDetectedInPreviousFrame
_handsDetector
_handsKeypointsDetector
_fastGestureDetector
_classIndexTracker
_gestureScoreTracker
_motionScoreTracker
_iouTracker
_handKeypointTracker
_prevFrameHandKeypoint
_prevTimeStampHandDetected
_prevTimeSignLanguageDetected
_prevHandCenter
numberWithUnsignedLongLong:
addImageBlurResults:
addImageCompositionResults:
addImageFaceResults:
addImageFeatureResults:
addImageJunkResults:
addImageSaliencyResults:
addImageShotTypeResults:
addLivePhotoRecommendationResults:
addLivePhotoSharpnessResults:
addMovieActivityLevelResults:
addMovieCameraMotionResults:
addMovieClassificationResults:
addMovieFaceResults:
addMovieFaceprintResults:
addMovieFeatureResults:
addMovieFineSubjectMotionResults:
addMovieInterestingnessResults:
addMovieMovingObjectResults:
addMovieMusicResults:
addMovieObstructionResults:
addMovieOrientationResults:
addMoviePreEncodeResults:
addMovieQualityResults:
addMovieSaliencyResults:
addMovieSceneResults:
addMovieSubjectMotionResults:
addMovieUtteranceResults:
addMovieVoiceResults:
addImagePetsResults:
addMovieSummaryResults:
addMovieHighlightResults:
addImageExposureResults:
addLivePhotoEffectsResults:
addImagePetsFaceResults:
addImageSceneprintResults:
addMovieSceneprintResults:
addImageHumanPoseResults:
addMovieHumanPoseResults:
addMovieApplauseResults:
addMovieBabbleResults:
addMovieCheeringResults:
addMovieLaughterResults:
addLivePhotoKeyFrameResults:
addLivePhotoKeyFrameStillResults:
addMovieHumanActionResults:
addMovieSubtleMotionResults:
addMovieLoudnessResults:
addMoviePetsResults:
addMoviePetsFaceResults:
addMovieStabilizationResults:
setAssetIdentifier:
setAssetMasterFingerprint:
setAssetAdjustedFingerprint:
imageBlurResultsCount
clearImageBlurResults
imageBlurResultsAtIndex:
imageCompositionResultsCount
clearImageCompositionResults
imageCompositionResultsAtIndex:
imageFaceResultsCount
clearImageFaceResults
imageFaceResultsAtIndex:
imageFeatureResultsCount
clearImageFeatureResults
imageFeatureResultsAtIndex:
imageJunkResultsCount
clearImageJunkResults
imageJunkResultsAtIndex:
imageSaliencyResultsCount
clearImageSaliencyResults
imageSaliencyResultsAtIndex:
imageShotTypeResultsCount
clearImageShotTypeResults
imageShotTypeResultsAtIndex:
livePhotoRecommendationResultsCount
clearLivePhotoRecommendationResults
livePhotoRecommendationResultsAtIndex:
livePhotoSharpnessResultsCount
clearLivePhotoSharpnessResults
livePhotoSharpnessResultsAtIndex:
movieActivityLevelResultsCount
clearMovieActivityLevelResults
movieActivityLevelResultsAtIndex:
movieCameraMotionResultsCount
clearMovieCameraMotionResults
movieCameraMotionResultsAtIndex:
movieClassificationResultsCount
clearMovieClassificationResults
movieClassificationResultsAtIndex:
movieFaceResultsCount
clearMovieFaceResults
movieFaceResultsAtIndex:
movieFaceprintResultsCount
clearMovieFaceprintResults
movieFaceprintResultsAtIndex:
movieFeatureResultsCount
clearMovieFeatureResults
movieFeatureResultsAtIndex:
movieFineSubjectMotionResultsCount
clearMovieFineSubjectMotionResults
movieFineSubjectMotionResultsAtIndex:
movieInterestingnessResultsCount
clearMovieInterestingnessResults
movieInterestingnessResultsAtIndex:
movieMovingObjectResultsCount
clearMovieMovingObjectResults
movieMovingObjectResultsAtIndex:
movieMusicResultsCount
clearMovieMusicResults
movieMusicResultsAtIndex:
movieObstructionResultsCount
clearMovieObstructionResults
movieObstructionResultsAtIndex:
movieOrientationResultsCount
clearMovieOrientationResults
movieOrientationResultsAtIndex:
moviePreEncodeResultsCount
clearMoviePreEncodeResults
moviePreEncodeResultsAtIndex:
movieQualityResultsCount
clearMovieQualityResults
movieQualityResultsAtIndex:
movieSaliencyResultsCount
clearMovieSaliencyResults
movieSaliencyResultsAtIndex:
movieSceneResultsCount
clearMovieSceneResults
movieSceneResultsAtIndex:
movieSubjectMotionResultsCount
clearMovieSubjectMotionResults
movieSubjectMotionResultsAtIndex:
movieUtteranceResultsCount
clearMovieUtteranceResults
movieUtteranceResultsAtIndex:
movieVoiceResultsCount
clearMovieVoiceResults
movieVoiceResultsAtIndex:
imagePetsResultsCount
clearImagePetsResults
imagePetsResultsAtIndex:
movieSummaryResultsCount
clearMovieSummaryResults
movieSummaryResultsAtIndex:
movieHighlightResultsCount
clearMovieHighlightResults
movieHighlightResultsAtIndex:
imageExposureResultsCount
clearImageExposureResults
imageExposureResultsAtIndex:
livePhotoEffectsResultsCount
clearLivePhotoEffectsResults
livePhotoEffectsResultsAtIndex:
imagePetsFaceResultsCount
clearImagePetsFaceResults
imagePetsFaceResultsAtIndex:
imageSceneprintResultsCount
clearImageSceneprintResults
imageSceneprintResultsAtIndex:
movieSceneprintResultsCount
clearMovieSceneprintResults
movieSceneprintResultsAtIndex:
imageHumanPoseResultsCount
clearImageHumanPoseResults
imageHumanPoseResultsAtIndex:
movieHumanPoseResultsCount
clearMovieHumanPoseResults
movieHumanPoseResultsAtIndex:
movieApplauseResultsCount
clearMovieApplauseResults
movieApplauseResultsAtIndex:
movieBabbleResultsCount
clearMovieBabbleResults
movieBabbleResultsAtIndex:
movieCheeringResultsCount
clearMovieCheeringResults
movieCheeringResultsAtIndex:
movieLaughterResultsCount
clearMovieLaughterResults
movieLaughterResultsAtIndex:
livePhotoKeyFrameResultsCount
clearLivePhotoKeyFrameResults
livePhotoKeyFrameResultsAtIndex:
livePhotoKeyFrameStillResultsCount
clearLivePhotoKeyFrameStillResults
livePhotoKeyFrameStillResultsAtIndex:
movieHumanActionResultsCount
clearMovieHumanActionResults
movieHumanActionResultsAtIndex:
movieSubtleMotionResultsCount
clearMovieSubtleMotionResults
movieSubtleMotionResultsAtIndex:
movieLoudnessResultsCount
clearMovieLoudnessResults
movieLoudnessResultsAtIndex:
moviePetsResultsCount
clearMoviePetsResults
moviePetsResultsAtIndex:
moviePetsFaceResultsCount
clearMoviePetsFaceResults
moviePetsFaceResultsAtIndex:
movieStabilizationResultsCount
clearMovieStabilizationResults
movieStabilizationResultsAtIndex:
imageBlurResultsType
imageCompositionResultsType
imageFaceResultsType
imageFeatureResultsType
imageJunkResultsType
imageSaliencyResultsType
imageShotTypeResultsType
imagePetsResultsType
imagePetsFaceResultsType
imageSceneprintResultsType
livePhotoEffectsResultsType
livePhotoRecommendationResultsType
livePhotoSharpnessResultsType
livePhotoKeyFrameResultsType
livePhotoKeyFrameStillResultsType
movieActivityLevelResultsType
movieCameraMotionResultsType
movieClassificationResultsType
movieFaceResultsType
movieFaceprintResultsType
movieFeatureResultsType
movieFineSubjectMotionResultsType
movieInterestingnessResultsType
movieMovingObjectResultsType
movieMusicResultsType
movieObstructionResultsType
movieOrientationResultsType
moviePreEncodeResultsType
movieQualityResultsType
movieSaliencyResultsType
movieSceneResultsType
movieSceneprintResultsType
movieSubjectMotionResultsType
movieSubtleMotionResultsType
movieUtteranceResultsType
movieVoiceResultsType
movieSummaryResultsType
movieHighlightResultsType
imageExposureResultsType
imageHumanPoseResultsType
movieHumanPoseResultsType
movieApplauseResultsType
movieBabbleResultsType
movieCheeringResultsType
movieLaughterResultsType
movieHumanActionResultsType
movieLoudnessResultsType
moviePetsResultsType
moviePetsFaceResultsType
movieStabilizationResultsType
setHasQuality:
hasQuality
setStatsFlags:
setHasStatsFlags:
hasStatsFlags
setTypesWide:
setHasTypesWide:
hasTypesWide
hasAssetAdjustedFingerprint
version
setVersion:
types
setTypes:
statsFlags
typesWide
assetIdentifier
assetModificationDate
setAssetModificationDate:
assetMasterFingerprint
assetAdjustedFingerprint
imageBlurResults
setImageBlurResults:
imageCompositionResults
setImageCompositionResults:
imageFaceResults
setImageFaceResults:
imageFeatureResults
setImageFeatureResults:
imageJunkResults
setImageJunkResults:
imageSaliencyResults
setImageSaliencyResults:
imageShotTypeResults
setImageShotTypeResults:
imagePetsResults
setImagePetsResults:
imagePetsFaceResults
setImagePetsFaceResults:
imageSceneprintResults
setImageSceneprintResults:
livePhotoEffectsResults
setLivePhotoEffectsResults:
livePhotoRecommendationResults
setLivePhotoRecommendationResults:
livePhotoSharpnessResults
setLivePhotoSharpnessResults:
livePhotoKeyFrameResults
setLivePhotoKeyFrameResults:
livePhotoKeyFrameStillResults
setLivePhotoKeyFrameStillResults:
movieActivityLevelResults
setMovieActivityLevelResults:
movieCameraMotionResults
setMovieCameraMotionResults:
movieClassificationResults
setMovieClassificationResults:
movieFaceResults
setMovieFaceResults:
movieFaceprintResults
setMovieFaceprintResults:
movieFeatureResults
setMovieFeatureResults:
movieFineSubjectMotionResults
setMovieFineSubjectMotionResults:
movieInterestingnessResults
setMovieInterestingnessResults:
movieMovingObjectResults
setMovieMovingObjectResults:
movieMusicResults
setMovieMusicResults:
movieObstructionResults
setMovieObstructionResults:
movieOrientationResults
setMovieOrientationResults:
moviePreEncodeResults
setMoviePreEncodeResults:
movieQualityResults
setMovieQualityResults:
movieSaliencyResults
setMovieSaliencyResults:
movieSceneResults
setMovieSceneResults:
movieSceneprintResults
setMovieSceneprintResults:
movieSubjectMotionResults
setMovieSubjectMotionResults:
movieSubtleMotionResults
setMovieSubtleMotionResults:
movieUtteranceResults
setMovieUtteranceResults:
movieVoiceResults
setMovieVoiceResults:
movieSummaryResults
setMovieSummaryResults:
movieHighlightResults
setMovieHighlightResults:
imageExposureResults
setImageExposureResults:
imageHumanPoseResults
setImageHumanPoseResults:
movieHumanPoseResults
setMovieHumanPoseResults:
movieApplauseResults
setMovieApplauseResults:
movieBabbleResults
setMovieBabbleResults:
movieCheeringResults
setMovieCheeringResults:
movieLaughterResults
setMovieLaughterResults:
movieHumanActionResults
setMovieHumanActionResults:
movieLoudnessResults
setMovieLoudnessResults:
moviePetsResults
setMoviePetsResults:
moviePetsFaceResults
setMoviePetsFaceResults:
movieStabilizationResults
setMovieStabilizationResults:
_assetModificationDate
_quality
_statsFlags
_typesWide
_assetAdjustedFingerprint
_assetIdentifier
_assetMasterFingerprint
_imageBlurResults
_imageCompositionResults
_imageExposureResults
_imageFaceResults
_imageFeatureResults
_imageHumanPoseResults
_imageJunkResults
_imagePetsFaceResults
_imagePetsResults
_imageSaliencyResults
_imageSceneprintResults
_imageShotTypeResults
_livePhotoEffectsResults
_livePhotoKeyFrameResults
_livePhotoKeyFrameStillResults
_livePhotoRecommendationResults
_livePhotoSharpnessResults
_movieActivityLevelResults
_movieApplauseResults
_movieBabbleResults
_movieCameraMotionResults
_movieCheeringResults
_movieClassificationResults
_movieFaceResults
_movieFaceprintResults
_movieFeatureResults
_movieFineSubjectMotionResults
_movieHighlightResults
_movieHumanActionResults
_movieHumanPoseResults
_movieInterestingnessResults
_movieLaughterResults
_movieLoudnessResults
_movieMovingObjectResults
_movieMusicResults
_movieObstructionResults
_movieOrientationResults
_moviePetsFaceResults
_moviePetsResults
_moviePreEncodeResults
_movieQualityResults
_movieSaliencyResults
_movieSceneResults
_movieSceneprintResults
_movieStabilizationResults
_movieSubjectMotionResults
_movieSubtleMotionResults
_movieSummaryResults
_movieUtteranceResults
_movieVoiceResults
_types
_version
setAttributesFromLegacyDictionary:
setResults:withClass:forPropertyKey:
exportResultsWithPropertyKey:toLegacyDictionary:withKey:
imageAnalysisFromLegacyDictionary:
movieAnalysisFromLegacyDictionary:
setX0:
setY0:
setWidth:
setHeight:
sharedModel:inputNames:
prepareModelWithAspectRatio:
creatModel
createInput:withBuffer:cnnInputHeight:cnnInputWidth:
_inputsData
_cnnOutputWidth
_cnnOutputHeight
initWithCommonFormat:sampleRate:channels:interleaved:
append:atTime:error:
initRequiringSecureCoding:
encodedData
_signature
_endTime
setIdentifier:
_identifier
setHasFaceSharpness:
hasFaceSharpness
setVanishingPoint:
setDominantLine:
vanishingPoint
dominantLine
_dominantLine
_vanishingPoint
pointWithPoint:
lineFromPoint:toPoint:
pointValue
startPointValue
endPointValue
setUnderExpose:
setHasUnderExpose:
hasUnderExpose
exposure
setExposure:
underExpose
_exposure
_underExpose
_processFormat
_peakValues
_momentaryEnergyValues
_loudnessSampleBuffer
_loudnessResults
_samplesFor100ms
_samplesForProcessingBufferList
setHasFaceQuality:
hasFaceQuality
eyeExpression
setEyeExpression:
_eyeExpression
setFeatureBlob:
featureBlob
_featureBlob
requestProcessing:ofIOSurface:withIdentifier:properties:options:andReply:
requestProcessingViaXPC:ofPixelBuffer:withOptions:andCompletionHandler:
requestProcessing:ofPixelBuffer:withOptions:andCompletionHandler:
initWithKeypointsOption:forceCPU:sharedModel:aspectRatio:modelName:
associateHands:withExisingHands:
handDistance:withhandB:
_existingHands
returnObject:
initWithObject:fromPool:
_object
_pool
initWithAllocator:
_allocator
_objects
shotType
setShotType:
_shotType
setEnd:
_end
numberWithLongLong:
addFrameInstructions:
frameInstructionsCount
clearFrameInstructions
frameInstructionsAtIndex:
setAutoloop:
setBounce:
setLongexposure:
setStabilize:
frameInstructionsType
setEpoch:
setHasEpoch:
hasEpoch
setHasFlags:
hasFlags
stabilizeResult
setStabilizeResult:
outputFrameDurValue
setOutputFrameDurValue:
cropRectX
setCropRectX:
cropRectY
setCropRectY:
cropRectHeight
setCropRectHeight:
cropRectWidth
setCropRectWidth:
timeScale
setTimeScale:
epoch
frameInstructions
setFrameInstructions:
autoloop
bounce
longexposure
stabilize
minVersion
setMinVersion:
_epoch
_outputFrameDurValue
_autoloop
_bounce
_cropRectHeight
_cropRectWidth
_cropRectX
_cropRectY
_frameInstructions
_longexposure
_minVersion
_stabilize
_stabilizeResult
_timeScale
exportToLegacyDictionaryFromFrameInstruction:
exportToLegacyDictionaryFromParam:withLoopFlavor:
setRecipeBlob:
hasRecipeBlob
loopSuggestionState
setLoopSuggestionState:
longExposureSuggestionState
setLongExposureSuggestionState:
recipeBlob
_longExposureSuggestionState
_loopSuggestionState
_recipeBlob
updateWithOptions:error:
processImage:withOptions:error:
raise
homographyParamsCount
clearHomographyParams
homographyParamAtIndex:
addHomographyParam:
homographyParams
setHomographyParams:count:
timeValue
setTimeValue:
_homographyParams
_timeValue
indexOfObject:inSortedRange:options:usingComparator:
getClosestAspectRatio:
updateModelWithResConfig:
convertSingleResultToDict:keypointConfidence:box:results:
initWithOptions:andCompletionHandler:
taskService
cancelTask:
submitTaskWithOptions:completionHandler:
taskWithOptions:andCompletionHandler:
_taskID
setLoopFadeLen:
setHasLoopFadeLen:
hasLoopFadeLen
setLoopPeriod:
setHasLoopPeriod:
hasLoopPeriod
setLoopStart:
setHasLoopStart:
hasLoopStart
errorCode
setErrorCode:
loopFadeLen
loopPeriod
loopStart
_errorCode
_loopFadeLen
_loopPeriod
_loopStart
activityScore
setActivityScore:
_activityScore
motionType
setMotionType:
isFast
setIsFast:
_motionType
_isFast
startSessionWithProperties:andReply:
initWithProperties:andResultsHandler:
setWeakSession:
processMessageWithOptions:andReply:
processVideoFragmentAssetData:withOptions:andReply:
processResults:withReply:
sessionWithProperties:andResultsHandler:
processVideoFragmentAssetData:withOptions:andErrorHandler:
processVideoFragmentAssetData:withOptions:andCompletionHandler:
processMessageWithOptions:andCompletionHandler:
_formatDescription
_resultsHandler
weakSession
_weakSession
setPixelBuffer:
calculateFrameDifference:
computeRegionsofInterest
_regions
_diff
_ptrFirst
_ptrLast
_widthBlockNum
_heightBlockNum
addClassification:
classificationsCount
clearClassifications
classificationAtIndex:
classificationType
classifications
setClassifications:
_classifications
setFaceprintBlob:
faceprintBlob
_faceprintBlob
useCPUOnly
_useCPUOnly
_maxNumHands
_humanActionWindowSize
mouthExpression
setMouthExpression:
isCloseup
setIsCloseup:
_mouthExpression
_isCloseup
clsDistanceIdentity
cloudIdentifier
filename
originalFilename
locationCoordinate
interestScore
setInterestScore:
_interestScore
approximateLocation
coordinate
gpsHorizontalAccuracy
approximateCoordinate
isCoarse
estimatedAssetCount
_personDetector
_personKeypointsDetector
energy
setEnergy:
peak
setPeak:
_energy
_peak
addBounds:
boundsCount
clearBounds
boundsAtIndex:
boundsType
initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:
retrieveBoxes:outHeight:outWidth:boxes:anchorBox:
nonMaxSuppression:
drawLine:width:height:stride:point0:point1:drawPoint:
generateHandsBoxes:
generateHandsRegions:boxes:maxNumRegions:
drawRectangle:width:height:stride:keypoints:
cnnInputWidth
cnnInputHeight
vcp_persistentStorageDirectoryURL
initWithContext:persistenceDelegate:cacheDirectoryURL:visionIntegration:
setDateFormat:
absoluteURL
stringForObjectValue:
stringByAppendingString:
URLByAppendingPathComponent:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
fileSystemRepresentation
lastPathComponent
copyItemAtURL:toURL:error:
setIncludeHiddenAssets:
setIncludeAllBurstAssets:
_appendToSuggestionsLog:
restoreClusterCacheAndSyncWithLibrary:error:
minimumSuggestionSize
suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:minimumSuggestionFaceCount:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:context:reply:
_closeSuggestionsLoggingSession
_startAndSyncClusterCacheWithLibrary:reply:
isReadyToReturnSuggestions
_openSuggestionsLoggingSession
faceClusterSequenceNumbersOfKeyFacesInAlgorithmicFaceGroupsForPerson:verifiedClusterSequenceNumbers:
_logFaceToSuggestionsLog:
requestSuggestionsForFaceClusterSequenceNumbers:withClusteringFlags:updateHandler:error:
_suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:cancel:context:error:
_finalizeSuggestionsLog
_suggestionsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:cancel:error:
distantPast
vcp_setAnalysisPreferencesValue:forKey:
vcp_personsModelFilepath
removeItemAtPath:error:
requestSuggestedMePersonIdentifierAtURL:withError:
hasProcessedForLibrary:
initWithPhotoLibrary:andDelegate:
advancedStatus
differencesBetweenClustersInClusterCacheAndLibrary:
terminate
setEventManager:
removeClusteringStateCacheWithContext:cacheDirectoryUrl:error:
setProcessed:forLibrary:
_deleteAllVerifiedPersonsWithError:
reclusterFacesWithThreshold:shouldRecluster:withContext:extendTimeout:cancel:error:
workerWithPhotoLibrary:andContext:
_copyImageAtURLToSuggestionsLoggingSession:
suggestPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:context:reply:cancel:
faceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:context:reply:
resetPersonsModelWithContext:reply:
requestSuggestedMePersonIdentifierWithContext:reply:
personPromoterStatusWithContext:reply:
validateClusterCacheWithContext:reply:
resetFaceClusteringStateWithContext:reply:
reclusterFacesWithContext:reply:extendTimeout:cancel:
rebuildPersonsWithContext:reply:extendTimeout:cancel:
_clusterer
_persistenceDelegate
_suggestionLoggingDirectory
_suggestionLoggingSessionOpen
_suggestionsLoggingEnabled
indexesOfObjectsPassingTest:
removeObjectsAtIndexes:
vcp_reportDownload:
vcp_inMemoryDownload:toData:cancel:
setCenterX:
setCenterY:
leftEyeX
leftEyeY
rightEyeX
rightEyeY
mouthX
mouthY
poseYaw
isHidden
setHidden:
isInTrash
setIsInTrash:
setAdjustmentVersion:
setTrainingType:
setGroupingIdentifier:
_vnFaceAttributeAgeToPHFaceAgeTypeMap
ageType
_vnFaceAttributeSexToPHFaceSexTypeMap
sexType
_vnFaceAttributeEyesToPHEyesStateMap
_vnFaceAttributeSmileToPHFaceSmileTypeMap
smileType
_vnFaceAttributeFacialHairToPHFacialHairTypeMap
facialHairType
_vnFaceAttributeHairColorToPHFaceHairColorTypeMap
hairColorType
_vnFaceAttributeBaldToPHFaceBaldTypeMap
baldType
_vnFaceAttributeGlassesToPHFaceGlassesTypeMap
glassesType
_phFaceAgeTypeFromPVFace:
_phFaceSexFromPVFace:
_phFaceEyesStateFromPVFace:
_phFaceSmileTypeFromPVFace:
_phFaceFacialHairTypeFromPVFace:
_phFaceHairColorTypeFromPVFace:
_phFaceBaldTypeFromPVFace:
_phFaceGlassesTypeFromPVFace:
hidden
setInTrash:
analysisType
_firstLocallyAvailableResourceFromResources:
_assetResourceLargestToSmallestComparator
preferredResourcesForFaceProcessingWithAsset:
resourceForFaceProcessing:allowStreaming:
pvImageCreationOptions
resourceForFaceProcessingWithAsset:allowStreaming:
_pvFacesArrayFromPHFetchResult:copyPropertiesOption:
configureRequest:algorithmUmbrellaVersion:
performVisionForcedCleanupWithOptions:
performVisionForcedCleanup
_readFaceAnalysisState
vcp_faceAnalysisStateFilepath
initWithContentsOfFile:
writeToFile:atomically:
_setFaceAnalysisStateValue:forKey:
setChunkSizeForFetch:
setLastMinimumFaceGroupSizeForCreatingMergeCandidate:
pv_faceProcessingProgress
_setAllFaceGroupsNeedPersonBuilding
setPersonBuilderMergeCandidatesEnabled:
clusterer
initWithPhotoLibrary:andFaceClusterer:andContext:
performPersonBuildingWithCanceler:extendTimeoutBlock:error:
_faceClusterer
_state
_lastMinimumFaceGroupSizeForCreatingMergeCandidates
_personBuilderMergeCandidatesEnabled
computeVar:index2:interVar:intraVar:
scaleRect:scaleX:scaleY:
computeActionScore
intersectionOverUnion:rect:
addActiveResults:
processPersons:humanBounds:dominantPersonIdx:frame:timestamp:duration:
_timeLastProcessFullFrame
_bodyArray
_maxScore
_keyPersonResults
_poseResults
_activePoseResults
_crop
_humanRect
_actionScoreAbsolute
_actionScoreRelative
_scoreAbsoluteMax
_scoreRelativeMax
_lastHumanTimestamp
_tracker
_tracking
initWithAssets:andCompletionHandler:
vcp_isPano
setStatisticsBlob:
statisticsBlob
_statisticsBlob
setDistanceToPreviousScene:
setHasDistanceToPreviousScene:
hasDistanceToPreviousScene
setFlickerScore:
setHasFlickerScore:
hasFlickerScore
setSceneprintDistanceToPreviousScene:
setHasSceneprintDistanceToPreviousScene:
hasSceneprintDistanceToPreviousScene
distanceToPreviousScene
flickerScore
sceneprintDistanceToPreviousScene
_distanceToPreviousScene
_flickerScore
_sceneprintDistanceToPreviousScene
hasAction
setHasAction:
_hasAction
startAndSyncClusterCacheWithLibrary:reply:
scheduleClusteringAfterRemovingFaceCSNs:addingFaceIdStrs:
numberOfAccumulatedClusterChanges
clusterIfNecessaryAndWait
clusterAndWait
performClusteringWithCompletion:
cancelClustering
setFaceClusteringThreshold:
resetFaceClusteringState:
performFaceClusteringAndWait
getClusters:threshold:utilizingGPU:error:
clustererState
_resetFaceClusteringStateWithContext:error:
clusterFacesWithExtendTimeoutBlock:andCancelBlock:
clusteringStatus
performFaceClusteringWithCompletion:
cancelFaceClustering
performFaceClusteringIfNecessaryAndWait
scheduleClusteringOfFacesWithLocalIdentifiers:
scheduleUnclusteringOfFacesWithClusterSequenceNumbers:
numberOfFacesPendingClustering
reclusterFacesWithThreshold:shouldRecluster:error:
getFaceClusters:clusteringThreshold:utilizingGPU:error:
clustererIsReadyToReturnSuggestions
resetClusterer
clusterFacesIfNecessaryWithExtendTimeoutBlock:andCancelBlock:
_visionIntegrating
fetchPersonAssociatedWithFaceGroup:options:
faceCountInFaceGroup
isDirty
setPlaybackCrop:
hasKeyFrame
hasPlaybackCrop
curationScore
setCurationScore:
autoPlayable
setAutoPlayable:
playbackCrop
_curationScore
_playbackCrop
_autoPlayable
setX:
setY:
setValue:
timescale
setTimescale:
_value
_timescale
initWithCallerIdentifier:face:andConfidence:
callerIdentifier
_callerIdentifier
lock
requestAnalysis:ofIOSurface:withProperties:withReply:
unlock
errorWithStatus:andDescription:
requestAnalysis:ofPixelBuffer:withProperties:withCompletionHandler:
_connectionLock
initFromConfigFile:numStage:numLandmarks:numTreePerStage:depthOfTree:numFeatures:
detectLandmark:width:height:stride:facerect:prevResult:result:
calculateFaceRectFromPrevLM:result:numOfLandmarks:
_internalLandmarkDetector
_numOfLandmarks
timeValuesCount
clearTimeValues
timeValueAtIndex:
addTimeValue:
homographyParamsAtIndex:
addHomographyParams:
timeValues
setTimeValues:count:
inputBoundsX
setInputBoundsX:
inputBoundsY
setInputBoundsY:
inputBoundsHeight
setInputBoundsHeight:
inputBoundsWidth
setInputBoundsWidth:
sourceSizeHeight
setSourceSizeHeight:
sourceSizeWidth
setSourceSizeWidth:
_timeValues
_inputBoundsHeight
_inputBoundsWidth
_inputBoundsX
_inputBoundsY
_sourceSizeHeight
_sourceSizeWidth
nodeForSceneClassId:
name
sceneIdFromSceneName:
numOfValidFrames
sumOfScore
initWithTimestamp:score:valid:
updateWithFirstFrame:score:valid:
updateSegment:score:valid:
updateDuration:
trimSegment:fromStart:
isContentTooShort
_sumOfScore
_numOfValidFrames
assetWriterWithURL:fileType:error:
setupMetadataTrack
initWithURL:andTrack:
finish
isReadyForMoreMediaData
popSample
appendSampleBuffer:
cancelWriting
markAsFinished
finishWritingWithCompletionHandler:
assetWriterInputWithMediaType:outputSettings:sourceFormatHint:
setTransform:
addInput:
startWriting
startSessionAtSourceTime:
processMediaRequest
requestMediaDataWhenReadyOnQueue:usingBlock:
createAssetWriterInputWithFormatDescription:
copyPixelBuffer:toPixelBuffer:
pushSample:
metadata
metadataItemsFromArray:withKey:keySpace:
setMetadata:
initWithMediaType:outputSettings:sourceFormatHint:
initWithAssetWriterInput:
assetWriterInput
canAddInput:
initWithSampleBuffer:
metadataItemsFromArray:filteredByIdentifier:
initWithItems:timeRange:
appendTimedMetadataGroup:
appendMetadataTrack
assetWriterWithURL:andTrack:
addPixelBuffer:withTime:
_writer
_metadataAdaptor
_sampleQueue
_enqueueSemaphore
_dequeueSemaphore
_completionSemaphore
_pixelBufferPool
_pts
serialQueue_
sharedInstances_
generateCurationSegment
generateInterestingTrimBasedOnCaptureTime:
updateCurationThreshold
calculateCandidateScoreWithRangeAdjust:endIdx:candidateTimeRange:captureTime:
isCurated:
isTimestampSkipable:
checkTrimAt:captureTime:
finalizeWithDestructiveTrimStart:trimEnd:andCaptureTime:
bestTrimTimeRange
_actionAnalyzer
_bestTrimTimeRange
_curationThreshold
_inTrimStart
_inTrimEnd
_captureTime
_ready
_imageURL
_movie
_mediaType
_mediaSubtypes
_pixelWidth
_pixelHeight
initWithImageURL:isSDOF:
sdofImageAssetWithURL:
initWithImageURL:andMovieURL:
nominalFrameRate
initWithMovieURL:
detectFaces:
checkAddFaces
videoChatAnalysis
analyzeFrame:
persistAnalysis
_detectionQueue
_faceTimeSession
_finished
descriptors
normalizeActivityDescriptor
initWithTimerange:andScore:
prepareActivityStats
generateActivityDescriptor
computeActivityScoreAtTime:
resetActivityStatsAtTime:
extractRequiredInfoFrom:toArray:
extractRequiredClassificationInfoFrom:toArray:
extractRequiredFaceInfoFrom:toArray:
validationScoreOfTimeRange:fromResult:startIdx:
actionScoreInTimeRange:
validateActivityScores
scaleBasedOnFaceForTimeRange:
addSceneSwitchFrequencyConstributionToActivityLevel:
addSceneClassificationContributionToActivityLevel:
initWithFrameStats:
preProcessQualityResults:interestingnessResults:obstructionResults:classificationResults:fineActionResults:faceResults:sceneSwitchFrequency:
finishAnalysisPass:fpsRate:
_activityDescriptor
_activityScores
_validActivityScores
_interestingnessResults
_obstructionResults
_classificationResults
_fineActionResults
_sceneSwitchFrequency
_lastProcessTime
_overallActivityLevel
_sportsSceneId
spatialDescriptorWithMvMagnitudeMean:
_widthInMb
_heightInMb
_motionMagnitudeHistogram
_motionMagnitude
createModel
prepareData:
detect
keypointsFromObservations:
analyzeBodyArray:
_inputChannels
_action
_poseRequest
_valid
dependencies
initWithTransform:withExistingFaceprints:frameStats:
initWithTransform:frameStats:faceDominated:
faceDetectorWithTransform:withExistingFaceprints:frameStats:tracking:faceDominated:cancel:
faceRanges
_angle
_timeLastDetection
_activeFaces
bufferRotated
_bufferRotated
initWithFace:andFace:andScore:
face1
face2
_face1
_face2
observationWithBoundingBox:
CGImage
initWithURL:orientation:options:
initWithCGImage:orientation:options:
initWithFaceObservations:
_faceObservationsWithBBoxFromPVFaces:mapping:
_bboxAlignedFaceObservationsFromFaceObservations:inImage:withError:
height
width
faceId
alignedBoundingBoxAsCGRect
faceMergeFaceprintDistanceThreshold
getDistance:toOtherFaceprint:error:
_alignBBoxForPVFaces:forImage:
setCoordinatesAndFeaturesFromFace:
_sortedViableFaceMergePairsFromQueryFaces:andCandidateFaces:
sortedViableMergeCandidateFacesFor:from:ignoreSourceAssetDimensions:matchScores:
initWith:confidence:
setBound:
_bound
parseResults:toDetections:atTime:fromTime:addActiveRegions:
addDetectionToDict:withActiveRegions:forPetsDetections:fromTime:
_petsDetections
_petsFaceDetections
_timeLastProcess
_petsStart
_petsFaceStart
_petsAnalyer
_petsActiveRegions
_petsFaceActiveRegions
setPose:
_pose
updateModelByAddingFaces:andRemovingFaces:canceller:error:
updateModelByAddingFaces:error:
vcp_updateModelByAddingFaces:
compareFace:withFace:
removeSmallestKeyFace
detectTrackFacesInFrame:withTimestamp:faces:
requestRevision
initWithType:cachePath:state:threshold:requestRevision:
clustererBuilderWithOptions:error:
objects
initForReadingFromData:error:
clusterFaces
updateWithExistingFaces
locationChange:relativeTo:landscape:
_latestTrackID
_smileDetector
_poseEstimator
_existingFaceprints
_latestFrameArea
_faceTrackers
_keyFaces
_reservedIDs
_facePrints
_allFaces
_frameFaceResults
hasMeaningfulSceneSegment:withFpsRate:
assetQualityScoreFromAnalysis:withFpsRate:
assetActionScoreFromAnalysis:
assetExpressionScoreFromAnalysis:
assetVoiceScoreFromAnalysis:
assetJunkScoreFromAnalysis:
assetCameraMotionScoreFromAnalysis:
scaleForTimeRange:basedOnFace:
isJunkTimeRange:basedOnResults:
subjectActivityInTimeRange:fromResults:
cameraActivityfromQuality:
assetActivityLevelFromAnalysisResults:
faceSharpness
isHeadingFrame
computeGlobalQuality
computeScoreFromColorfulness
computeScoreFromExposure
computeExpressionScore
computeScoreFromAction
computeGlobalQualityForLivePhoto
computeVisualPleasingScore
computePenaltyScore
computeContentScore
computeCurationScoreComponents
storeFrameResults
printStats
setFrameResults:
_subjectAction
_cameraMotion
_interestingness
_obstruction
_colorfulness
_subMb
_isHeadingFrame
_semanticScore
_faceSharpness
_expressionChangeScore
_frameResults
initWithLivePhoto:
setKeyFrameTime:isHeadingFrame:
prepareFrameStats:
computeSharpnessOfFrame:
computeFaceQualityOfFrame:
finalizeKeyFrame
loadKeyFrameResult:timestamp:
adjustScoreByFace
modulateByJunk
modulateByTimeRange
setBlurAnalyzerFaceResults:
setFaceSharpness:
computeCurationScore
frameResults
hasGoodSubjectAction
setIsHeadingFrame:
resetStatsFlag
loadKeyFrameResults:
setFaceStatsFlag:detectedFaces:
setExpressionChangeScore:
setMotionStatsFlag:cameraMotion:subjectAction:interestingness:obstruction:colorfulness:exposureScore:humanActionStatsFlag:humanPoseScore:humanActionScore:subMb:
modulateByExposure
computeMinDistanceBetween:withSet:
_faceQualityAnalyzer
_keyFrames
_activeKeyFrame
_keyFrameScores
_inputKeyFrameResults
minProcessTimeIntervalInSecs
detectFaces:faces:
_lastestFaceID
_numFacesLastFrame
_lastVertices
_lastJawOpenness
initWithRequestAnalyses:formatDescription:
items
time
resetSegment:atTime:
focusStatus
addSegmentToResults
initWithFocusStatus:atTime:
updateSegment:atTime:
processFrameMetadata:
_mutableResults
setFocusStatus:
_focusStatus
hadZoom
setHadZoom:
minZoom
setMinZoom:
maxZoom
setMaxZoom:
_minZoom
_maxZoom
readGyroHomographyDimension:
gyroHomographyVersionIsValid:
readSoftwareStackVersion:
referenceSoftwareStackVersion
compareSoftwareStackVersion:withReferenceVersion:
getSetupDataFrom:
getFirstAtomWithFourCharCode:fromSetupData:
compareNumericVersion:withReferenceVersion:
componentsSeparatedByString:
numberFromString:
numberWithChar:
increaseLengthBy:
resetBytesInRange:
convertLivePhotoStruct:toDictionary:
dataType
dataValue
convertLivePhotoBinary:toDictionary:
defaultDesiredKeys
_prevEstimatedCenterMv
_deSerializedMetaBuffer
_metaFocusAnalyzer
_metaMotionAnalyzer
_requestAnalyses
_metadataStabilizationArray
_frameTimestampArray
_originalFrameTimestampArray
_metaLensSwitchAnalzer
_gyroHomographyIsValid
_gyroHomographyDimension
stabilityScore
decideSegmentPointBasedOn:
initWithAbsMotion:atTime:
absMotion
_hinkleyDetector
setAbsMotion:
setStabilityScore:
_absMotion
_stabilityScore
numberValue
setupTrackerWithReferenceFrame:withROI:
trackInFrame:
lostTrackInd
initWithObjectBounds:inFrame:timestamp:
trackObjectInFrame:
objectBoundsInitial
objectBounds
lostCount
_correlationTracker
_lostCount
_objectBoundsInitial
_objectBounds
initWithPlistRepresentation:
attachSalientRegions:toPixelBuffer:
plistRepresentation
isOutOfBoundary:
updateConfidence:prevBound:newBound:width:height:
pruneRegions:withOverlapRatio:
boundDistance:relativeTo:landscape:
_detections
_latestRegions
_timeLastTracking
_saliencyAnalyer
_trackers
_confidences
_activeRegions
initWithSceneId:withDuration:withConfidence:
sceneId
setSceneId:
setDuration:
sumConfidence
setSumConfidence:
_duration
_sumConfidence
_sceneId
addResult:start:duration:keyIsName:
compareObjectsOfInterest:withScenes:
addAggregatedScenes:timerange:
frameScenes
sceneResults
setSceneResults:
_existingScenes
_sceneTaxomy
_internalFrameScenes
naturalSize
decodeDimensionsForTrack:
settings
getNextCaptureSampleBuffer
_track
initWithTrack:timerange:withSettings:applyTransform:
assetReaderWithAsset:error:
cancelReading
track
initWithTrack:timerange:
_assetReader
_trackOutput
_nextSample
_status
initWithTrack:timerange:atInterval:
_decodeEnd
_sampleDuration
_nextSampleTime
_currentSample
assetReaderSampleReferenceOutputWithTrack:
canAddOutput:
findNextSample:timerange:
decodeSample:sample:
decodeTask
_trackReader
_launchOnce
_group
_inputSemaphore
_outputSemaphore
_cancelDecode
_decodeError
_decodeFinished
_decodedFrames
_outputFrameIdx
_sampleBuffer
setVoiceDetections:
_audioStream
_voiceActivity
_voiceStart
_voiceDetections
_utteranceDetections
_musicDetections
dictionaryWithContentsOfURL:
addDetectionFromTime:toTime:result:
setupWithAudioStream:
loadModel
_voiceActivityNew
_audioUnit
fetchRequest
setBox:
stableInd
setStableInd:
setLostTrackInd:
stable
lostTrack
@28@0:8Q16B24
v16@0:8
@16@0:8
i24@0:8^{opaqueCMSampleBuffer=}16
i88@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}24
i24@0:8r^{?=qiIq}16
i40@0:8@16@?24^@32
{AudioTimeStamp="mSampleTime"d"mHostTime"Q"mRateScalar"d"mWordClockTime"Q"mSMPTETime"{SMPTETime="mSubframes"s"mSubframeDivisor"s"mCounter"I"mType"I"mFlags"I"mHours"s"mMinutes"s"mSeconds"s"mFrames"s}"mFlags"I"mReserved"I}
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
@"VCPVoiceDetector"
@"VCPAudioClassifier"
@"VCPLoudnessAnalyzer"
@"VCPSongDetector"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v32@0:8@16@24
v24@0:8@16
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
v24@0:8@"<SNRequest>"16
@52@0:8{?=qiIq}16f40@44
v36@0:8r^{?=qiIq}16r^{?=qiIq}24f32
@"NSMutableArray"
{?="value"q"timescale"i"flags"I"epoch"q}
@"NSString"
@24@0:8Q16
i28@0:8^{opaqueCMSampleBuffer=}16i24
@"SNAudioStreamAnalyzer"
@"AVAudioPCMBuffer"
@80@0:8Q16@24{CGSize=dd}32{CGRect={CGPoint=dd}{CGSize=dd}}48
@24@0:8@16
@44@0:8B16@20B28B32B36B40
i16@0:8
i24@0:8@16
i40@0:8^i16^i24^I32
i28@0:8f16i20i24
i24@0:8^{__CVBuffer=}16
i36@0:8^{__CVBuffer=}16^f24i32
i24@0:8i16i20
i40@0:8^f16^{__CVBuffer=}24i32i36
i48@0:8^{__CVBuffer=}16^Q24^@32@?40
v20@0:8B16
@"VCPCNNModelEspresso"
@"NSURL"
v80@0:8{?={?=qiIq}{?=qiIq}}16@64@72
v96@0:8@16@24{?={?=qiIq}{?=qiIq}}32@80@88
@32@0:8@16d24
@24@0:8^{_NSZone=}16
v20@0:8f16
d16@0:8
v24@0:8d16
f16@0:8
{?="contentScore"b1"globalQualityScore"b1}
f40@0:8*16i24i28q32
i40@0:8^f16@24^{__CVBuffer=}32
@36@0:8f16f20f24f28f32
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8f16f20
@"NSDictionary"16@0:8
@24@0:8@"NSDictionary"16
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24^f32i40i44
f52@0:8^f16i24i28i32*36f44i48
i52@0:8^{__CVBuffer=}16^f24^f32f40@?44
f24@0:8^f16
^f40@0:8i16i20^i24^i32
i48@0:8^f16*24f32i36@?40
v56@0:8*16q24^f32q40i48i52
@"VCPLoaned"
#20@0:8i16
@36@0:8i16i20i24B28B32
@48@0:8i16i20i24B28B32i36i40B44
i32@0:8@16@24
@"VCPCNNData"
B20@0:8i16
i28@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16s24
@36@0:8i16i20i24@28
i20@0:8B16
i28@0:8^{__CVBuffer=}16i24
^f16@0:8
v24@0:8^f16
@"VCPCNNMetalContext"
^v20@0:8B16
@24@0:8B16B20
^v16@0:8
i56@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
@20@0:8i16
i52@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16^f24^f32i40i44i48
i36@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16i24i28i32
i32@0:8^{__CVBuffer=}16^f24
i72@0:8^f16^{__CVBuffer=}24i32i36{CGRect={CGPoint=dd}{CGSize=dd}}40
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^B56
@72@0:8@16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40
v68@0:8{CGAffineTransform=dddddd}16B64
@32@0:8B16B20@24
i36@0:8^{CGPoint=dd}16^f24f32
^f48@0:8i16i20^i24^i32^f40
i64@0:8^f16i24i28i32i36i40^{CGPoint=dd}44^f52f60
i48@0:8^{__CVBuffer=}16@24[21{CGPoint=dd}]32[21f]40
@20@0:8B16
@"<MTLDevice>"
@"<MTLCommandQueue>"
@"<MTLCommandBuffer>"
f32@0:8@16@24
@40@0:8^{opaqueCMSampleBuffer=}16@24^@32
v48@0:8@16i24i28^f32^f40
f48@0:8{CGPoint=dd}16{CGPoint=dd}32
{CGSize=dd}32@0:8@16^@24
I16@0:8
B32@0:8@16^@24
@"VCPImageHumanPoseAnalyzer"
@"NSArray"
@24@0:8s16B20
[200@"VCPCNNBlock"]
@48@0:8@16@24@32@40
i24@0:8^f16
i40@0:8{vector<float *, std::__1::allocator<float *> >=^^f^^f{__compressed_pair<float **, std::__1::allocator<float *> >=^^f}}16
{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t> >=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t> >=^{?}}}16@0:8
v40@0:8{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t> >=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t> >=^{?}}}16
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
v184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
{?="plan"^v"network_index"i}
@"VCPCNNEspressoContext"
{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t> >="__begin_"^{?}"__end_"^{?}"__end_cap_"{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t> >="__value_"^{?}}}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
i52@0:8^f16i24i28@32@40i48
i48@0:8^{__CVBuffer=}16@24@32@?40
@"VCPProtoTimeRange"
i40@0:8@16@24@?32
@28@0:8i16i20i24
B72@0:8{?=qiIq}16{?=qiIq}40^@64
@"VCPVideoProcessorSession"
@"NSArray"16@0:8
v24@0:8@"<PVFetchResultProtocol>"16
@"<PVFaceProtocol>"16@0:8
v24@0:8@"<PVFaceProtocol>"16
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^q56
B40@0:8@16@24^@32
B88@0:8{?={?=qiIq}{?=qiIq}}16{?=qiIq}64
B56@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24^@48
B32@0:8^{opaqueCMSampleBuffer=}16^@24
B48@0:8{?=qiIq}16^@40
v20@0:8I16
@"NSObject<OS_dispatch_queue>"
{CF<opaqueCMSampleBuffer *>="value_"^{opaqueCMSampleBuffer}}
@"VCPCNNModel"
@44@0:8@16@24@32i40
@"VCPDatabaseReader"
@"NSSet"
@"NSDictionary"
@"PHAsset"
i36@0:8^{sqlite3_stmt=}16i24@28
i40@0:8^{sqlite3_stmt=}16i24i28@32
i40@0:8@16^@24^q32
i32@0:8q16@24
i40@0:8q16@24@32
@32@0:8Q16Q24
^{sqlite3=}
Q28@0:8@16f24
v24@0:8Q16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@56@0:8^f16^f24Q32Q40i48i52
i28@0:8f16f20f24
i36@0:8^f16f24^f28
i64@0:8^f16Q24Q32{DSPSplitComplex=^f^f}40^f56
B28@0:8i16i20i24
{DSPSplitComplex="realp"^f"imagp"^f}
i52@0:8@16B24@?28^Q36^@44
@44@0:8Q16Q24B32@?36
@36@0:8Q16B24@?28
@"NSObject<OS_dispatch_source>"
@32@0:8@16Q24
{CGAffineTransform=dddddd}20@0:8I16
i32@0:8@16^Q24
i32@0:8^Q16^@24
@"NSMutableDictionary"
Q36@0:8B16Q20Q28
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8Q16Q24
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8Q16Q24{CGAffineTransform=dddddd}32
q16@0:8
v24@0:8q16
v20@0:8i16
@"VNFaceObservation"
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
{mach_timebase_info="numer"I"denom"I}
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@"NSDate"
@"NSTimeZone"
v40@0:8^{__CVBuffer=}16@24@?32
v40@0:8@16@24@?32
@"VCPTaskProcessingService"
B32@0:8@?16^@24
d24@0:8@16
@"NSURL"16@0:8
B32@0:8@?<v@?>16^@24
@"<PVFetchResultProtocol>"24@0:8@"NSArray"16
@"<PVFetchResultProtocol>"24@0:8Q16
@"<PVFetchResultProtocol>"24@0:8@"<PVMomentProtocol>"16
@"<PVFetchResultProtocol>"24@0:8@"<PVPersonProtocol>"16
@"NSDictionary"24@0:8@"<PVFetchResultProtocol>"16
@"<PVFetchResultProtocol>"32@0:8@"<PVPersonProtocol>"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"32@0:8@"NSArray"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"24@0:8@"<PVFaceGroupProtocol>"16
@"<PVFetchResultProtocol>"16@0:8
@"NSDate"16@0:8
@"NSSet"16@0:8
@32@0:8@16@24
v32@0:8@16Q24
i72@0:8^@16^@24^@32^@40^@48^@56^@64
i32@0:8^@16^@24
v32@0:8@16^{CGRect={CGPoint=dd}{CGSize=dd}}24
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i40@0:8^@16^@24@32
v40@0:8@16@24@32
q32@0:8@16Q24
@60@0:8@16Q24Q32@40i48^@52
i56@0:8^@16@24@32Q40Q48
@40@0:8@16@24^@32
i40@0:8^@16@24@32
i48@0:8@16@24@32^@40
@"PVContext"
@"VCPFaceMerger"
@"NSObject<OS_dispatch_group>"
@"VCPObjectPool"
@28@0:8i16f20f24
f24@0:8f16B20
Q24@0:8Q16
@"NSData"
@64@0:8{CGAffineTransform=dddddd}16
@72@0:8@16@24@32@40B48B52f56f60f64B68
i48@0:8^{__CVBuffer=}16{?=qiIq}24
i80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^Q80
i40@0:8{?=qiIq}16
f40@0:8@16^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}24i32i36
i64@0:8{?={?=qiIq}{?=qiIq}}16
i20@0:8i16
v24@0:8^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}16
f24@0:8^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}16
i36@0:8@16@24B32
i44@0:8^{__CFArray=}16@24@32B40
v24@0:8^{__CVBuffer=}16
v32@0:8^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}16@24
^{EncodeAnalysis=ii*^{__CVBuffer}{Translation=fff}^q^q^i^i^i^{Translation}^{FrameBuffer}^{EncodeStats}ff{MotionFieldAnalysis=^{EncodeStats}^f^f*iiiifffBB[2^i][2*][2^f][2^s][2^f][2i][2^i][2^f][2^f]{map<int, CGRect, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, CGRect> > >={__tree<std::__1::__value_type<int, CGRect>, std::__1::__map_value_compare<int, std::__1::__value_type<int, CGRect>, std::__1::less<int>, true>, std::__1::allocator<std::__1::__value_type<int, CGRect> > >=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<int, CGRect>, void *> > >={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<int, std::__1::__value_type<int, CGRect>, std::__1::less<int>, true> >=Q}}}{ObjectDetection={Vector<ma::Object *>=^{__CFArray}}^{MotionVector}^f^i^i^iiiB}{ObjectTracking={Object=i{CGRect={CGPoint=dd}{CGSize=dd}}{CGPoint=dd}{CGPoint=dd}BffffB}{Object=i{CGRect={CGPoint=dd}{CGSize=dd}}{CGPoint=dd}{CGPoint=dd}BffffB}Bii^f^f^f^f^f^f^fqq^fiiqi{Vector<ma::ObjectTracking::Expert *>=^{__CFArray}}B}}[10f]{?=iii}{?=iiiiii}{?=iiiiii}{?=qiIq}fi^f^fBBqfff}
^{PreEncodeAnalysis=BB^{__CFData}^{__CFArray}B{Vector<unsigned int>=^{__CFArray}}{Vector<unsigned short>=^{__CFArray}}{Vector<float>=^{__CFArray}}{Vector<float>=^{__CFArray}}{?=qiIq}iQQ{EncodeParameters=iiIIISS}ffff{?=qiIq}dI}
^{ObstructionAnalysis={Vector<ma::ObstructionSegment *>=^{__CFArray}}^{ObstructionSegment}^{__CFArray}{?=qiIq}Bf}
^{SceneAnalysis={Vector<ma::SceneSegment *>=^{__CFArray}}^{SceneSegment}^{__CFArray}{?=qiIq}BffBBBBBiiB{CameraMotionAnalysis={Vector<ma::CameraMotionSegment *>=^{__CFArray}}^{CameraMotionSegment}^{__CFArray}{?=qiIq}Bf[6{HinkleyDetector=ffi{HinkleyStats=ffff}}]i{RotationAnalysis={Vector<ma::RotationSegment *>=^{__CFArray}}^{RotationSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}i}BB}{SubjectMotionAnalysis={Vector<ma::SubjectMotionSegment *>=^{__CFArray}}^{SubjectMotionSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}}{FineSubjectMotionAnalysis={Vector<ma::FineSubjectMotionSegment *>=^{__CFArray}}^{FineSubjectMotionSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}B}{SubtleMotionAnalysis={Vector<ma::SubtleMotionSegment *>=^{__CFArray}}^{SubtleMotionSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}B}{TrackingAnalysis={Vector<ma::TrackSegment *>=^{__CFArray}}^{TrackSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}}{DescriptorAnalysis={Vector<ma::DescriptorSegment *>=^{__CFArray}}^{DescriptorSegment}^{__CFArray}{?=qiIq}Bf^{Rotator}^{__CFArray}}{MovingObjectAnalysis={Vector<ma::MovingObjectSegment *>=^{__CFArray}}^{MovingObjectSegment}^{__CFArray}{?=qiIq}Bfi}{InterestingnessAnalysis={Vector<ma::InterestingnessSegment *>=^{__CFArray}}^{InterestingnessSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}}{QualityAnalysis={Vector<ma::QualitySegment *>=^{__CFArray}}^{QualitySegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}{?=qiIq}f^{FrameBuffer}ffffiiiBBB{?=qiIq}ff^{__CFArray}^{__CFArray}^{__CFArray}^{__CFArray}}{SlowMotionAnalysis={Vector<ma::SlowMotionSegment *>=^{__CFArray}}^{SlowMotionSegment}^{__CFArray}{?=qiIq}Bf^{FrameBuffer}^{__CVBuffer}{HinkleyDetector=ffi{HinkleyStats=ffff}}}}
^{MotionFilter=^{FrameBuffer}BB}
^{MetaDataAnalysis=B^{FrameBuffer}{Translation=fff}{Translation=fff}}
^{IrisAnalysis=ffiiB^{__CFArray}}
{FrameBuffer="frame_count_"i"buffer_"[35{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}]}
{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}
@"VCPFrameAnalysisStats"
@"VCPFrameScoreFilter"
@"VCPMotionFlowSubtleMotionAnalyzer"
@40@0:8i16i20Q24Q32
i56@0:8i16i20r^f24^f32Q40Q48
i60@0:8{Kernel=^fQQ}16f40f44f48f52f56
^^{Kernel}
@36@0:8^f16i24i28f32
i28@0:8i16@20
i48@0:8^f16^{__CVBuffer=}24i32i36@40
i40@0:8^{__CVBuffer=}16@24@32
i40@0:8^{__CVBuffer=}16@24@?32
i84@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56B72@76
i44@0:8^f16i24i28B32*36
@36@0:8@16B24Q28
@28@0:8@16B24
v40@0:8@16@24f32f36
f28@0:8@16f24
i40@0:8^{__CVBuffer=}16^f24@?32
i32@0:8^f16^{__CVBuffer=}24
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24@32i40i44
i52@0:8^{__CVBuffer=}16^Q24f32^@36@?44
[16f]
@"VCPCNNBlurAnalyzer"
@24@0:8@?16
B24@0:8^@16
@?16@0:8
v24@0:8@?16
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__1::__cxx_atomic_base_impl<bool> >="__a_value"AB}}
i32@0:8^{CGImage=}16^^{__CVBuffer}24
^{CGColorSpace=}
^{CGContext=}
^{__CVPixelBufferPool=}
@24@0:8^{__CVBuffer=}16
i32@0:8^f16@24
@"NSData"16@0:8
i32@0:8^f16@"<VCPDistanceDescriptorProtocol>"24
@24@0:8@"NSData"16
@"VNImageprint"
f56@0:8*16*24*32i40i44q48
f48@0:8*16i24i28q32*40
Q32@0:8@16@24
Q24@0:8@16
Q40@0:8@16@24Q32
i40@0:8@16Q24^@32
i40@0:8^@16@24Q32
i40@0:8^f16@24Q32
B80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
@40@0:8@16@24@?32
@"PHPhotoLibrary"
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
i44@0:8Q16Q24i32^^{__CVBuffer}36
i28@0:8^^{__CVBuffer}16i24
i48@0:8@16i24Q28^^{__CVBuffer}36B44
i44@0:8^{CGImage=}16I24Q28^^{__CVBuffer}36
i44@0:8^{CGImageSource=}16i24Q28^^{__CVBuffer}36
^{__CVBuffer=}48@0:8i16Q20@28@36B44
^{__CVBuffer=}28@0:8@16i24
^{__CVBuffer=}36@0:8@16i24Q28
^{__CVBuffer=}32@0:8i16@20B28
^{__CVBuffer=}36@0:8i16Q20@28
^{FigPhotoDecompressionSession=}
^{OpaqueVTPixelTransferSession=}
v40@0:8Q16Q24@?32
@40@0:8@16@24@32
v40@0:8@16Q24@?32
@24@0:8^@16
@36@0:8@16I24@28
@28@0:8@16I24
B56@0:8@16@24@32^@40^@48
B48@0:8@16Q24@32^@40
B44@0:8@16B24@28^@36
@32@0:8Q16^@24
B72@0:8@16@24@32@40@?48@56^@64
v56@0:8@16@?24@32@40@?48
@56@0:8@16@24@32@40^@48
@"NSSet"24@0:8^@16
@"NSArray"36@0:8@"NSArray"16I24@"NSMutableArray"28
@"NSArray"28@0:8@"NSArray"16I24
@"NSArray"24@0:8@"PHAsset"16
@"NSSet"40@0:8@"NSSet"16@"PVCanceler"24^@32
B56@0:8@"NSArray"16@"NSArray"24@"PHAsset"32^@40^@48
B48@0:8@"NSArray"16Q24@"PVCanceler"32^@40
B32@0:8@"PVCanceler"16^@24
B40@0:8@"PVFaceprint"16@"PVFace"24^@32
B32@0:8@"NSArray"16^@24
@"NSArray"24@0:8Q16
@"NSString"40@0:8@"PVFace"16@"PVFaceCrop"24^@32
@"PVFace"24@0:8@"PVFaceCrop"16
B44@0:8@"NSArray"16B24@"PVCanceler"28^@36
@"NSMutableArray"32@0:8Q16^@24
B72@0:8@"NSDictionary"16@"NSDictionary"24@"NSMutableSet"32@"NSMutableSet"40@?<v@?>48@"PVCanceler"56^@64
B32@0:8@"PVFace"16^@24
v56@0:8@"<PVFaceClusteringProtocol>"16@?<v@?@"NSArray">24@"PVCanceler"32@"PVContext"40@?<v@?>48
@"NSString"56@0:8@"NSString"16@"<PVFaceClusteringProtocol>"24@"PVCanceler"32@"PVContext"40^@48
v24@0:8@"NSString"16
@44@0:8@16@24B32@?36
@48@0:8@16d24Q32@?40
@"<PVFaceProtocol>"40@0:8@"<PVPersonProtocol>"16@"NSMapTable"24@?<v@?f^B>32
@"NSString"40@0:8@"PVPersonClusterManager"16@"NSSet"24@?<v@?f^B>32
@"NSArray"44@0:8@"PVPersonClusterManager"16@"NSSet"24B32@?<v@?f^B>36
@"NSArray"48@0:8@"NSArray"16d24Q32@?<d@?@@>40
v56@0:8@16@24^@32@40@48
B48@0:8@16@24@32^@40
B40@0:8Q16@24^@32
v48@0:8@16@24@32@?40
v112@0:8^@16^@24^@32^@40^@48^@56^@64^@72^@80@88@96@104
v56@0:8^@16^@24^@32@40@48
B112@0:8@16@24@32@40@48@56@64@72@?80@88@96^@104
Q32@0:8Q16@24
v64@0:8@16@24@32@40@48@56
v56@0:8@16@24@?32@40@48
@32@0:8@16^@24
@"VCPCNNPetsDetector"
i36@0:8@16f24@?28
@24@0:8i16B20
i40@0:8^{__CVBuffer=}16^f24i32i36
f40@0:8^f16i24i28i32i36
i32@0:8^f16i24i28
i24@0:8@?16
[5{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}]
[5f]
i44@0:8^^{__CVBuffer}16^^{__CVBuffer}24@32B40
{CF<__CVPixelBufferPool *>="value_"^{__CVPixelBufferPool}}
i28@0:8^^{__CVPixelBufferPool}16I24
i36@0:8^{__CVBuffer=}16^^{__CVBuffer}24B32
i52@0:8@16B24^@28@36^^{__CVBuffer}44
i112@0:8^@16^@24^@32^@40^@48^@56^@64^@72^@80^@88^@96^@104
v80@0:8@16@24@32@40@48@56@64@72
i112@0:8^@16@24@32@40@48@56@64@72@80@88@96@104
i32@0:8^@16@24
i40@0:8^@16^{__CVBuffer=}24@32
i40@0:8^@16^{__CVBuffer=}24B32B36
i32@0:8^@16^{__CVBuffer=}24
i48@0:8^@16B24B28@32^{__CVBuffer=}40
v40@0:8@16B24B28@?32
i48@0:8^{__CVBuffer=}16B24B28^@32@?40
@"VCPSceneProcessingImageManager"
@"PVSceneTaxonomy"
{CF<OpaqueVTPixelTransferSession *>="value_"^{OpaqueVTPixelTransferSession}}
B32@0:8@16@24
{CGSize=dd}32@0:8@16@24
i40@0:8^@16#24@32
^{__CVBuffer=}36@0:8@16@24i32
i52@0:8^@16#24@32@40B48
i48@0:8^f16@24@32@40
i40@0:8^f16@24@32
@40@0:8^{__CVBuffer=}16@24@?32
@40@0:8^{__CVBuffer=}16@"NSDictionary"24@?<v@?@"NSDictionary"@"NSError">32
@40@0:8@"NSURL"16@"NSDictionary"24@?<v@?@"NSDictionary"@"NSError">32
{CF<__CVBuffer *>="value_"^{__CVBuffer}}
f24@0:8@16
i32@0:8[6f]16[6f]24
i24@0:8^{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}16
v80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@?72
{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}
^{EncodeStatsHW=^^?^B^B^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBiii^{OpaqueVTCompressionSession}^{__CFData}{?=qiIq}iiB}
[6[5f]]
i40@0:8@16@?24^Q32
i32@0:8@?16^Q24
@"AVAsset"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
@148@0:8Q16{CGAffineTransform=dddddd}24{?={?=qiIq}{?=qiIq}}72B120@124B132B136@140
v56@0:8@16@24@32{CGSize=dd}40
@"VCPVideoKeyFrameAnalyzer"
@"VCPMovieHighlightAnalyzer"
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
{CGSize="width"d"height"d}
@44@0:8{?=qiIq}16f40
@76@0:8{?={?=qiIq}{?=qiIq}}16f64@68
{?={?=qiIq}{?=qiIq}}16@0:8
@"VCPVideoKeyFrameResult"
@64@0:8{?={?=qiIq}{?=qiIq}}16
v64@0:8{?={?=qiIq}{?=qiIq}}16
@"VCPImageDescriptor"
@"VCPVideoKeyFrame"
@36@0:8Q16B24B28B32
i144@0:8@16@24@32@40@48@56@64@72@80@88@96@104@112@120{CGSize=dd}128
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{?={?=qiIq}{?=qiIq}}16
{?={?=qiIq}{?=qiIq}}68@0:8{?={?=qiIq}{?=qiIq}}16B64
{?={?=qiIq}{?=qiIq}}64@0:8{?={?=qiIq}{?=qiIq}}16
B64@0:8{?={?=qiIq}{?=qiIq}}16
f64@0:8{?={?=qiIq}{?=qiIq}}16
v60@0:8i16@20@28Q36@44@?52
v48@0:8i16@20@28B36@?40
v52@0:8i16Q20@28@36@?44
v60@0:8i16Q20@28@36@44@?52
v60@0:8i16@20@28@36@44@?52
v48@0:8i16@20B28@32@?40
v44@0:8i16@20@28@?36
v36@0:8i16@20@?28
v40@0:8i16B20@24@?32
v32@0:8@16@?24
v60@0:8i16@"NSArray"20@"NSDictionary"28Q36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v48@0:8i16@"NSURL"20@"NSArray"28B36@?<v@?@"NSDictionary"@"NSError">40
v52@0:8i16Q20@"NSURL"28@"NSDictionary"36@?<v@?@"NSError">44
v60@0:8i16Q20@"NSArray"28@"NSURL"36@"NSDictionary"44@?<v@?@"NSDictionary"@"NSError">52
v24@0:8@?<v@?@"NSError">16
v24@0:8@"NSURL"16
v60@0:8i16@"NSString"20@"NSArray"28@"NSArray"36@"NSURL"44@?<v@?@"NSArray"@"NSError">52
v48@0:8i16@"NSArray"20B28@"NSURL"32@?<v@?B@"NSError">40
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?@"NSArray"@"NSError">36
v36@0:8i16@"NSURL"20@?<v@?B@"NSError">28
v44@0:8i16@"NSDictionary"20@"NSURL"28@?<v@?@"NSString"@"NSError">36
v40@0:8i16B20@"NSURL"24@?<v@?@"NSDictionary"@"NSError">32
v36@0:8i16@"NSURL"20@?<v@?@"NSDictionary"@"NSError">28
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?B@"NSError">36
v32@0:8@"NSURL"16@?<v@?@"NSDictionary"@"NSError">24
v32@0:8@"NSURL"16@?<v@?@"NSString"@"NSError">24
v28@0:8d16i24
i56@0:8Q16@24@32@?40@?48
i44@0:8@16B24@?28@?36
i48@0:8Q16@24@?32@?40
i48@0:8@16@24@?32@?40
i32@0:8@16@?24
@"NSXPCConnection"
i64@0:8@16@24@32@40@?48@?56
i52@0:8@16B24@28@?36@?44
i40@0:8@16@?24@?32
i44@0:8B16@20@?28@?36
v48@0:8@"NSDictionary"16@"NSString"24@"NSURL"32@?<v@?>40
v40@0:8@"NSString"16@"NSURL"24@?<v@?@"NSString">32
q24@0:8@16
Q32@0:8Q16Q24
@52@0:8@16Q24@32@40B48
@48@0:8Q16@24@32^@40
@48@0:8@16@24Q32^@40
@56@0:8Q16@24@32@40@48
i48@0:8@16Q24@?32@?40
v40@0:8@16@24^q32
v88@0:8@16#24{?={?=qiIq}{?=qiIq}}32@80
@108@0:8#16@24@32@40{?={?=qiIq}{?=qiIq}}48B96^B100
v48@0:8@16@24^q32^f40
v144@0:8@16{?={?=qiIq}{?=qiIq}}24@72{?={?=qiIq}{?=qiIq}}80^q128^f136
i56@0:8Q16@24@32@?40@48
i52@0:8@16Q24B32@?36@?44
@52@0:8Q16@24B32@?36^@44
@56@0:8Q16@24@32@?40^@48
@44@0:8@16@24Q32B40
@"NSNumber"
@"AVAssetReaderOutputMetadataAdaptor"
S16@0:8
@40@0:8@16@24Q32
@72@0:8{?={?=qiIq}{?=qiIq}}16^Q64
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32
i48@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32@?40
i64@0:8@16{?=qiIq}24Q48@?56
@32@0:8@?16^B24
@"VCPAsset"
@"VCPProtoBounds"
Q40@0:8^{?=Q^@^Q[5Q]}16^@24Q32
B20@0:8B16
@24@0:8i16i20
{?={?=qiIq}{?=qiIq}}32@0:8@16f24B28
i48@0:8@16f24f28f32B36@?40
i56@0:8B16@20@28f36f40f44B48B52
f28@0:8f16@20
f48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
Q56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
i40@0:8@16@24^@32
i40@0:8@16@24@32
i36@0:8B16@?20@?28
@"VNPersonsModel"
i40@0:8^Q16^Q24@?32
Q32@0:8q16Q24
Q32@0:8@16Q24
@"VNSceneprint"
B24@0:8^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}16
[10f]
@"VCPSceneChangeSegment"
v56@0:8@16@24@32@40@?48
v48@0:8@"NSString"16@"IOSurface"24@"NSDictionary"32@?<v@?@"NSDictionary"@"NSError">40
v56@0:8@"NSString"16@"NSURL"24@"NSString"32@"NSDictionary"40@?<v@?@"NSDictionary"@"NSError">48
v48@0:8#16^{__CVBuffer=}24@32@?40
v48@0:8#16@24@32@?40
@48@0:8@16^{__CVBuffer=}24@32@?40
i36@0:8^{__CVBuffer=}16^^{__CVBuffer}24i32
i24@0:8^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}16
i84@0:8^{__CVBuffer=}16^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}24{?=qiIq}32{?=qiIq}56i80
{Scaler="pool_"^{__CVPixelBufferPool}"width_"i"height_"i"crop_rect_"{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}"sw_scaler_"^{OpaqueVTPixelTransferSession}}
@"VCPImageMotionFlowAnalyzer"
{vector<__CVBuffer *, std::__1::allocator<__CVBuffer *> >="__begin_"^^{__CVBuffer}"__end_"^^{__CVBuffer}"__end_cap_"{__compressed_pair<__CVBuffer **, std::__1::allocator<__CVBuffer *> >="__value_"^^{__CVBuffer}}}
@"VNRequest"
i40@0:8^{CGPoint=dd}16^f24^@32
v64@0:8^f16^f24Q32Q40Q48Q56
v28@0:8i16^f20
v40@0:8^f16Q24Q32
i56@0:8^f16@24^{CGPoint=dd}32^f40^@48
i52@0:8@16f24{CGPoint=dd}28^f44
i32@0:8@16^f24
[8^f]
@"VCPGaborFilter"
i68@0:8{?={?=qiIq}{?=qiIq}}16f64
i64@0:8{?=qiIq}16{?=qiIq}40
@"VCPSegment"
^{HinkleyDetector=ffi{HinkleyStats=ffff}}
^{__CVBuffer=}24@0:8Q16
{CGSize=dd}16@0:8
@32@0:8r^16Q24
r^16@0:8
@96@0:8{?=[4]}16@80@88
{?=[4]}16@0:8
@"VCPFaceGeometry"
{?="columns"[4]}
@80@0:8Q16{CGAffineTransform=dddddd}24@72
@40@0:8Q16@24@32
@88@0:8Q16{CGAffineTransform=dddddd}24f72@76B84
B32@0:8r^{CGAffineTransform=dddddd}16@24
{CGAffineTransform=dddddd}64@0:8{CGAffineTransform=dddddd}16
{CGAffineTransform=dddddd}28@0:8i16^{__CVBuffer=}20
{?=[4]}84@0:8{?=[4]}16i80
@88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^@80
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72@?80
i72@0:8{?={?=qiIq}{?=qiIq}}16@64
B68@0:8{?=qiIq}16{?=qiIq}40B64
@"VCPVideoFacePoseAnalyzer"
@"VCPVideoFaceMeshAnalyzer"
@"VCPFullVideoAnalyzer"
@"VCPImageBlurAnalyzer"
@"VCPAudioAnalyzer"
@"VCPVideoFullFaceDetector"
@"VCPSceneChangeAnalyzer"
@"VCPLightMotionAnalyzer"
@"VCPTrimAnalyzer"
@"VCPHomeKitMotionAnalyzer"
^{Rotator=^{__CVPixelBufferPool}iii^{OpaqueVTImageRotationSession}}
v40@0:8*16Q24^f32
i24@0:8^Q16
i32@0:8^{__CVBuffer=}16^Q24
^{__CVBuffer=}
@"NSObject<OS_dispatch_semaphore>"
@"NSMutableData"
@"NSURLSessionDataTask"
@32@0:8q16q24
@56@0:8@16@24Q32@?40@?48
@"VNFaceprint"
@56@0:8@16Q24Q32Q40@48
i40@0:8^f16^{CGPoint=dd}24i32i36
i32@0:8^{CGPoint=dd}16^f24
@"VCPProtoTime"
@"NSPersistentContainer"
@"NSManagedObjectContext"
@"VCPVideoActivityDescriptor"
v52@0:8Q16@24i32@36@?44
v52@0:8Q16@"NSData"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v52@0:8Q16@"IOSurface"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSData"20@"NSDictionary"28@?<v@?@"NSString"@"NSError">36
v36@0:8i16@"NSDictionary"20@?<v@?@"NSDictionary"@"NSError">28
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v24@0:8I16B20
^{__SCNetworkReachability=}
@"PVFace"
@"PVImage"
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
@48@0:8@16@?24@?32@40
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
i32@0:8@?16@?24
@"VCPFaceAnalyzer"
i28@0:8@16i24
i32@0:8^{CGPoint=dd}16^{CGPoint=dd}24
f32@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{CGRect={CGPoint=dd}{CGSize=dd}}24
i40@0:8^f16^{__CVBuffer=}24@32
@"VCPCNNHandsDetector"
@"VCPCNNHandKeypointsDetector"
@"VCPCNNFastGestureRecognition"
{?="quality"b1"statsFlags"b1"typesWide"b1}
B40@0:8@16#24@32
B40@0:8@16@24@32
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
i20@0:8f16
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24@?32
^f32@0:8^i16^i24
{vector<float *, std::__1::allocator<float *> >="__begin_"^^f"__end_"^^f"__end_cap_"{__compressed_pair<float **, std::__1::allocator<float *> >="__value_"^^f}}
@"SHMutableSignature"
{?="faceSharpness"b1}
@"VCPProtoLine"
@"VCPProtoPoint"
{?="underExpose"b1}
^{LkFsMeasure=IIqBIIddddqqIII[30[6f]]^f^f^f^{DspLibBiquad}^{DspLibBiquad}}
^{CAStreamBasicDescription=dIIIIIIII}
{vector<double, std::__1::allocator<double> >="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::__1::allocator<double> >="__value_"^d}}
{vector<float, std::__1::allocator<float> >="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::__1::allocator<float> >="__value_"^f}}
^{AUOutputBL={CAStreamBasicDescription=dIIIIIIII}*^{AudioBufferList}III}
{?="faceQuality"b1}
v60@0:8@16@24i32@36@44@?52
v60@0:8@"NSArray"16@"IOSurface"24i32@"NSDictionary"36@"NSDictionary"44@?<v@?@"NSDictionary"@"NSError">52
i48@0:8@16^{__CVBuffer=}24@32@?40
@"VCPImageHandsAnalyzer"
@48@0:8{CGPoint=dd}16{CGPoint=dd}32
@"VCPProtoLivePhotoVariationParams"
{?="epoch"b1"flags"b1}
@40@0:8^{__CVBuffer=}16@24^@32
f24@0:8Q16
v32@0:8^f16Q24
{?="list"^f"count"Q"size"Q}
@44@0:8i16B20B24@28@36
i48@0:8[21{CGPoint=dd}]16^f24@32@40
{?="loopFadeLen"b1"loopPeriod"b1"loopStart"b1}
v32@0:8@"NSDictionary"16@?<v@?@"NSError">24
v32@0:8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSData"16@"NSDictionary"24@?<v@?@"NSDictionary"@"NSError">32
@32@0:8@16@?24
{CF<const opaqueCMFormatDescription *>="value_"^{opaqueCMFormatDescription}}
@"VCPHomeKitAnalysisSession"
{CLLocationCoordinate2D=dd}16@0:8
@"VCPCNNPersonDetector"
@"VCPCNNPersonKeypointsDetector"
@36@0:8i16B20B24@28
i48@0:8^f16i24i28@32[3[2f]]40
i36@0:8r^{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t> >=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t> >=^{?}}}16@24i32
i72@0:8*16i24i28i32{CGPoint=dd}36{CGPoint=dd}52I68
i44@0:8*16i24i28i32^{CGPoint=dd}36
v28@0:8B16@?20
v44@0:8@16B24@28@?36
@64@0:8@16@24@32@?40@48^@56
@56@0:8@16@24@32@?40^@48
v64@0:8@16@24@32@40@?48@?56
v48@0:8@16@?24@?32@?40
@"PVClusterer"
@"VCPPhotosPersistenceDelegate"
i40@0:8@16^@24@?32
@32@0:8@16q24
S24@0:8@16
v28@0:8@16I24
v28@0:8@"VNRequest"16I24
v24@0:8@"NSDictionary"16
B40@0:8@16@?24^@32
@"VCPFaceClusterer"
v40@0:8i16i20^f24^f32
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48f52
f80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i92@0:8@16@24i32^{__CVBuffer=}36{?=qiIq}44{?=qiIq}68
@"VCPVideoObjectTracker"
{?="distanceToPreviousScene"b1"flickerScore"b1"sceneprintDistanceToPreviousScene"b1}
B36@0:8@16B24^@28
B48@0:8^@16^d24^B32^@40
B60@0:8@16B24@28@?36@?44^@52
@"VCPFaceVisionIntegrating"
@"VCPProtoVideoKeyFrame"
@32@0:8{CGPoint=dd}16
@40@0:8{?=qiIq}16
@36@0:8@16@24f32
@"PHFace"
v48@0:8Q16@24@32@?40
v48@0:8Q16@"IOSurface"24@"NSDictionary"32@?<v@?@"NSDictionary"@"NSError">40
@28@0:8i16@20
v48@0:8Q16^{__CVBuffer=}24@32@?40
@"NSLock"
@44@0:8@16i24i28i32i36i40
v60@0:8*16i24i28i32^f36^f44^f52
v36@0:8^f16^f24i32
^{LandmarkDetector=iiiiiiiB^f^f^f^i^{ZPoint}^{RegressionTree}^?}
^q16@0:8
q24@0:8Q16
v32@0:8^q16Q24
{?="list"^q"count"Q"size"Q}
@20@0:8I16
@48@0:8{?=qiIq}16f40B44
v72@0:8{?={?=qiIq}{?=qiIq}}16f64B68
v44@0:8{?=qiIq}16B40
v24@0:8^{opaqueCMSampleBuffer=}16
i24@0:8^{opaqueCMFormatDescription=}16
i32@0:8^{__CVBuffer=}16^^{__CVBuffer}24
@"AVAssetWriter"
@"AVAssetWriterInput"
@"AVAssetWriterInputMetadataAdaptor"
{atomic<int>="__a_"{__cxx_atomic_impl<int, std::__1::__cxx_atomic_base_impl<int> >="__a_value"Ai}}
i88@0:8{?=qiIq}16{?=qiIq}40{?=qiIq}64
f56@0:8i16i20^{?={?=qiIq}{?=qiIq}}24{?=qiIq}32
B40@0:8{?=qiIq}16
B64@0:8{?=qiIq}16{?=qiIq}40
@"VCPActionAnalyzer"
@"AVURLAsset"
@"VCPFaceTimeSession"
i68@0:8@16@24@32@40@48@56f64
f80@0:8{?={?=qiIq}{?=qiIq}}16@64^i72
@68@0:8{?={?=qiIq}{?=qiIq}}16f64
v24@0:8^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}16
@"VCPHumanPoseImageRequest"
@96@0:8{CGAffineTransform=dddddd}16@64@72B80B84@?88
@24@0:8f16B20
i84@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24i56{?=qiIq}60
r^f16@0:8
@40@0:8@16@24d32
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
@72@0:8@16@24{?=qiIq}32^{?=qiIq}56@64
v104@0:8{?={?=qiIq}{?=qiIq}}16@64@72{?=qiIq}80
@"VCPImagePetsAnalyzer"
@20@0:8f16
B20@0:8f16
i80@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{?=qiIq}56
v80@0:8{?=[4]}16
@80@0:8{CGAffineTransform=dddddd}16@64@72
B84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
i56@0:8^{__CVBuffer=}16{?=qiIq}24@48
@"VCPCNNSmileDetector"
@"VCPCNNPoseEstimator"
B28@0:8@16f24
f72@0:8{?={?=qiIq}{?=qiIq}}16@64
f20@0:8f16
B72@0:8{?={?=qiIq}{?=qiIq}}16@64
i48@0:8@16{?=qiIq}24
v28@0:8B16@20
v60@0:8B16f20f24f28f32f36f40B44f48f52B56
@132@0:8{CGAffineTransform=dddddd}16{?={?=qiIq}{?=qiIq}}64B112@116@124
@"VCPImageFaceQualityAnalyzer"
@76@0:8{CGAffineTransform=dddddd}16@64B72
i32@0:8^{__CVBuffer=}16@24
@88@0:8@16{CGAffineTransform=dddddd}24Q72^{opaqueCMFormatDescription=}80
@"VCPVideoMetaFocusSegment"
@48@0:8q16{?=qiIq}24
v48@0:8q16{?=qiIq}24
@32@0:8Q16^{opaqueCMFormatDescription=}24
B24@0:8^{opaqueCMFormatDescription=}16
{CGSize=dd}24@0:8^{opaqueCMFormatDescription=}16
@24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}28@0:8I16^{__CFData=}20
i32@0:8^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16@24
{CGVector="dx"d"dy"d}
@"VCPVideoMetaFocusAnalyzer"
@"VCPVideoMetaMotionAnalyzer"
@"VCPVideoMetaLensSwitchAnalyzer"
{HinkleyDetector="sensitivity_"f"threshold_"f"min_length_"i"stats_"{HinkleyStats="upper_"f"lower_"f"max_"f"min_"f}}
@"VCPVideoMetaMotionSegment"
@44@0:8f16{?=qiIq}20
v44@0:8f16{?=qiIq}20
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48{?=qiIq}56
@"VCPCtrTracker"
v32@0:8@16^{__CVBuffer=}24
f92@0:8f16{CGRect={CGPoint=dd}{CGSize=dd}}20{CGRect={CGPoint=dd}{CGSize=dd}}52i84i88
B48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@28@0:8@16f24
f84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
@"VCPImageSaliencyAnalyzer"
@32@0:8@16f24f28
v76@0:8@16{?=qiIq}24{?=qiIq}48B72
v72@0:8@16{?={?=qiIq}{?=qiIq}}24
@"VCPSceneTaxonomy"
{?=ii}24@0:8@16
^{opaqueCMSampleBuffer=}16@0:8
@"AVAssetTrack"
@32@0:8@16r^{?={?=qiIq}{?=qiIq}}24
@44@0:8@16r^{?={?=qiIq}{?=qiIq}}24@32B40
@"AVAssetReader"
@"AVAssetReaderTrackOutput"
^{opaqueCMSampleBuffer=}
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24r^{?=qiIq}32
i28@0:8B16^{?={?=qiIq}{?=qiIq}}20
i72@0:8{?={?=qiIq}{?=qiIq}}16^^{opaqueCMSampleBuffer}64
@"AVAssetReaderSampleReferenceOutput"
[2^{opaqueCMSampleBuffer}]
v40@0:8r^{?=qiIq}16r^{?=qiIq}24@32
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
i24@0:8r^{AudioStreamBasicDescription=dIIIIIIII}16
^{OpaqueAudioComponentInstance=}
v32@0:8^{__CVBuffer=}16^{CGPoint=dd}24
^{CGPoint=dd}16@0:8
v24@0:8^{CGPoint=dd}16
^{CGPoint=dd}
^{?=^{?}^{?}^{?}^{tplTracker_resampler_context}^{?}}
mcpl
v024
ARGB
v024
mcpl
   %%*
!!!!!$$$$&&&((*
   !!#
