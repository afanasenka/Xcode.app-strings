@(#)PROGRAM:Translation  PROJECT:Translation-126
@mcpl
v32@?0@"NSLocale"8@"_LTSpeechRecognitionResult"16^B24
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
delegate
T@"<_LTSpeechTranslationDelegate>",W,N,V_delegate
com.apple.translation.powerlog
sentence
singleParagraph
paragraphs
text-to-speech
speech
preheat
text-LID
v8@?0
loggerQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_loggerQueue
requestTypeSet
T@"NSOrderedSet",&,V_requestTypeSet
__unknown__
localeDetectionCount
unsupportedLanguageCount
dominantLocale
LTTextLanguageDetectionResult.m
Invalid parameter not satisfying: %@
locales
languages
com.apple.translation.TextLID
language
isSupported
@"NSDictionary"8@?0
supportsSecureCoding
TB,R
T@"NSLocale",R,C,N,V_dominantLocale
T@"NSCountedSet",R,C,N,V_localeDetectionCount
unsupportedLanguageCounts
T@"NSCountedSet",R,C,N,V_unsupportedLanguageCounts
features
compiledModelFile
modelInput
modelOutput
missingLanguageDetectionDefault
min_source
max_source
avg_source
min_target
max_target
avg_target
acoustic_lid
v32@?0@"NSString"8Q16^B24
v32@?0@"NSNumber"8Q16^B24
com.apple.private.translation
com.apple.Translation
Daemon
com.apple.translation.daemon.listener
DisambiguationEnabled
com.apple.translationd
uniqueID
sessionID
taskHint
localePair
autodetectLanguage
autoEndpoint
sensorSpeech
outputFileURL
asrModelURLs
mtModelURL
route
audioSessionID
lidThreshold
asrConfidenceThreshold
sourceURL
T@"NSString",C,N,V_uniqueID
T@"NSString",C,N,V_sessionID
Tq,N,V_taskHint
T@"_LTLocalePair",C,N,V_localePair
TB,N,V_autodetectLanguage
censorSpeech
TB,N,V_censorSpeech
T@"NSURL",C,N,V_outputFileURL
T@"NSArray",C,N,V_asrModelURLs
T@"NSURL",C,N,V_mtModelURL
T@"NSURL",C,N,V_sourceURL
TB,N,V_autoEndpoint
Tq,N,V_lidThreshold
Tq,N,V_route
TI,N,V_audioSessionID
Tq,N,V_asrConfidenceThreshold
clientIdentifier
T@"NSString",&,N,V_clientIdentifier
dataSharingOptInStatus
Tq,N,V_dataSharingOptInStatus
zh-Hant
zh_TW
zh-Hans
zh_CN
dominantLanguage
confidences
isConfident
isFinal
T@"NSLocale",C,N,V_dominantLanguage
T@"NSDictionary",C,N,V_confidences
TB,R,N,V_isConfident
TB,N,V_isFinal
com.apple.translation.lid.result
lastResult
T@"_LTLanguageDetectionResult",&,N,V_lastResult
featureCombinationModelSupported
TB,N,V_featureCombinationModelSupported
featureCombinationModel
T@"_LTLanguageDetectorFeatureCombinationModel",&,N,V_featureCombinationModel
samplingRate
Td,R,N,V_samplingRate
audioBitDepth
Tq,R,N,V_audioBitDepth
%lld
%@ %@ %@
progress
offlineState
localeIdentifier
totalExpected
totalWritten
isStalled
expectedTimeRemaining
Tq,N,V_progress
T@"NSString",C,N,V_localeIdentifier
TQ,N,V_offlineState
Tq,N,V_totalExpected
Tq,N,V_totalWritten
TB,N,V_isStalled
Td,N,V_expectedTimeRemaining
TranslationErrorDomain
InternalTranslationErrorDomain
LTRemoteFailure
unknown error
Remote service failure
Online translation not implemented
Cannot force both online and offline
Failed to load LID model
Translation ongoing already
Speech translation already ongoing
Speech duration limit exceeded
Translation server did not respond in time.
Offline TTS failed
Translation from %@ to %@ is not supported.
completion
T@?,C,N,V_completion
paragraph
T@"_LTTranslationParagraph",&,N,V_paragraph
requestParagraph
T@"FTMutableBatchTranslationRequest_Paragraph",&,N,V_requestParagraph
request_id
hasFinalServerResponse
completionHandlerCalled
Missing Batch Translation Responses
request
T@"FTMutableBatchTranslationRequest",&,N,V_request
toLocale
T@"NSLocale",&,N,V_toLocale
metricEvent
T@"LTSchemaBatchTranslationEvent",&,N,V_metricEvent
batchedParagraphs
T@"NSMutableDictionary",&,N,V_batchedParagraphs
bufferSize
TQ,N,V_bufferSize
sourceLocale
T@"NSLocale",&,N,V_sourceLocale
targetLocale
T@"NSLocale",&,N,V_targetLocale
requestID
T@"NSString",&,N,V_requestID
T@"NSString",&,N,V_sessionID
startTime
T@"NSDate",&,N,V_startTime
T@"NSURL",&,N,V_sourceURL
TB,N,V_hasFinalServerResponse
TB,N,V_completionHandlerCalled
OnlineTranslationEngine
com.apple.translation.online-queue
com.apple.translation.server-timer
v24@?0@"NSError"8q16
com.apple.Translate
com.apple.mobilesafari
%@-%@
v16@?0@"OspreyMutableRequest"8
v24@?0@"FTTextToSpeechResponse"8@"NSError"16
v24@?0@"FTTranslationResponse"8@"NSError"16
%@/%08ld
@"FTSpan"16@?0@"_LTTranslationSpan"8
v16@?0@"NSError"8
sentenceCount
v24@?0@"_LTTranslationResult"8@"NSError"16
Translation failed
Translation input was empty
v32@?0@"_LTTranslationParagraph"8Q16^B24
ttsCache
T@"_LTTextToSpeechCache",&,N,V_ttsCache
serverQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_serverQueue
default
InstalledLocales
LastOfflineAssetCatalogUpdate
LastCDNUpdate
LastOfflineAssetUpdate
LastConfigAssetUpdate
OspreyEndpointURL
DeviceSessionID
BatchingMaxParagraphs
BatchingMaxParagraphBufferSize
BatchingMaxParagraphBufferTimeout
ASRConfidenceThresholds
ASRWordLevelConfidenceThreshold
LanguageDetectorConfidenceThreshold
LanguageDetectorConfidenceFallbackThreshold
LanguageDetectorFeatureCombinationModelSupported
LanguageDetectorFeatureCombinationModelThreshold
LanguageDetectorFeatureCombinationModelConfidenceThreshold
EnableHybridEndpointer
HybridEndpointerThreshold
DisconnectedHybridEndpointerThreshold
HybridEndpointerClientLagThreshold
HybridEndpointerClampedLatencyForClientLag
HybridEndpointerUseDefaultFeaturesOnClientLag
CharacterBasedLocales
LotteryNumber
World
ServerSpeechSessionInitialOnlineTimeout
ServerSpeechSessionOnlineTimeout
ServerSpeechSessionOnlineEndpointTimeout
Configuration
SupportedRegions
mt_app.online
web.online
LanguagePairs
@"_LTLocalePair"16@?0@"NSString"8
AdditionalLanguages
WebTaskIsSupportedInCountry
https://sequoia.apple.com
https://seed-sequoia.siri.apple.com
https://carry-sequoia.siri.apple.com
asbd
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
rawData
T@"NSData",R,N,V_rawData
packetCount
Tq,R,N,V_packetCount
packetDescriptions
T@"NSData",R,N,V_packetDescriptions
wordCount
trailingSilence
eosLikelihood
pauseCounts
silencePosterior
processedAudio
Tq,N,V_wordCount
trailingSilenceDuration
Tq,N,V_trailingSilenceDuration
Td,N,V_eosLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
processedAudioDurationInMilliseconds
Tq,N,V_processedAudioDurationInMilliseconds
com.apple.siri.translation.HEP
com.apple.siri.translation.HEP.features
endpointerThreshold
T@"NSDictionary",C,N,V_endpointerThreshold
Tq,R,N,V_samplingRate
clientLagThresholdMs
Td,N,V_clientLagThresholdMs
clampedSFLatencyMsForClientLag
Td,N,V_clampedSFLatencyMsForClientLag
useDefaultServerFeaturesOnClientLag
TB,N,V_useDefaultServerFeaturesOnClientLag
Missing
Installed
Downloading
NeedsDownload
ErrorInstalling
Error
%@ %@ %@ %@
status
TQ,N,V_status
voiceAsset
T@"VSVoiceAsset",&,N,V_voiceAsset
identifier
T@"NSString",C,N,V_identifier
error
T@"NSError",&,N,V_error
localIdentifiers
T@"NSArray",&,N,V_localIdentifiers
update
T@"MAProgressNotification",&,N,V_update
LanguageManager
com.apple.siri.translation.LanguageManager
mt_app.offline
ASR-%@
TTS-%@
asset_list
AssetName
v16@?0@"MAProgressNotification"8
asr_languages
_all
TTS-
Translation voice not found for %@:%@
Translation voice downloaded for %@:%@
Downloading Translation voice %@:%@, progress: %.2f remainingTime: %.f
v20@?0d8f16
ASR-
v16@?0q8
sourceRange
targetRange
text
T{_NSRange=QQ},N,V_sourceRange
T{_NSRange=QQ},N,V_targetRange
T@"NSString",C,N,V_text
shouldTranslate
TB,N,V_shouldTranslate
com.apple.translationd.playback
Translation
v24@?0@"_LTAudioData"8@"NSError"16
deviceOS
deviceType
appIdentifier
T@"NSString",R,C,N,V_sessionID
Tq,R,N,V_taskHint
T@"_LTLocalePair",R,C,N,V_localePair
T@"NSString",R,C,N,V_deviceOS
T@"NSString",R,C,N,V_deviceType
T@"NSString",R,C,N,V_appIdentifier
Languages
Footprint
Premium
hybridendpointer.json
hybridepAssetFile
T@"NSString",R,N,V_hybridepAssetFile
spgAssetFile
T@"NSString",R,N,V_spgAssetFile
T@"NSString",&,N,V_text
completionHandler
T@?,C,N,V_completionHandler
AssetVersion
_LTSpeechTranslationAssetInfo
%@ <-> %@ | %@ %@
config-lq
config
assets.json
mt-quasar-config.json
inputTokenCount
inputSubtokenCount
firstleg sentencepiece encoder input
sentencepiece encoder input
firstleg sentencepiece decoder output
sentencepiece decoder output
Tq,N,V_inputTokenCount
Tq,N,V_inputSubtokenCount
undefined
loggingType
T@"NSString",R,N
T@"_LTLocalePair",R,N,V_localePair
T@"NSURL",&,N,V_outputFileURL
forcedOfflineTranslation
TB,N,V_forcedOfflineTranslation
_forcedOnlineTranslation
TB,N,V__forcedOnlineTranslation
_offlineMTModelURL
T@"NSURL",&,N,V__offlineMTModelURL
_mtConfidenceThreshold
Tq,N,V__mtConfidenceThreshold
T@"NSString",C,N,V_sentence
textHandler
T@?,C,N,V_textHandler
translationHandler
T@?,C,N,V_translationHandler
batch
LTTranslationRequest.m
This is deprecated
T@"NSArray",C,N,V_paragraphs
TranslationRequest
com.apple.siri.translation.speechrequest
@"AVAudioBuffer"20@?0I8^q12
Could not drain converter %@
Could not run audio converter %@
_lidModelURL
T@"NSURL",&,N,V__lidModelURL
_offlineASRModelURLs
T@"NSArray",&,N,V__offlineASRModelURLs
_asrConfidenceThreshold
Tq,N,V__asrConfidenceThreshold
_lidThreshold
Tq,N,V__lidThreshold
textToSpeech
CMBlockBufferCopyDataBytes could not copy data: %d
SELF != ''
v40@?0{_NSRange=QQ}8Q24^B32
DeviceName
 Simulator
ProductName
ProductType
BuildVersion
ProductVersion
+N9mZUAHooNvMiQnjeTJ8g
siri
app_review
mt_app
InternalBuild
ar_AE
ar_SA
com.apple.translation.tts-cache
LTTextToSpeechCache.m
MISS
com.apple.MobileAsset.SpeechTranslationAssets
com.apple.MobileAsset.SpeechEndpointAssets
AssetManager
com.apple.Translator.EMTAssetManager
v12@?0B8
ramp.plist
https://fides-pol.apple.com/attachments/safari-translation/ramp.plist
v32@?0@"NSData"8@"NSURLResponse"16@"NSError"24
plist
q24@?0@"_LTLocalePair"8@"_LTLocalePair"16
@16@?0@"_LTLocalePair"8
TranslationAssetDownloadDomain
_DownloadSize
MADownLoadResult
Mobile asset failed to download.
v16@?0@"NSArray"8
Assets
Type
RequiredCapabilityIdentifier
Configuration asset is missing.
The Configuration asset has not yet been downloaded.
Missing asset entitlement
LanguageDetectorDefaultAsset
featureCombinationLID.plist
_UnarchivedSize
TranslationAssetQueryDomain
profile_blob
profile_blob_version
profile_checksum
T@"NSData",C,N
T@"NSString",C,N
acoustic_profile_version
acoustic_profile_blob
token_text
start_milli_seconds
end_milli_seconds
silence_start_milli_seconds
confidence
add_space_after
phone_seq
ipa_phone_seq
Ti,N
TB,N
tokens
T@"NSArray",C,N
tok_phrases
has_unsuggested_alternatives
positional_tok_phrase_alt
alternative_index
itn_alignment
post_itn_choice_indices
pre_itn_token_to_post_itn_char_alignments
pre_itn
post_itn
pre_itn_nbest_choices
post_itn_nbest_choices
pre_itn_token_to_post_itn_char_alignment
choice_alignments
T@"FTRecognitionSausage",C,N
bool_stats
int32_stats
double_stats
speech_id
request_locale
name
value
Td,N
first_pre_itn_token_index
last_pre_itn_token_index
first_post_itn_char_pos
last_post_itn_char_pos
acoustic_feature_per_frame
frame_duration
Tf,N
speech_recognition_features
acoustic_features
T@"FTAcousticFeature",C,N
session_id
return_code
return_str
recognition_result
lang_profile_recreate_codes
audio_analytics
watermark_detection
watermark_peak_average
latnn_mitigator_result
has_result
T@"FTRecognitionResult",C,N
Tq,N
T@"FTAudioAnalytics",C,N
T@"FTLatnnMitigatorResult",C,N
recognition_text
is_stable_result
audio_duration_ms
task_name
codec
stream_results
enable_server_side_endpoint
device_type
device_os
mic_type
udm_host
udm_port
tandem_mode
store_audio
stream_unstable_results
end_point_mode
start_audio_bookmark
is_far_field
enable_utterance_detection
enable_endpoint_candidate
start_recognition_at
start_endpointing_at
enable_hybrid_endpoint
client_endpointer_model_version
keyboard_identifier
input_origin
initial_recognition_candidate_id
disable_auto_punctuation
keyboard_dictation
experiment_id
speech_request_source
fork_id
application_name
metadata
TQ,N
TI,N
start_speech_request
user_parameters
primary_speech_id
T@"FTStartSpeechRequest",C,N
product_id
vendor_id
contextual_text
pron_hints
left_context
right_context
context_with_pron_hints
user_language_profile
user_acoustic_profile
T@"FTUserLanguageProfile",C,N
T@"FTUserAcousticProfile",C,N
audio_bytes
packet_count
total_audio_recorded_seconds
features_at_endpoint
server_feature_latency_distribution
updated_acoustic_profile
orthography
pronunciations
frequency
attributes
category_name
category_data
user_data
error_code
error_str
incomplete_profile
recreate_apg_prons
reason
phonemes
blob
apg_id
voc_token
tts_pronunciations
human_readable_prons
T@"FTVocToken",C,N
apg_ids
recovery_return_codes
voc_tokens
num_of_requested
num_of_processed
num_of_succeeded
words_list
formatted_words_list
post_itn_string
nbest_variants_max
normalized_tokens
original_token
nbest_variants
pron_sequence
log_weight
token
pron_source
sanitized_sequences
prons
normalized_prons
sanitized_tokens
T@"FTContextWithPronHints",C,N
is_pron_guessed
g2p_version
g2p_model_version
phoneset_version
aot_token_prons
jit_token_prons
index
start_index
end_index
do_not_translate
meta_info
span
raw_sausage
raw_nbest_choices
post_itn_tokens
post_itn_recognition
itn_alignments
translation_phrase
pre_itn_payload
post_itn_payload
pre_sausage_payload
spans
task
source_language
target_language
siri_translation_info
speech_translation_info
siri_payload_translation_info
sequence_id
web_translation_info
disable_log
opt_in_status
app_id
T@"FTSiriTranslationInfo",C,N
T@"FTSpeechTranslationInfo",C,N
T@"FTSiriPayloadTranslationInfo",C,N
T@"FTWebTranslationInfo",C,N
return_string
n_best_translated_phrases
engine_input
engine_output
mt_alignment
T@"FTAlignment",C,N
translated_tokens
low_confidence
end_point_likelihood
processed_audio_duration_ms
latitude
longitude
enable_geo_location_features
speech_packet_count
processed
version
threshold
score
result_id
fingerprint_detection
start_speech_time
end_speech_time
speech_detected
audio_packets
ref_transcript
blamer_report
token_str
log10_score
ngram_used
transcript
enable_completion
max_results
max_expand_paths
max_tm_score
abs_pruning_threshold
rel_pruning_threshold
enable_word_boundary
max_path_num_at_boundary
parabolic_error_wide
parabolic_error_center
parabolic_error_bias
parabolic_error_min
max_latency
word_penalty
delimiter
matched_result
total_score
tm_score
match_ids
debug_information
matcher_id
query
target
T@"FTAStarFuzzyMatchingConfig",C,N
latency
expanded_path
results
keyword_orthography
posterior
keywords
enable_sanitization
corrected_sausage
n_best_list
num_of_words
trailing_silence_duration
eos_likelihood
pause_counts
silence_posterior
original_utterance
corrected_utterance
original_words
corrected_words
corrections
fe_feature
fe_feature_only
disable_prompts
gender
quality
type
voice
resource
T@"FTTextToSpeechVoice",C,N
T@"FTTextToSpeechResource",C,N
channel_type
context_info
dialog_identifier
experiment_identifier
word_phonemes
prompts
prompts_v2
original
replacement
normalized_text
phoneme_sequence
force_use_tts_service
disable_cache
data
resources
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
context
experiment
feature_flags
debug
profile
T@"FTTextToSpeechRequestMeta",C,N
T@"FTTextToSpeechRequestContext",C,N
T@"FTTextToSpeechRequestExperiment",C,N
T@"FTTTSRequestFeatureFlags",C,N
T@"FTTextToSpeechRequestDebug",C,N
T@"FTTextToSpeechUserProfile",C,N
sample_rate
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
length
timestamp
audio
decoder_description
playback_description
word_timing_info
feature
T@"FTAudioDescription",C,N
T@"FTTextToSpeechMeta",C,N
T@"FTTextToSpeechFeature",C,N
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
audio_length
original_session_id
cache_meta_info
cache_object
T@"FTTextToSpeechCacheMetaInfo",C,N
endpoint_threshold
endpoint_extra_delay
audio_frames
source_locale
target_locale
conversation_id
translation_locale_pairs
translation_request
text_to_speech_requests
restricted_mode
T@"FTTranslationRequest",C,N
translation_locale_pair
detected_locale
user_selected_locale
senses
user_selected_sense
user_interacted_senses
T@"FTTranslationLocalePair",C,N
T@"FTLanguageDetected",C,N
text_to_speech_response
T@"FTTextToSpeechResponse",C,N
server_endpoint_features
T@"FTServerEndpointFeatures",C,N
utterance
shortcuts
interaction_id
locale
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",C,N
raw_string
shortcut_score_pairs
shortcut
similarity_score
language_parameters_by_id
is_low_confidence
predictions
paragraph_id
translated_text
sentence_count
content_type
content
contentAsFTStartPronGuessRequest
T@"FTStartPronGuessRequest",C,N
contentAsFTAudioPacket
T@"FTAudioPacket",C,N
contentAsFTFinishAudio
T@"FTFinishAudio",C,N
contentAsFTCancelRequest
T@"FTCancelRequest",C,N
contentAsFTPronGuessResponse
T@"FTPronGuessResponse",C,N
contentAsFTStartBatchRecoverRequest
T@"FTStartBatchRecoverRequest",C,N
contentAsFTBatchRecoverFinalResponse
T@"FTBatchRecoverFinalResponse",C,N
contentAsFTStartSpeechRequest
contentAsFTUpdateAudioInfo
T@"FTUpdateAudioInfo",C,N
contentAsFTSetRequestOrigin
T@"FTSetRequestOrigin",C,N
contentAsFTSetSpeechContext
T@"FTSetSpeechContext",C,N
contentAsFTSetSpeechProfile
T@"FTSetSpeechProfile",C,N
contentAsFTSetEndpointerState
T@"FTSetEndpointerState",C,N
contentAsFTResetServerEndpointer
T@"FTResetServerEndpointer",C,N
contentAsFTCheckForSpeechRequest
T@"FTCheckForSpeechRequest",C,N
contentAsFTSetAlternateRecognitionSausage
T@"FTSetAlternateRecognitionSausage",C,N
contentAsFTFinalSpeechRecognitionResponse
T@"FTFinalSpeechRecognitionResponse",C,N
contentAsFTPartialSpeechRecognitionResponse
T@"FTPartialSpeechRecognitionResponse",C,N
contentAsFTUpdatedAcousticProfile
T@"FTUpdatedAcousticProfile",C,N
contentAsFTEndPointLikelihood
T@"FTEndPointLikelihood",C,N
contentAsFTEndPointCandidate
T@"FTEndPointCandidate",C,N
contentAsFTRecognitionProgress
T@"FTRecognitionProgress",C,N
contentAsFTCheckForSpeechResponse
T@"FTCheckForSpeechResponse",C,N
contentAsFTRecognitionCandidate
T@"FTRecognitionCandidate",C,N
contentAsFTRequestStatsResponse
T@"FTRequestStatsResponse",C,N
contentAsFTServerEndpointFeatures
contentAsFTClientSetupInfo
T@"FTClientSetupInfo",C,N
contentAsFTAudioLimitExceeded
T@"FTAudioLimitExceeded",C,N
contentAsFTMultiUserStartSpeechRequest
T@"FTMultiUserStartSpeechRequest",C,N
contentAsFTFinalBlazarResponse
T@"FTFinalBlazarResponse",C,N
contentAsFTStartMultilingualSpeechRequest
T@"FTStartMultilingualSpeechRequest",C,N
contentAsFTLanguageDetected
contentAsFTStartSpeechTranslationRequest
T@"FTStartSpeechTranslationRequest",C,N
contentAsFTSpeechTranslationAudioPacket
T@"FTSpeechTranslationAudioPacket",C,N
contentAsFTStartSpeechTranslationLoggingRequest
T@"FTStartSpeechTranslationLoggingRequest",C,N
contentAsFTSpeechTranslationPartialRecognitionResponse
T@"FTSpeechTranslationPartialRecognitionResponse",C,N
contentAsFTSpeechTranslationFinalRecognitionResponse
T@"FTSpeechTranslationFinalRecognitionResponse",C,N
contentAsFTSpeechTranslationMtResponse
T@"FTSpeechTranslationMtResponse",C,N
contentAsFTSpeechTranslationTextToSpeechResponse
T@"FTSpeechTranslationTextToSpeechResponse",C,N
contentAsFTSpeechTranslationServerEndpointFeatures
T@"FTSpeechTranslationServerEndpointFeatures",C,N
contentAsFTBatchTranslationRequest
T@"FTBatchTranslationRequest",C,N
contentAsFTBatchTranslationResponse
T@"FTBatchTranslationResponse",C,N
contentAsFTStartTextToSpeechStreamingRequest
T@"FTStartTextToSpeechStreamingRequest",C,N
contentAsFTBeginTextToSpeechStreamingResponse
T@"FTBeginTextToSpeechStreamingResponse",C,N
contentAsFTPartialTextToSpeechStreamingResponse
T@"FTPartialTextToSpeechStreamingResponse",C,N
contentAsFTFinalTextToSpeechStreamingResponse
T@"FTFinalTextToSpeechStreamingResponse",C,N
contentAsFTQssAckResponse
T@"FTQssAckResponse",C,N
contentAsFTStartLanguageDetectionRequest
T@"FTStartLanguageDetectionRequest",C,N
contentAsFTLanguageDetectionResponse
T@"FTLanguageDetectionResponse",C,N
Not Present
Required by OS
Installed not in catalog
Installed with OS
Unknown
Unavailable
Unimplemented
%@ <-> %@ | pair: %@ MT: %@ ASR-%@ : %@ ASR-%@: %@ %@
Update
pair
pairState
sourceASRState
targetASRState
sourceTTSState
targetTTSState
mtState
needsUpdate
TQ,N,V_pairState
T@"_LTLocalePair",&,N,V_pair
T@"NSString",&,N,V_sourceASRState
T@"NSString",&,N,V_targetASRState
T@"NSString",&,N,V_mtState
T@"NSString",&,N,V_sourceTTSState
T@"NSString",&,N,V_targetTTSState
TB,N,V_needsUpdate
@"_LTTranslationToken"16@?0@"FTTranslationResponse_TranslationToken"8
com.apple.siri.translation.offline
@"_LTTranslationCandidate"16@?0@"EMTResult"8
sourceSentence
LTOfflineTranslationEngine.m
Missing result locale
bestConfidence
bestTranslation
@"NSString"16@?0@"_LTTranslationResult"8
v16@?0@"_LTTranslationResult"8
v24@?0@"NSString"8@?<v@?@@"NSError">16
v24@?0@"NSArray"8@"NSError"16
v24@?0@"_LTTranslationParagraph"8@?<v@?@@"NSError">16
mtStartTime
mtResultTime
mtLocale
mtBestConfidence
mtBestText
autodetect
v16@?0@"_LTSpeechRecognitionResult"8
asrResultTime
asrLocale
unknown
asrBestConfidence
asrBestText
v24@?0@"_LTSpeechRecognitionResult"8@"NSError"16
T@"_LTLocalePair",&,N,V_localePair
T@"NSArray",&,N,V_asrModelURLs
T@"NSURL",&,N,V_mtModelURL
male
female
com.apple.assistant.backedup
Output Voice
Gender
OfflineSpeechSynthesizer
@"_LTTranslationCandidate"16@?0@"FTSpeechTranslationMtResponse_TranslationPhrase"8
@"_LTTranslationCandidate"16@?0@"FTTranslationResponse_TranslationPhrase"8
q24@?0@"_LTAlignment"8@"_LTAlignment"16
MultilingualSpeechRecognizer
v32@?0@"NSLocale"8@"NSURL"16^B24
com.apple.multilingualrecognition.results
pbMatch
sense ID
definition
sourceMatch
source match
targetMatch
target match
input
output
labels
formality
@"_LTTranslationSense"16@?0@"NSObject"8
phrasebook_exact
phrasebookMatch
TB,N,GisPhrasebookMatch,V_phrasebookMatch
senseID
T@"NSString",C,N,V_senseID
T@"NSString",C,N,V_definition
T@"NSString",C,N,V_sourceMatch
T@"NSString",C,N,V_targetMatch
T@"NSArray",C,N,V_labels
conversationID
selectedLocale
lidResult
T@"NSString",C,N,V_conversationID
T@"NSString",C,N,V_requestID
T@"NSLocale",C,N,V_targetLocale
T@"NSLocale",C,N,V_selectedLocale
T@"_LTLanguageDetectionResult",&,N,V_lidResult
userInteractedSenses
T@"NSArray",C,N,V_senses
T@"NSArray",C,N,V_userInteractedSenses
start
firstResponse
pageComplete
firstParagraphComplete
processName
timeToFirstResponse
timeToPageComplete
timeToFirstParagraphComplete
Td,R,N,V_start
Td,R,N,V_firstResponse
Td,R,N,V_pageComplete
Td,R,N,V_firstParagraphComplete
T@"NSString",C,N,V_processName
dict
T@"NSDictionary",R,N
com.apple.translation.text
LTTranslationSession.m
v24@?0@"<_LTTranslationService>"8@?<v@?>16
requests
@"_LTTranslationParagraph"16@?0@"_LTParagraphTranslationRequest"8
feedback
translator
T@"_LTTranslator",&,N,V_translator
service
T@"<_LTTranslationService>",&,N,V_service
T@"NSURL",C,N,V_URL
FormatVersion
Language
Config
MT-bi-
LTTranslationRange.m
Invalid paramter: identifier is nil
T@"NSString",R,C,N,V_identifier
T@"NSString",R,C,N,V_text
TB,R,N,V_shouldTranslate
metaInfo
T@"NSDictionary",C,N,V_metaInfo
LTSpeechCompressor.m
Already started compressor
AudioConverterNew failed: %x
AudioConverterSetProperty/kAudioConverterEncodeBitRate failed: %x
Too many buffers
Cannot produce ASPD for PCM
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
range
metaInfoData
T@"NSString",R,N,V_identifier
T{_NSRange=QQ},R,N,V_range
T@"NSData",C,N,V_metaInfoData
translations
sourceString
sanitizedSourceString
alignments
NO_IDENTIFIER
T@"NSArray",C,N,V_translations
T@"NSLocale",C,N,V_locale
T@"NSString",C,N,V_sourceString
T@"NSString",C,N,V_sanitizedSourceString
T@"NSArray",C,N,V_alignments
@"NSString"16@?0@"_LTTranslationParagraph"8
com.apple.translation.combined
v32@?0@"NSString"8@"_LTTranslationResult"16@"NSError"24
offlineDelegateBuffer
T@"_LTSpeechTranslationResultsBuffer",&,N,V_offlineDelegateBuffer
offlineEngine
T@"<_LTTranslationEngine>",&,N,V_offlineEngine
onlineEngine
T@"<_LTTranslationEngine>",&,N,V_onlineEngine
com.apple.translation.async-map
v24@?0@8@"NSError"16
v32@?0@8Q16^B24
sourceContentAsJSON
targetContentAsJSON
errorsAsJSON
safariVersion
webpageURL
clientBundleID
T@"NSString",C,N,V_clientBundleID
T@"NSString",C,N,V_sourceContentAsJSON
T@"NSString",C,N,V_targetContentAsJSON
T@"NSString",C,N,V_errorsAsJSON
T@"NSString",C,N,V_safariVersion
T@"NSURL",C,N,V_webpageURL
Translator
v16@?0@"<_LTTranslationService>"8
v24@?0q8@"NSError"16
v16@?0@"NSDictionary"8
v16@?0@"_LTLanguageDetectionResult"8
v16@?0@"_LTTextLanguageDetectionResult"8
interruptionHandler
T@?,C,N
OfflineEngine
OnlineEngine
OfflineModelLoading
OfflineRecognizerLoading
ClientConnection
OfflineEtiquetteSanitizerLoading
OfflineTranslatorLoading
OfflineFormatterLoading
CombinedTranslation
XPC Server
Session
node
T@"NSDictionary",&,N,V_node
T{_NSRange=QQ},N,V_range
T@"NSString",&,N,V_token
LTEtiquetteSanitizer
v32@?0@"NSString"8@16^B24
LTEtiquetteSanitizer.m
missing replacement tokens
etiquette.json
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
TOKEN
v32@?0@8@16^B24
com.apple.translation.speech
mini.json
MtApp
Empty recognition
No speech recognized
recognitionHandler
T@?,C,N,V_recognitionHandler
modelURL
T@"NSURL",R,N,V_modelURL
modelVersion
T@"NSString",R,N,V_modelVersion
T@"NSLocale",R,N,V_language
Error AudioQueueStart
state
Tq,R,N,V_state
com.apple.translationd.server
Offline models not available for language pair
com.apple.translation.session
engine
T@"<_LTTranslationEngine>",&,N,V_engine
T@"<_LTSpeechTranslationDelegate>",&,N,V_delegate
T@"NSUUID",&,N,V_sessionID
languageDetector
T@"_LTLanguageDetector",R,N,V_languageDetector
endpointer
T@"_LTHybridEndpointer",R,N,V_endpointer
formattedString
sanitizedFormattedString
lowConfidence
statistics
Td,N,V_confidence
TB,N,GisLowConfidence,V_lowConfidence
T@"NSArray",C,N,V_tokens
T@"NSString",C,N,V_formattedString
T@"NSString",C,N,V_sanitizedFormattedString
proToPostITN
T@"NSArray",C,N,V_proToPostITN
T@"_LTTranslationStatistics",C,N,V_statistics
preToPostITN
T@"NSArray",R,N,V_preToPostITN
application-identifier
T@"<_LTClientConnectionDelegate>",W,N,V_delegate
QssRpc_immutable_generated.mm
Output Buffer is null
v20@?0r*8I16
v24@?0^v8Q16
T@"NSData",R,N
Ti,R,N
TB,R,N
T@"NSArray",R,N
T@"FTRecognitionSausage",R,N
Td,R,N
Tf,R,N
T@"FTAcousticFeature",R,N
T@"FTRecognitionResult",R,N
Tq,R,N
T@"FTAudioAnalytics",R,N
T@"FTLatnnMitigatorResult",R,N
TQ,R,N
TI,R,N
T@"FTStartSpeechRequest",R,N
T@"FTUserLanguageProfile",R,N
T@"FTUserAcousticProfile",R,N
T@"FTVocToken",R,N
T@"FTContextWithPronHints",R,N
T@"FTSiriTranslationInfo",R,N
T@"FTSpeechTranslationInfo",R,N
T@"FTSiriPayloadTranslationInfo",R,N
T@"FTWebTranslationInfo",R,N
T@"FTAlignment",R,N
T@"FTAStarFuzzyMatchingConfig",R,N
T@"FTTextToSpeechVoice",R,N
T@"FTTextToSpeechResource",R,N
T@"FTTextToSpeechRequestMeta",R,N
T@"FTTextToSpeechRequestContext",R,N
T@"FTTextToSpeechRequestExperiment",R,N
T@"FTTTSRequestFeatureFlags",R,N
T@"FTTextToSpeechRequestDebug",R,N
T@"FTTextToSpeechUserProfile",R,N
T@"FTAudioDescription",R,N
T@"FTTextToSpeechMeta",R,N
T@"FTTextToSpeechFeature",R,N
T@"FTTextToSpeechCacheMetaInfo",R,N
T@"FTTranslationRequest",R,N
T@"FTTranslationLocalePair",R,N
T@"FTLanguageDetected",R,N
T@"FTTextToSpeechResponse",R,N
T@"FTServerEndpointFeatures",R,N
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",R,N
T@"FTStartPronGuessRequest",R,N
T@"FTAudioPacket",R,N
T@"FTFinishAudio",R,N
T@"FTCancelRequest",R,N
T@"FTPronGuessResponse",R,N
T@"FTStartBatchRecoverRequest",R,N
T@"FTBatchRecoverFinalResponse",R,N
T@"FTUpdateAudioInfo",R,N
T@"FTSetRequestOrigin",R,N
T@"FTSetSpeechContext",R,N
T@"FTSetSpeechProfile",R,N
T@"FTSetEndpointerState",R,N
T@"FTResetServerEndpointer",R,N
T@"FTCheckForSpeechRequest",R,N
T@"FTSetAlternateRecognitionSausage",R,N
T@"FTFinalSpeechRecognitionResponse",R,N
T@"FTPartialSpeechRecognitionResponse",R,N
T@"FTUpdatedAcousticProfile",R,N
T@"FTEndPointLikelihood",R,N
T@"FTEndPointCandidate",R,N
T@"FTRecognitionProgress",R,N
T@"FTCheckForSpeechResponse",R,N
T@"FTRecognitionCandidate",R,N
T@"FTRequestStatsResponse",R,N
T@"FTClientSetupInfo",R,N
T@"FTAudioLimitExceeded",R,N
T@"FTMultiUserStartSpeechRequest",R,N
T@"FTFinalBlazarResponse",R,N
T@"FTStartMultilingualSpeechRequest",R,N
T@"FTStartSpeechTranslationRequest",R,N
T@"FTSpeechTranslationAudioPacket",R,N
T@"FTStartSpeechTranslationLoggingRequest",R,N
T@"FTSpeechTranslationPartialRecognitionResponse",R,N
T@"FTSpeechTranslationFinalRecognitionResponse",R,N
T@"FTSpeechTranslationMtResponse",R,N
T@"FTSpeechTranslationTextToSpeechResponse",R,N
T@"FTSpeechTranslationServerEndpointFeatures",R,N
T@"FTBatchTranslationRequest",R,N
T@"FTBatchTranslationResponse",R,N
T@"FTStartTextToSpeechStreamingRequest",R,N
T@"FTBeginTextToSpeechStreamingResponse",R,N
T@"FTPartialTextToSpeechStreamingResponse",R,N
T@"FTFinalTextToSpeechStreamingResponse",R,N
T@"FTQssAckResponse",R,N
T@"FTStartLanguageDetectionRequest",R,N
T@"FTLanguageDetectionResponse",R,N
com.apple.translation.speech-timer
@"FTAudioFrame"16@?0@"NSData"8
@"NSString"16@?0@"_LTSpeechTranscription"8
%@: %f : %d
initialOnlineTimeout
Td,N,V_initialOnlineTimeout
onlineTimeout
Td,N,V_onlineTimeout
endpointTimeout
Td,N,V_endpointTimeout
completionBlock
T@?,C,N,V_completionBlock
final
transcriptions
sausage
Sausage
TB,N,GisFinal,V_final
T@"NSString",&,N,V_modelVersion
T@"NSArray",&,N,V_transcriptions
bestRecognitionAlternatives
T@"_LTSpeechRecognitionSausage",&,N,V_bestRecognitionAlternatives
TranslateRequest
OfflineTextTranslation
OfflineBatchTextTranslation
OfflineSpeechTranslation
OfflineTextToSpeechTranslation
OnlineTextTranslation
com.apple.translation
code
domain
domain_code
%@_%ld
underlying_domain
underlying_code
underlying_domain_code
com.apple.translation.analytics-event
errorDomain
errorCode
errorDescription
duration
T@"NSLocale",C,N,V_sourceLocale
%@.%@
TextLIDUseLSTM
TextLIDAggregateEvaluation
availableLocales
T@"NSArray",C,N,V_availableLocales
T@"NSArray",R,C,N,V_spans
bins
alternatives
bestIndex
spaceAfter
@"_LTSpeechRecognitionTokensAlternative"16@?0@"NSArray"8
@"NSString"16@?0@"_LTSpeechRecognitionBin"8
(%@)
T@"NSArray",&,N,V_bins
T@"NSArray",&,N,V_alternatives
bestAlternativeIndex
TQ,N,V_bestAlternativeIndex
Tq,N,V_confidence
hasSpaceAfter
TB,N,V_hasSpaceAfter
/siri.speech.qss_fb.Apg/PronGuess
Flatbuffers
v16@?0@"NSData"8
/siri.speech.qss_fb.Apg/BatchRecover
/siri.speech.qss_fb.Asr/Recognition
/siri.speech.qss_fb.Asr/ErrorBlamer
v24@?0@"NSData"8@"NSError"16
/siri.speech.qss_fb.Asr/Itn
/siri.speech.qss_fb.Asr/TextNormalization
/siri.speech.qss_fb.Asr/PostItnHammer
/siri.speech.qss_fb.Asr/KeywordFinder
/siri.speech.qss_fb.Asr/CorrectionsValidator
/siri.speech.qss_fb.Asr/GraphemeToPhoneme
/siri.speech.qss_fb.Blazar/MultiUser
/siri.speech.qss_fb.Blazar/Multilingual
/siri.speech.qss_fb.Blazar/SpeechTranslation
/siri.speech.qss_fb.Blazar/BatchTranslation
/siri.speech.qss_fb.Blazar/TextToSpeechRouter
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
/siri.speech.qss_fb.Lmt/LmScorer
/siri.speech.qss_fb.Napg/CreateLanguageProfile
/siri.speech.qss_fb.Mt/Translation
/siri.speech.qss_fb.Tts/TextToSpeech
/siri.speech.qss_fb.Tts/TextToSpeechStreaming
/siri.speech.qss_fb.Nl/ShortcutFuzzyMatch
/siri.speech.qss_fb.Afm/AStarFuzzyMatching
/siri.speech.qss_fb.Sls/LanguageDetection
PRIVACY_LINK
ON_DEVICE_FOOTER
OnDeviceOnly
showTranslatePrivacy
ON_DEVICE_PREF_NAME
com.apple.Translate.globalprefschanged
CONFIRMATION_TITLE
CONFIRMATION_DESCRIPTION
NOT_NOW
OPEN_APP
InstallRequest
T@"NSArray",C,N,V_locales
useCellular
TB,N,V_useCellular
progressHandler
T@?,C,N,V_progressHandler
@"_LTSpeechRecognitionTokensAlternative"16@?0@"FTRecognitionPhraseTokens"8
minConfidence
maxConfidence
Td,N,V_minConfidence
Td,N,V_maxConfidence
<no value>
<%@: source:%@ target:%@>
T@"NSLocale",R,N,V_sourceLocale
T@"NSLocale",R,N,V_targetLocale
com.apple.translation.ParagraphTranslationDone
mtAppService
T@"FTBlazarService",R,N,V_mtAppService
Text or ranges need to be specified
v32@?0@"_LTTranslationRange"8Q16^B24
ranges
T@"NSArray",C,N,V_ranges
Missing necessary configuration values
Setting default value for missing language detector result to %f
Unknown feature in model file: %@
Unable to load CoreML model from: %@
CoreML model loaded: %@
Min confidence source: %f
Max confidence source: %f
Average confidence source: %f
Min confidence target: %f
Max confidence target: %f
Average confidence target: %f
Acoustic LID: %f
Created CoreML features: %@
Did not receive all ASR final results yet, falling back to original LID result
Unable to compile CoreML input features, falling back to original LID result
Unable to construct CoreML feature provider, falling back to original LID result
Unable to perform inference on CoreML model, falling back to original LID result
Was unable to extract CoreML prediction, falling back to original LID result
Was unable to extract posterior values from prediction results, falling back to original LID result
Using LID feature combination model, detected %@, with score %f and threshold %f and confidence threshold %f (confident: %@)
Memory pressure warning level %lu.
Rejected Translation client with PID %d lacking the appropriate entitlement (%@).
Failed to obtain LID asset
Start
Overriding confidence thresholds, setting to %ld
Confidence thresholds for source %f and target %f
Invalid source and target confidence threshold configuration
Using ASR confidence fallback, detected %@, with threshold %f (confident: %@)
NumSamples: %ld
LID Audio Data
confidence: %@
CS-LID Result
Confident in source language (%lf) with threshold %lf
Confident in target language (%lf) with threshold %lf
LID detected %@ (confident: %@): %@
streamDidReceiveBatchTranslationStreamingResponse request_id %{public}@
found BatchTranslationResponse request_id %{public}@
FIXME: NULL FTBatchTranslationResponse!
GRPC error %d: %@
Translation error on %{public}@: %@
Succeeded request %{public}@ (%ld alignments)
Translation: %{private}@ for %{private}@
Missing paragraphBatchInfo for paragraph ID: %{public}@
NULL FTFinalBlazarResponse!
found FTFinalBlazarResponse request_id %{public}@ outstanding paragraphs %@ error %@
Publishing BatchTranslationEvent to FLLogger
Unrecognized message type from server recieved!
Failed to get siri data sharing opt in status: %@
Creating service with URL: %@, bundleID: %@
startServerTimeoutTimer 
updateServerTimeout %.2fs 
cancelServerTimeout: %@
batch timeout triggered
 serverTimeoutFired Sending batch request after %.2fs 
Found cached TTS data
Start TTS request: %@ / %@
TTS response (%d): %@
Should skip empty string to translate
Sending translation request: %@
Online: Translating string
TranslateString
Online: Finished translating
Error translating request: %@, error: %@
Finished translating request: %@
Sending batch request: bufferSizeExceeded %@ maxParagraphsExceeded %@ taskChanged %@ after %.2fs
Translating: %{private}@ request_id %@
Spans: %@
Online: Translating paragraph: %@
TranslateParagraph
Sending batch for requestID: %{public}@, task: %{public}@, sessionID: %{public}@, URL: %@
Translating: %lu batched paragraph(s)
Online: Finished translating paragraph: %@ error %@
Start translating sentence
Online: Translating sentence
TranslateSentence
Online: finished translating sentence
Start translating %ld paragraphs
Online speech or text to speech translation already ongoing
Online speech translation already ongoing
Invalidating current speech session with error: %@
Invalid chunk size: %d at offset %d, bytes count = %d
error %@ creating directory at path %@
error %@ writing to url %@
Client lag configuration is %f, %f, %@
Init of HEP
Auto endpointing is turned off
Start new HEP request
Could not get appropriate endpointer assets
Could not obtain SPG asset
Updating disconnected source endpointer threshold to %f
Request for sampling rate failed for source locale
Updating disconnected target endpointer threshold to %f
Have hybrid endpointer for source %@, for target %@
Received server endpointer features for source locale
Re-request sampling rate for source endpointer
Updating source endpointer threshold to %f
Received server endpointer features for target locale
Re-request sampling rate for target endpointer
Updating target endpointer threshold to %f
Unexpected locale %@ for server endpointer features
Adding audio samples %ld
Sending end of audio to SPG
ClientLag: serverProcessedAudioMs(%{public}ld) > effectiveClientProcessedAudioMs(%{public}f)
ClientLag: Not invoking HybridClassifier: sfLatency > clientLagThreshold: %{public}f > %{public}f
ClientLag: Using DefaultServerFeatures with disconnected-state sfLatency: %{public}f
ClientLag: Using ServerFeatures with ClampedSFLatency: %{public}f
ClientLag: Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
HEP.feats: [%{public}ld,%{public}f,%{public}f,%{public}ld,%{public}f,%{public}f] & [(%{public}@),%{public}f,%{public}f] @ %{public}lu [%{public}f, %{public}d]
clientSilenceFeaturesAvailable
Endpointing decision from source endpointer %@
Endpointing decision from target endpointer %@
missing mt_app.offline.plist
asset names for %@: %@
progressCallback update assetIdentifier %@ %@
[self->_assetStatusDictionary count] %lu
Required Assets: %@
setAutoDownloadedVoiceAssets %@
Unreferenced assets: %@
purged %@ result %ld
Nothing to install.
Installing:
Failed to create playback service
Failed to start TTS playback: %@
Data length: %lu
Finished TTS playback
Asked to cancel speak session
No available endpointer assets
HEP not supported for given locale pair/configuration
Number of HEP assets %ld
Could not find suitable HEP asset for any language
Found asset for source %@, for target %@
Malformed config asset
Models - sourceASR: %d, targetASR: %d, mt: %d
Updating symlinks for %@
Failed to create directory %@ error %@
Failed to link mt-quasar-config.json %@
creating link from %@ to %@
Failed to link model file %@
Failed to rename temp language pair directory %@
Requested to download asset for: %@
Starting download for asset with attributes: %@
All asset downloads for language pair %@ completed successfuly
Reference counts before purge %@
Language pair directory doesn't exist %@
Starting purge for %@
Error deleting directory %@ error %@
Starting purge for asset : %@
error purging asset %@
All assets purged for language pair %@ finished (error: %@)
Reference counts after purge %@
Start speech translation with service
Drain queued buffers first
Append audio data
Start text to speech translation with service
TTS cache request: %@
Purging %ld items from TTS cache
Asset manager clearing caches
Update offline asset catalog
Asset catalog finished downloading with result %ld
MADownloadNotEntitled
Downloading config asset
Error downloading config asset %@
Finished downloading config asset
Failure updating all assets %@
Finished updating all assets
error querying catalog assets
error querying installed assets
Config asset not installed!
Failed to download plist %@
Failed to write plist %@
Failed to read plist %@
Reading configuration plist %@
Error creating speechTranslationAssetInfo: %@
Asset purge finished
Failed asset purge: %ld
Start downloading asset %@ userInitiated: %@, useCellular: %@
Asset progress: %@
update: %@ %@
Asset download finished %@
Failed asset download: %@
getAutoDownloadedVoiceAssets %@
Failed to create asset directory %@
Failed to deserialize JSON at path %@ error %@
No asset info found for language pair %@
Requested to delete all offline assets
Failed to delete asset link directory: %@
Failed asset query: %ld
Waiting for %ld assets to be deleted
All assets purged (error: %@)
%@ %@ Version %@ Capability %@ %@
----------------------------- sortedCatalogAssets ------------------------------------ 
----------------------------- Assets to download ------------------------------------ 
%@ %@ %@ %@
error downloading asset %@
error deleting asset %@
Config asset updated.
----------------------------- Fixing symlinks --------------------------------------- 
Error downloading offline assets %@
Reference counts after download %@
Error getting asset info %@
Missing asset entitlement
Fallback asset resource path : %{public}@
Error loading config data: %@ at url: %@
Error reading from plist: %@
Loaded config plist from : %@
Missing required resource! %@
Failed to fetch asset metadata. Result: %ld
Loading recognizers
Using model overrides as specified: %@
Creating multi recognizer: %@, %@
Offline modelVersions %@
Finished loading recognizers
LoadOfflineRecognizers
Loading etiquette sanitizers
loaded etiquette sanitizer for: %@
Finished loading etiquette sanitizers
LoadOfflineSanitizers
Loading translator
Creating translator with task %@ model URL: %@
Finished loading translator
LoadOfflineTranslator
Loading all models
Finished loading models
PreheatModels
Offline: Translating string
TranslateTokens
Done translating
Offline: Finished translating
Finished translating: %@
Translate sentence: %@
Translate pragraph: %@
Finished translating paragraph
Finished translation, sending analytics event
Translate text paragraphs (block completion handler)
Offline: Translating %ld paragraphs
TranslateParagraphs
Cancel speech translation
Add audio to engine
Notified of LID result: %@ is confident: %@
Already got final LID result, forwarding...
Waiting for LID result
Received final LID result, continue with wait block
Starting translation
Offline: Translating text: %@
OfflineTranslation
Offline: Finished translating speech result, (id: %@)
Starting offline speech translation (auto detect language: %@, id: %@)
Offline: Translating speech result, (id: %@)
ModelVersion %@
LowConfidence (%f): %d with threshold %ld
Best recognition: %@
Siri Voice Defaults :%@ 
Speaking: %@ language code %@
Failed to start speaking request: %@
Failed to cancel offline TTS, error: %@
Finished offline TTS metrics:%@ 
Finished offline TTS, successfully: %@, error: %@
Starting recognition for %ld recognizers
Starting recognizer: %@
Starting ASR for %@
Recognition error: %@
Failed ASR (%@) with error: %@
ASR result (%@): %@
Recognizer finished
Completed ASR for %@
All recognizers finished
Propagate endAudio to recognizers
Session sending %ld requests
Error sending %ld paragraphs %{public}@
Finished sending %ld paragraphs
Session sending feedback
Received translation result for %@
Starting combined translation
Failed online TTS, will fallback to offline: %@
HEP triggered
Server translation finished (optional error: %@)
Online translation failed, continue with offline
Failed to clear caches: %@
Failed to complete _offlineLanguageStatus %@
Failed to complete _downloadAssetForLanguagePair %@
Failed to complete _purgeAssetForLanguagePair %@
Failed to complete installedLocales %@
Failed to complete availableLocalePairsForTask %@
Failed to complete additionalLikelyPreferredLocalesForLocale %@
Failed to complete configInfoForLocale %@
Failed to complete taskIsSupportedInCurrentRegion %@
Failed to complete text-LID request %@
Creating service proxy
Connection error: %@
Connection done
Creating SYNC service proxy
Failed sync preheat request
Failed to complete preheat request %@
Failed to initiate cleanup: %@
Failed to serialize logging request: %@
Failed to complete logging request: %@
Could not locate asset etiquette.json
Could not read %@: %@
Could not parse %@: %@
%@ is wrong type: %@
%@ contains bogus key/value pair: %@ => %@
Creating etiquette sanitizer with URL: %@
sanitizedString '%@' forString '%@' locale: %@
Error creating playback service, %d
Current audio output route: %@
AudioQueue initialized with session id: %d
Error disposing audio queue %d
mediaserverd reset
Error starting audio queue %d
Creating buffer of length: %ld
Failed to create audio buffer: %d
Failed to enqueue audio data: %d
Enqueued audio buffer at sample title: %.2f, size: %ld
Playback service running state changed
Error adding audio queue property listener %d
Wait for audio queue to stop
Audio queue playback stopped (%d)
Failed to remove property listener %d
Error flushing audio queue %d
Error stopping audio queue %d
Error AudioQueueStop %d
Error AudioQueueReset %d
Error checking is running property: %d
LTPlaybackServices %p played audio buffer at sample time: %f, size: %ld
Error AudioQueueFreeBuffer %d
Reusing cached offline engine for locales: %@
No asset info found for pair %@: %@
MT model URL: %@
Unsupported language pair requested for online engine
Creating offline engine
Creating online engine
Could not create online engine: %@
Could not create offline engine, using online only: %@
Creating combined engine
Requested preheat with context: %@
Cancel ongoing speech session: %{public}@
Cancel ongoing speak session
Failed to create text translation engine: %@
Translating %ld paragraphs for route: %ld
Handling text translation request for route: %ld (autodetect: %@)
Failed to create translation engine: %@
Failed TTS request: %@
Handling speech translation request for route: %ld (autodetect: %@)
Failed to create speech translation engine: %@
Start speech translation session
Asked to cancel %{public}@, current ongoing is: %{public}@
Ignoring cancel request because of different session IDs
Resetting session
Add speech audio data for session
End speech audio data on session
Sending end of audio
Asked to cancel speech session
Skipping meta, failed to parse as JSON. %@
Translation candidate meta: %@
Skipping meta, disabled in user defaults
Client didn't set application-identifier entitlement
Client connection for: %@
Client disconnected, ask to cancel speech session
_LTTranslationService paragraphResult %@ error %@ paragraphError %@ 
Failed to deserialize logging request: %@ 
Starting speech translation with request ID: %{public}@ session ID: %{public}@, opt in status: %ld
Streaming connection finished with error: %@
Starting text to speech translation with request ID: %{public}@, session ID: %{public}@, opt in status: %ld
Streaming text translation session finished with error: %@
Setting server timeout for %.2fs
Server timeout triggered
Already endpointed, do not need to send additional data.
Start compressing audio
Sending end audio
Ending audio due to endpointer trigger
Ignoring non-final LID result
LID result received. Primary language recognized: %@
Sending MT responses if needed
Detected translation locale: %@
Result locale: %@
Sending %ld packets from compressor
Audio limit exceeded
Always sending ASR partial %@
Received final recognition response
Final recognition status: %d: %@
Recognition: %@
Insufficient information in server endpointer features response
Received translation response: %@
Received TTS response: %@ (%ld)
Unable to process TTS audio data
Final blazar response: %d %@
Remote service error %d: %@
Speech translation stream error: %@
Received server message
Sausage conf %ld for locale %@
Using LSTM text lid engine
Using CFRO text lid engine
Dominant language: %@
Language confidences: %@
Mapped language: %@
Could not find locale for %@ in available: %@
Using aggregate text lid evaluation
Sausage confidences: %@
Start installation request with service
Start Speech LID logging request
Speech LID logging request finished with error: %@
Speech LID logging request finished
Start speech senses logging request
Speech senses logging request finished with error: %@
Speech senses logging request finished
Start Safari latency logging request
Start Safari feedback request
Received logging request response: [%d] %@
Logging request received unexpected response: %@
Logging request received error: %@
_LTSpeechTranslationResultsBuffer
_LTSpeechTranslationDelegate
NSObject
_LTPowerLogger
_LTTextLanguageDetectionResult
NSSecureCoding
NSCoding
_LTLanguageDetectorFeatureCombinationModel
Osprey
_LTDaemon
NSXPCListenerDelegate
_LTClientConnectionDelegate
_LTTranslationContext
_LTLanguageDetectionResult
_LTLanguageDetector
CSLanguageDetectorDelegate
_LTLanguageInstallationStatus
LTTranslationError
_FTParagraphBatchInfo
_LTBatchTranslationResponseHandler
FTBatchTranslationResponseDelegate
_LTOnlineTranslationEngine
_LTTranslationEngine
_LTAudioData
_LTServerEndpointerFeatures
_LTHybridEndpointer
EARCaesuraSilencePosteriorGeneratorDelegate
_LTLanguageAssetStatus
_LTLanguageManager
_LTAlignment
_LTServerSpeakSession
_LTTaskContext
_LTHybridEndpointerAssetInfo
_LTSpeakRequest
_LTSpeechTranslationAssetInfo
LTStatistics
_LTTranslationStatistics
NSCopying
_LTTranslationRequest
_LTTextTranslationRequest
_LTBatchTextTranslationRequest
_LTSpeechTranslationRequest
_LTTextToSpeechTranslationRequest
_LTTokenizer
_SentenceBoundaries
_LTTextToSpeechCache
_LTOfflineAssetManager
FTMutableUserLanguageProfile
FTMutableUserAcousticProfile
FTMutableRecognitionToken
FTMutableRecognitionPhraseTokens
FTMutableRecognitionPhraseTokensAlternatives
FTMutableRecognitionSausage
FTMutableSetAlternateRecognitionSausage
FTMutableRecognitionChoice
FTMutableRepeatedItnAlignment
FTMutableChoiceAlignment
FTMutableRecognitionResult
FTMutableRequestStatsResponse
FTMutableRequestStatsResponse_BoolStat
FTMutableRequestStatsResponse_Int32Stat
FTMutableRequestStatsResponse_DoubleStat
FTMutableItnAlignment
FTMutableAcousticFeature
FTMutableAudioAnalytics
FTMutableAudioAnalytics_SpeechRecognitionFeaturesEntry
FTMutableAudioAnalytics_AcousticFeaturesEntry
FTMutableFinalSpeechRecognitionResponse
FTMutablePartialSpeechRecognitionResponse
FTMutableStartSpeechRequest
FTMutableUserParameters
FTMutableMultiUserStartSpeechRequest
FTMutableUpdateAudioInfo
FTMutableContextWithPronHints
FTMutableSetSpeechContext
FTMutableSetSpeechProfile
FTMutableSetEndpointerState
FTMutableAudioPacket
FTMutableFinishAudio
FTMutableFinishAudio_ServerFeatureLatencyDistributionEntry
FTMutableUpdatedAcousticProfile
FTMutableWord
FTMutableUserDataEntity
FTMutableCategoryData
FTMutableCreateLanguageProfileRequest
FTMutableCreateLanguageProfileResponse
FTMutableStartPronGuessRequest
FTMutableCancelRequest
FTMutablePronunciation
FTMutableVocToken
FTMutablePronGuessResponse
FTMutableRecoverPronsRequest
FTMutableRecoverPronsResponse
FTMutableStartBatchRecoverRequest
FTMutableBatchRecoverFinalResponse
FTMutableItnRequest
FTMutableItnResponse
FTMutablePostItnHammerRequest
FTMutablePostItnHammerResponse
FTMutableTextNormalizationRequest
FTMutableNormalizedTokenVariant
FTMutableNormalizedToken
FTMutableTextNormalizationResponse
FTMutablePronChoice
FTMutableSanitizedPronToken
FTMutableTokenProns
FTMutableTokenProns_SanitizedSequence
FTMutableGraphemeToPhonemeRequest
FTMutableGraphemeToPhonemeResponse
FTMutableAlignment
FTMutableSpan
FTMutableRepeatedSpan
FTMutableSpeechTranslationInfo
FTMutableSiriTranslationInfo
FTMutableSiriPayloadTranslationInfo
FTMutableWebTranslationInfo
FTMutableTranslationRequest
FTMutableTranslationResponse
FTMutableTranslationResponse_TranslationToken
FTMutableTranslationResponse_TranslationPhrase
FTMutableEndPointLikelihood
FTMutableEndPointCandidate
FTMutableSetRequestOrigin
FTMutableRecognitionProgress
FTMutableResetServerEndpointer
FTMutableLatnnMitigatorResult
FTMutableRecognitionCandidate
FTMutableCheckForSpeechRequest
FTMutableCheckForSpeechResponse
FTMutableErrorBlamerRequest
FTMutableErrorBlamerResponse
FTMutableLmScorerToken
FTMutableLmScorerRequest
FTMutableLmScorerResponse
FTMutableAStarFuzzyMatchingConfig
FTMutableAStarFuzzyMatchingResult
FTMutableAStarFuzzyMatchingRequest
FTMutableAStarFuzzyMatchingResponse
FTMutableKeyword
FTMutableKeywordFinderRequest
FTMutableKeywordFinderResponse
FTMutableServerEndpointFeatures
FTMutableCorrectionsValidatorRequest
FTMutableCorrectionsAlignment
FTMutableCorrectionsValidatorResponse
FTMutableTTSRequestFeatureFlags
FTMutableTextToSpeechVoice
FTMutableTextToSpeechResource
FTMutableTextToSpeechMeta
FTMutableTextToSpeechRequestMeta
FTMutableTextToSpeechRequestContext
FTMutableTextToSpeechRequestContext_ContextInfoEntry
FTMutableTextToSpeechRequestExperiment
FTMutableTTSWordPhonemes
FTMutableTTSPhonemeSequence
FTMutableTTSPrompts
FTMutableTTSReplacement
FTMutableTTSNormalizedText
FTMutableTextToSpeechFeature
FTMutableTextToSpeechRequestDebug
FTMutableTextToSpeechVoiceResource
FTMutableTextToSpeechUserProfile
FTMutableTextToSpeechRequest
FTMutableTextToSpeechRequest_ContextInfoEntry
FTMutableAudioDescription
FTMutableWordTimingInfo
FTMutableTextToSpeechResponse
FTMutableStartTextToSpeechStreamingRequest
FTMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
FTMutableBeginTextToSpeechStreamingResponse
FTMutablePartialTextToSpeechStreamingResponse
FTMutableFinalTextToSpeechStreamingResponse
FTMutableTextToSpeechCacheMetaInfo
FTMutableTextToSpeechCacheObject
FTMutableTextToSpeechCacheContainer
FTMutableQssAckResponse
FTMutableClientSetupInfo
FTMutableAudioLimitExceeded
FTMutableAudioFrame
FTMutableSpeechTranslationAudioPacket
FTMutableTranslationLocalePair
FTMutableStartSpeechTranslationRequest
FTMutableStartSpeechTranslationLoggingRequest
FTMutableSpeechTranslationPartialRecognitionResponse
FTMutableSpeechTranslationFinalRecognitionResponse
FTMutableSpeechTranslationMtResponse
FTMutableSpeechTranslationMtResponse_TranslationPhrase
FTMutableSpeechTranslationTextToSpeechResponse
FTMutableSpeechTranslationServerEndpointFeatures
FTMutableShortcutFuzzyMatchRequest
FTMutableShortcutFuzzyMatchRequest_StringTokenPair
FTMutableShortcutFuzzyMatchResponse
FTMutableShortcutFuzzyMatchResponse_ShortcutScorePair
FTMutableLanguageParameters
FTMutableStartMultilingualSpeechRequest
FTMutableLanguageDetectionPrediction
FTMutableLanguageDetected
FTMutableFinalBlazarResponse
FTMutableBatchTranslationRequest
FTMutableBatchTranslationRequest_Paragraph
FTMutableBatchTranslationResponse
FTMutableBatchTranslationCacheContainer
FTMutableStartLanguageDetectionRequest
FTMutableLanguageDetectionResponse
FTMutablePronGuessStreamingRequest
FTMutablePronGuessStreamingResponse
FTMutableBatchRecoverStreamingRequest
FTMutableBatchRecoverStreamingResponse
FTMutableRecognitionStreamingRequest
FTMutableRecognitionStreamingResponse
FTMutableMultiUserStreamingRequest
FTMutableMultiUserStreamingResponse
FTMutableMultilingualStreamingRequest
FTMutableMultilingualStreamingResponse
FTMutableSpeechTranslationStreamingRequest
FTMutableSpeechTranslationStreamingResponse
FTMutableBatchTranslationStreamingRequest
FTMutableBatchTranslationStreamingResponse
FTMutableTextToSpeechRouterStreamingStreamingRequest
FTMutableTextToSpeechRouterStreamingStreamingResponse
FTMutableTextToSpeechStreamingStreamingRequest
FTMutableTextToSpeechStreamingStreamingResponse
FTMutableLanguageDetectionStreamingRequest
FTMutableLanguageDetectionStreamingResponse
_LTLanguagePairOfflineAvailability
_LTOfflineTranslationEngine
_LTOfflineSpeechSynthesizer
VSSpeechSynthesizerDelegate
LTLocaleIdentifier
_LTLanguageDetectorAssetInfo
_LTMultilingualSpeechRecognizer
_LTTranslationSense
_LTSpeechLIDLoggingRequest
_LTLoggingRequest
_LTTranslationSensesLoggingRequest
_LTSafariLatencyLoggingRequest
ABSD
_LTTranslationSession
TranslationAssetUtil
_LTTranslationRange
_LTSpeechCompressor
_LTTranslationSpan
_LTTranslationResult
_LTCombinedEngine
_LTAsyncMap
_LTTranslationFeedback
_LTTranslator
_LTMatch
_LTEtiquetteSanitizer
_LTSpeechRecognizer
_EARSpeechRecognitionResultStream
_LTPlaybackService
_LTTranslationServer
_LTServerSpeechSession
_LTCombinedRouteParagraphTranslationRequest
_LTTranslationService
_LTTranslationCandidate
_LTClientConnection
FTUserLanguageProfile
FLTBFBufferAccessor
FTUserAcousticProfile
FTRecognitionToken
FTRecognitionPhraseTokens
FTRecognitionPhraseTokensAlternatives
FTRecognitionSausage
FTSetAlternateRecognitionSausage
FTRecognitionChoice
FTRepeatedItnAlignment
FTChoiceAlignment
FTRecognitionResult
FTRequestStatsResponse
FTRequestStatsResponse_BoolStat
FTRequestStatsResponse_Int32Stat
FTRequestStatsResponse_DoubleStat
FTItnAlignment
FTAcousticFeature
FTAudioAnalytics
FTAudioAnalytics_SpeechRecognitionFeaturesEntry
FTAudioAnalytics_AcousticFeaturesEntry
FTFinalSpeechRecognitionResponse
FTPartialSpeechRecognitionResponse
FTStartSpeechRequest
FTUserParameters
FTMultiUserStartSpeechRequest
FTUpdateAudioInfo
FTContextWithPronHints
FTSetSpeechContext
FTSetSpeechProfile
FTSetEndpointerState
FTAudioPacket
FTFinishAudio
FTFinishAudio_ServerFeatureLatencyDistributionEntry
FTUpdatedAcousticProfile
FTWord
FTUserDataEntity
FTCategoryData
FTCreateLanguageProfileRequest
FTCreateLanguageProfileResponse
FTStartPronGuessRequest
FTCancelRequest
FTPronunciation
FTVocToken
FTPronGuessResponse
FTRecoverPronsRequest
FTRecoverPronsResponse
FTStartBatchRecoverRequest
FTBatchRecoverFinalResponse
FTItnRequest
FTItnResponse
FTPostItnHammerRequest
FTPostItnHammerResponse
FTTextNormalizationRequest
FTNormalizedTokenVariant
FTNormalizedToken
FTTextNormalizationResponse
FTPronChoice
FTSanitizedPronToken
FTTokenProns
FTTokenProns_SanitizedSequence
FTGraphemeToPhonemeRequest
FTGraphemeToPhonemeResponse
FTAlignment
FTSpan
FTRepeatedSpan
FTSpeechTranslationInfo
FTSiriTranslationInfo
FTSiriPayloadTranslationInfo
FTWebTranslationInfo
FTTranslationRequest
FTTranslationResponse
FTTranslationResponse_TranslationToken
FTTranslationResponse_TranslationPhrase
FTEndPointLikelihood
FTEndPointCandidate
FTSetRequestOrigin
FTRecognitionProgress
FTResetServerEndpointer
FTLatnnMitigatorResult
FTRecognitionCandidate
FTCheckForSpeechRequest
FTCheckForSpeechResponse
FTErrorBlamerRequest
FTErrorBlamerResponse
FTLmScorerToken
FTLmScorerRequest
FTLmScorerResponse
FTAStarFuzzyMatchingConfig
FTAStarFuzzyMatchingResult
FTAStarFuzzyMatchingRequest
FTAStarFuzzyMatchingResponse
FTKeyword
FTKeywordFinderRequest
FTKeywordFinderResponse
FTServerEndpointFeatures
FTCorrectionsValidatorRequest
FTCorrectionsAlignment
FTCorrectionsValidatorResponse
FTTTSRequestFeatureFlags
FTTextToSpeechVoice
FTTextToSpeechResource
FTTextToSpeechMeta
FTTextToSpeechRequestMeta
FTTextToSpeechRequestContext
FTTextToSpeechRequestContext_ContextInfoEntry
FTTextToSpeechRequestExperiment
FTTTSWordPhonemes
FTTTSPhonemeSequence
FTTTSPrompts
FTTTSReplacement
FTTTSNormalizedText
FTTextToSpeechFeature
FTTextToSpeechRequestDebug
FTTextToSpeechVoiceResource
FTTextToSpeechUserProfile
FTTextToSpeechRequest
FTTextToSpeechRequest_ContextInfoEntry
FTAudioDescription
FTWordTimingInfo
FTTextToSpeechResponse
FTStartTextToSpeechStreamingRequest
FTStartTextToSpeechStreamingRequest_ContextInfoEntry
FTBeginTextToSpeechStreamingResponse
FTPartialTextToSpeechStreamingResponse
FTFinalTextToSpeechStreamingResponse
FTTextToSpeechCacheMetaInfo
FTTextToSpeechCacheObject
FTTextToSpeechCacheContainer
FTQssAckResponse
FTClientSetupInfo
FTAudioLimitExceeded
FTAudioFrame
FTSpeechTranslationAudioPacket
FTTranslationLocalePair
FTStartSpeechTranslationRequest
FTStartSpeechTranslationLoggingRequest
FTSpeechTranslationPartialRecognitionResponse
FTSpeechTranslationFinalRecognitionResponse
FTSpeechTranslationMtResponse
FTSpeechTranslationMtResponse_TranslationPhrase
FTSpeechTranslationTextToSpeechResponse
FTSpeechTranslationServerEndpointFeatures
FTShortcutFuzzyMatchRequest
FTShortcutFuzzyMatchRequest_StringTokenPair
FTShortcutFuzzyMatchResponse
FTShortcutFuzzyMatchResponse_ShortcutScorePair
FTLanguageParameters
FTStartMultilingualSpeechRequest
FTLanguageDetectionPrediction
FTLanguageDetected
FTFinalBlazarResponse
FTBatchTranslationRequest
FTBatchTranslationRequest_Paragraph
FTBatchTranslationResponse
FTBatchTranslationCacheContainer
FTStartLanguageDetectionRequest
FTLanguageDetectionResponse
FTPronGuessStreamingRequest
FTPronGuessStreamingResponse
FTBatchRecoverStreamingRequest
FTBatchRecoverStreamingResponse
FTRecognitionStreamingRequest
FTRecognitionStreamingResponse
FTMultiUserStreamingRequest
FTMultiUserStreamingResponse
FTMultilingualStreamingRequest
FTMultilingualStreamingResponse
FTSpeechTranslationStreamingRequest
FTSpeechTranslationStreamingResponse
FTBatchTranslationStreamingRequest
FTBatchTranslationStreamingResponse
FTTextToSpeechRouterStreamingStreamingRequest
FTTextToSpeechRouterStreamingStreamingResponse
FTTextToSpeechStreamingStreamingRequest
FTTextToSpeechStreamingStreamingResponse
FTLanguageDetectionStreamingRequest
FTLanguageDetectionStreamingResponse
_LTOspreySpeechTranslationSession
FTSpeechTranslationResponseDelegate
_LTSpeechCompressorDelegate
LTArrayExtensions
_LTSpeechRecognitionResult
_LTAnalyticsEvent
_LTTextLanguageDetector
_LTTranslationParagraph
_LTSpeechRecognitionSausage
_LTSpeechRecognitionBin
_LTSpeechRecognitionTokensAlternative
FTApgService
FTAsrService
FTBlazarService
FTLmtService
FTNapgService
FTMtService
FTTtsService
FTNlService
FTAfmService
FTSlsService
FTPronGuessStreamingContext
FTBatchRecoverStreamingContext
FTRecognitionStreamingContext
FTMultiUserStreamingContext
FTMultilingualStreamingContext
FTSpeechTranslationStreamingContext
FTBatchTranslationStreamingContext
FTTextToSpeechRouterStreamingStreamingContext
FTTextToSpeechStreamingStreamingContext
FTLanguageDetectionStreamingContext
_LTTranslateSettingsController
_LTInstallRequest
_LTSpeechTranscription
JSONRepresentation
_LTLocalePair
_LTLoggingRequestHandler
_LTParagraphTranslationRequest
OspreyRequest
_LTTranslationToken
init
delegate
speechRecognitionResult:
enumerateKeysAndObjectsUsingBlock:
translatorDidTranslate:
translationDidFinishWithError:
count
locale
setObject:forKeyedSubscript:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
languageDetectionResult:
languageDetectionCompleted
hybridEndpointerFoundEndpoint
serverEndpointerFeatures:locale:
cancel
paragraphTranslation:result:error:
languageInstallProgressed:error:
stopBuffering
hasFailed
hasResults
setDelegate:
.cxx_destruct
_isBuffering
_lastASRResults
_translationResult
_didFinish
_error
_delegate
orderedSetWithObjects:
sharedInstance
logTranslateRequestEvent:requestType:routeType:
loggerQueue
setLoggerQueue:
requestTypeSet
setRequestTypeSet:
_loggerQueue
_requestTypeSet
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
copy
countByEnumeratingWithState:objects:count:
objectForKeyedSubscript:
unsignedIntegerValue
allObjects
countForObject:
addObject:
numberWithBool:
dictionaryWithObjects:forKeys:count:
decodeObjectOfClass:forKey:
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
encodeObject:forKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
initWithDetectedLocales:unknownLanguages:
initWithDetectionCounts:availableLocales:
dominantLocale
localeDetectionCount
unsupportedLanguageCounts
_dominantLocale
_localeDetectionCount
_unsupportedLanguageCounts
isEqualToString:
initWithContentsOfURL:
objectForKey:
floatValue
numberWithUnsignedInt:
enumerateObjectsUsingBlock:
URLByDeletingLastPathComponent
URLByAppendingPathComponent:
modelWithContentsOfURL:error:
path
modelDescription
numberWithUnsignedInteger:
initWithShape:dataType:error:
integerValue
bestTranscription
minConfidence
numberWithDouble:
setObject:atIndexedSubscript:
maxConfidence
confidence
confidences
sourceLocale
doubleValue
localePair
cannonicalLocalePair
targetLocale
getModelFeatures:canonicalPair:sourceSpeechResult:targetSpeechResult:
initWithDictionary:error:
setUsesCPUOnly:
predictionFromFeatures:options:error:
featureValueForName:
multiArrayValue
objectAtIndexedSubscript:
modelVersion
oppositeToLocale:
initWithSourceLocale:targetLocale:
_ltLocaleIdentifier
initWithConfidences:isConfident:dominantLanguage:isFinal:
initWithConfig:
estimateLanguage:languageDetectionResult:finalSpeechResults:
_mlModel
_modelInput
_modelOutput
_features
_missingLanguageDetectorDefault
string
alternative_index
positional_tok_phrase_alt
tok_phrases
tokens
token_text
appendString:
add_space_after
setConfidence:
setMinConfidence:
setMaxConfidence:
setFormattedString:
initWithRecognitionChoice:inSausage:
array
standardUserDefaults
registerDefaults:
_setupMemoryWarningListener
initWithMachServiceName:
_setQueue:
resume
notifyOfMemoryPressure
valueForEntitlement:
boolValue
processIdentifier
initWithConnection:server:
removeObject:
initialize
listener:shouldAcceptNewConnection:
clientConnectionClosed:
_translationListener
_listenerQueue
_connections
_server
decodeIntegerForKey:
decodeBoolForKey:
decodeInt32ForKey:
encodeInteger:forKey:
encodeBool:forKey:
encodeInt32:forKey:
uniqueID
setUniqueID:
sessionID
setSessionID:
taskHint
setTaskHint:
setLocalePair:
autodetectLanguage
setAutodetectLanguage:
censorSpeech
setCensorSpeech:
outputFileURL
setOutputFileURL:
asrModelURLs
setAsrModelURLs:
mtModelURL
setMtModelURL:
sourceURL
setSourceURL:
autoEndpoint
setAutoEndpoint:
lidThreshold
setLidThreshold:
route
setRoute:
audioSessionID
setAudioSessionID:
asrConfidenceThreshold
setAsrConfidenceThreshold:
clientIdentifier
setClientIdentifier:
dataSharingOptInStatus
setDataSharingOptInStatus:
_autodetectLanguage
_censorSpeech
_autoEndpoint
_audioSessionID
_uniqueID
_sessionID
_taskHint
_localePair
_outputFileURL
_asrModelURLs
_mtModelURL
_sourceURL
_lidThreshold
_route
_asrConfidenceThreshold
_clientIdentifier
_dataSharingOptInStatus
localeWithLocaleIdentifier:
containsObject:
languageCode
allKeys
setDominantLanguage:
setConfidences:
dominantLanguage
isConfident
isFinal
setIsFinal:
_isConfident
_isFinal
_dominantLanguage
_confidences
languageDetectorAssetWithError:
languageDetectorModelURL
initWithModelURL:
featureCombinationConfigUrl
reversedPair
_ltCsLocaleIdentifier
setSamplingRate:
setWithObjects:
setDictationLanguages:
resetForNewRequest:
isEqualToNumber:
initWithDouble:
endAudio
sendFinalLanguageDetectionResult
length
addSamples:numSamples:
cancelCurrentRequest
dictionary
localeIdentifier
languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:
startLanguageDetectionWithContext:delegate:
addSpeechRecognitionResult:
addSpeechAudioData:
cancelLanguageDetection
samplingRate
audioBitDepth
lastResult
setLastResult:
featureCombinationModelSupported
setFeatureCombinationModelSupported:
featureCombinationModel
setFeatureCombinationModel:
_context
_csLanguageDetector
_sourceLocaleConfidenceThreshold
_targetLocaleConfidenceThreshold
_endAudioCalled
_finalSpeechResults
_lidSignpostID
_resultQueue
_featureCombinationModelSupported
_samplingRate
_audioBitDepth
_lastResult
_featureCombinationModel
stringWithFormat:
encodeInt64:forKey:
encodeDouble:forKey:
decodeInt64ForKey:
decodeDoubleForKey:
progress
setProgress:
setLocaleIdentifier:
offlineState
setOfflineState:
totalExpected
setTotalExpected:
totalWritten
setTotalWritten:
isStalled
setIsStalled:
expectedTimeRemaining
setExpectedTimeRemaining:
_isStalled
_progress
_localeIdentifier
_offlineState
_totalExpected
_totalWritten
_expectedTimeRemaining
errorWithDomain:code:userInfo:
mainBundle
localizedStringForKey:value:table:
mutableCopy
lt_errorWithCode:description:userInfo:
currentLocale
localizedStringForLocaleIdentifier:
lt_internalErrorWithCode:description:userInfo:
lt_onlineNotImplementedError
lt_incompatibleForcedRoutes
lt_lidModelLoadError
lt_speechTranslationOngoingError
lt_invalidRequestErrorWithDescription:
lt_speechTranslationOngoing
lt_speechLimitExceeded
lt_translationTimeout
lt_offlineTTSErrorWithError:
lt_unsupporedLocalePairError:
completion
setCompletion:
paragraph
setParagraph:
requestParagraph
setRequestParagraph:
_completion
_paragraph
_requestParagraph
request_id
content_type
contentAsFTBatchTranslationResponse
paragraph_id
return_code
return_string
span
translated_text
text
initWithOspreyBatchResponse:
setIdentifier:
setLocale:
setSourceString:
spans
updateAlignmentWithSourceSpan:targetSpan:
removeObjectForKey:
setHasFinalServerResponse:
contentAsFTFinalBlazarResponse
return_str
allValues
timeIntervalSinceNow
setResponseTimeMs:
setBatchTranslationEvent:
wrapAsAnyEvent
data
sharedLogger
report:application:
callCompletionHandlersWithError:
removeAllObjects
streamDidReceiveBatchTranslationStreamingResponse:
streamFailVerifyBatchTranslationStreamingResponse:
request
setRequest:
toLocale
setToLocale:
metricEvent
setMetricEvent:
batchedParagraphs
setBatchedParagraphs:
bufferSize
setBufferSize:
setSourceLocale:
setTargetLocale:
requestID
setRequestID:
startTime
setStartTime:
hasFinalServerResponse
completionHandlerCalled
setCompletionHandlerCalled:
_hasFinalServerResponse
_completionHandlerCalled
_request
_toLocale
_metricEvent
_batchedParagraphs
_bufferSize
_sourceLocale
_targetLocale
_requestID
_startTime
setMaxConcurrentOperationCount:
getSiriDataSharingOptInStatusWithCompletion:
defaultSessionConfiguration
initWithURL:configuration:
setUseCompression:
set_sourceApplicationBundleIdentifier:
blazarServiceWithBundleID:
_webTaskService
_blazarService
date
updateServerTimeout
serverTimeoutFired
timeIntervalSinceDate:
sendBatchTranslationRequestWithDelegate:
tokenize:forLocale:
ttsCache
audioDataForKey:
_ospreyTTSRequestWithText:
language
gender
_serviceForTask:
speech_id
setClientTraceIdentifier:
error_code
error_str
decoder_description
audioStreamBasicDescription
audio
initWithASBD:rawData:
cacheAudioData:forKey:
performTextToSpeechRouter:requestBuilder:completion:
_tokenizeString:inLocale:
UUID
UUIDString
setTask:
setSpeech_id:
setRequest_id:
setSource_language:
setTarget_language:
setTranslation_phrase:
setApp_id:
_service
initWithOspreyResponse:
performTranslation:requestBuilder:completion:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
identifier
setTranslations:
startServerTimeoutTimer
setParagraph_id:
setText:
range
setStart_index:
setEnd_index:
shouldTranslate
setDo_not_translate:
metaInfoData
initWithData:encoding:
setMeta_info:
_ltCompactMap:
setSpan:
cancelServerTimeout
setSession_id:
absoluteString
setUrl:
setParagraphs:
task
setContentAsFTBatchTranslationRequest:
setContent_type:
setTranslationTask:
setSourceLanguage:
setTargetLanguage:
setDeviceOS:
setDeviceType:
setOsVersion:
setBundleIdentifier:
session_id
setSystemLocale:
paragraphs
setNumberOfParagraphs:
performBatchTranslationWithDelegate:requestBuilder:completion:
sendBatchTranslationStreamingRequest:
closeStream
timedEventWithName:
addFieldsFromDictionary:
sendLazy
_translate:context:completion:
_translateParagraph:index:context:completion:
_hasOngoingSpeechSession
initWithService:context:text:delegate:
_speechSessionCompletedWithError:
setCompletionBlock:
setLanguagesRecognized:
sendAudioData:
endpoint
sendEndAudio
initWithService:context:delegate:
setTtsCache:
translatesPair:
preheatAsynchronously:withContext:
translateSentence:withContext:completion:
translate:withContext:paragraphResult:completion:
startSpeechTranslationWithContext:delegate:
cancelSpeechTranslation
speak:withContext:completion:
startTextToSpeechTranslationWithContext:text:delegate:
serverQueue
setServerQueue:
_sendQueue
_translationQueue
_speechSession
batchTranslationResponseHandler
_timerQueue
_serverTimer
_assistantSettingsConnection
_ttsCache
_serverQueue
boolForKey:
dictionaryForKey:
setObject:forKey:
configurationPropertyListWithName:
stringByAppendingString:
cannonicalIdentifier
compare:
numberWithInteger:
CDN_propertyList
pairWithIdentifiers:
null
URLWithString:
_populateWithOpusData:
bytes
appendBytes:length:
defaultManager
fileExistsAtPath:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
writeToURL:options:error:
writeToURL:
asbd
rawData
packetCount
packetDescriptions
_asbd
_data
_packetCount
_packetDescriptions
_rawData
num_of_words
trailing_silence_duration
eos_likelihood
pause_counts
silence_posterior
processed_audio_duration_ms
defaultServerEndpointFeatures
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
endOfSentenceLikelihood
setEosLikelihood:
setPauseCounts:
silencePosterior
setSilencePosterior:
setProcessedAudioDurationInMilliseconds:
GetDefaultEndpointerFeaturesForEndpointer:
initWithResponse:
eosLikelihood
pauseCounts
processedAudioDurationInMilliseconds
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
endpointAssetInfoWithContext:error:
caesuraModelURL
initWithConfigFile:samplingRate:
endpointerModelURL:
initWithConfiguration:
requestSupportedWithSamplingRate:
updateEndpointerThresholdWithValue:
addAudio:numSamples:
processedAudioMs
silenceFramesCountMs
silenceProbability
silenceDurationMs
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
clientSilenceFramesCountMs
serverFeaturesLatency
clientSilenceProbability
componentsJoinedByString:
didEndpointWithFeatures:silenceFeatures:endpointer:
clientSilenceFeaturesAvailable:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
startEndpointingWithContext:delegate:
setServerEndpointerFeatures:withLocale:
endpointerThreshold
setEndpointerThreshold:
clientLagThresholdMs
setClientLagThresholdMs:
clampedSFLatencyMsForClientLag
setClampedSFLatencyMsForClientLag:
useDefaultServerFeaturesOnClientLag
setUseDefaultServerFeaturesOnClientLag:
_asset
_sourceEndpointer
_sourceEndpointerThreshold
_sourceDisconnectedEndpointerThreshold
_sourceEndpointerFeatures
_targetEndpointer
_targetEndpointerThreshold
_targetDisconnectedEndpointerThreshold
_targetEndpointerFeatures
_spg
_didEndpoint
_queue
_featureQueue
_endpointerSignpostID
_useDefaultServerFeaturesOnClientLag
_endpointerThreshold
_clientLagThresholdMs
_clampedSFLatencyMsForClientLag
_LTAssetStateString
status
setStatus:
voiceAsset
setVoiceAsset:
error
setError:
localIdentifiers
setLocalIdentifiers:
update
setUpdate:
_status
_voiceAsset
_identifier
_localIdentifiers
_update
sortedArrayUsingSelector:
componentsSeparatedByString:
identifiersInIdentifiers:forLanguageName:
arrayByAddingObjectsFromArray:
subarrayWithRange:
_configPlistWithFileName:
addObjectsFromArray:
hasPrefix:
hasSuffix:
attributes
languageToStatusDictionary
installationStatusArray
numberWithLongLong:
updateProgress
downloadAsset:userInitiated:useCellular:progressCallback:completion:
_setInstalledLocales:
catalogAssets
installedAssets
setDiscretionary:
setAllowsCellularAccess:
setRequiresPowerPluggedIn:
pairNamesForLocales:
assetNamesForPairNames:
substringFromIndex:
_vsLocaleIdentifier
_voiceAssetForLocaleIdentifier:
sharedManager
languages
firstObject
genderStringFromGender:
downloadVoiceAsset:options:progressUpdateHandler:
setAutoDownloadedVoiceAssets:
removeObjectsInArray:
matchingASRAssetForLocale:inAssets:
assetWithName:inAssets:
identifiersInIdentifiers:forAssetName:
downloadAsset:withStatus:
isConfig
purge:
assetsNamesForLocale:
installedLocales:
setInstalledLocales:useCellular:completion:
_assetManager
_assetStatusDictionary
_localeIdentifierList
_completionHandler
_useCellular
valueWithRange:
rangeValue
sourceRange
setSourceRange:
targetRange
setTargetRange:
setShouldTranslate:
_shouldTranslate
_text
_sourceRange
_targetRange
initWithAudioSessionID:ASBD:
start
enqueue:packetCount:packetDescriptions:
flushAndStop
reset
_playback:context:completion:
stop
initWithEngine:
speak:context:completion:
_engine
_player
initWithSessionID:taskHint:localePair:deviceOS:deviceType:appIdentifier:
deviceOS
deviceType
appIdentifier
_deviceOS
_deviceType
_appIdentifier
endpointerIsAvailableWithContext:
selectAsset:withLocale:
getPreferredAsset:orAsset:withLocale:
valueForKey:
isPremium:
state
getLocalUrl
initWithAvailableAssets:context:
hybridepAssetFile
spgAssetFile
_spgAsset
_sourceLanguageAsset
_targetLanguageAsset
_hybridepAssetFile
_spgAssetFile
requestContext
forcedOfflineTranslation
_forcedOnlineTranslation
_startTranslationWithService:done:
completionHandler
setCompletionHandler:
modelURLForLanguagePair:
_getTranslationConfig
referenceAssets:catalogAssets:
updateAvailableInAssets:
_validateSymlinksForAssets:
_createSymlinkDirectoryForAssets:
isMTModel
isPhrasebook
matchesAsset:
isNewerCompatibleVersionThan:
getLocalFileUrl
isPassthrough
isCurrentlyAvailable
_mtModelOfflineState
initWithLocales:
setMtState:
setSourceASRState:
setTargetASRState:
setPairState:
setNeedsUpdate:
assetDirectory
_languagePairDirectory
dataWithContentsOfURL:
JSONObjectWithData:options:error:
assetId
configAsset
URLByAppendingPathExtension:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
linkItemAtURL:toURL:error:
dataWithJSONObject:options:error:
writeToURL:atomically:
removeItemAtURL:error:
moveItemAtURL:toURL:error:
currentProgress
initWithParent:userInfo:
setTotalUnitCount:
becomeCurrentWithPendingUnitCount:
downloadAsset:userInitiated:progressCallback:completion:
resignCurrent
assetIdentifierReferenceCountDictionary
deleteAsset:completion:
initWithInstalledAssets:catalogAssets:localePair:configInfo:assetManager:
createSymlinkDirectoryForMTAssets
speechModelURLForLocale:
speechModelVersionForLocale:
translationModelURL
isCompletePasshtroughModel
isCompleteBidirectionalModel
availabilityInfo
downloadAssetsUserInitiated:queue:completion:
purgeAssetUserInitiated:queue:completion:
_pairDictionary
_sourceASRModel
_targetASRModel
_allAssets
_mtAssets
_missingAssets
_missingMTAssets
_needsUpdate
_modelURL
refreshState
stringByReplacingOccurrencesOfString:withString:options:range:
_ltRemoveAllWhitespaces
_ltTrimWhitespaces
whitespaceCharacterSet
componentsSeparatedByCharactersInSet:
_countWithTokenString:countCharacters:
setInputTokenCount:
setInputSubtokenCount:
allocWithZone:
inputTokenCount
inputSubtokenCount
statisticsWithEngineMeta:locale:
copyWithZone:
_inputTokenCount
_inputSubtokenCount
initWithLocalePair:
_offlineMTModelURL
opaqueSessionID
loggingType
_translationFailedWithError:
setForcedOfflineTranslation:
set_forcedOnlineTranslation:
set_offlineMTModelURL:
_mtConfidenceThreshold
set_mtConfidenceThreshold:
_forcedOfflineTranslation
__forcedOnlineTranslation
__offlineMTModelURL
__mtConfidenceThreshold
sentence
translations
formattedString
setSentence:
textHandler
setTextHandler:
translationHandler
setTranslationHandler:
_sentence
_textHandler
_translationHandler
_paragraphs
_offlineASRModelURLs
initWithStreamDescription:
startSpeechTranslationWithContext:
_appendAudioPCMBuffer:
_appendAudioSampleBuffer:simulateRealtime:
nativeAudioFormat
format
int16ChannelData
frameLength
dataWithBytes:length:
_convertAndFeedPCMBuffer:
processInfo
systemUptime
sleepForTimeInterval:
subdataWithRange:
_drainAndClearAudioConverter
_simulateRealtimeBehavior:
initWithPCMFormat:frameCapacity:
setFrameLength:
mutableAudioBufferList
convertToBuffer:error:withInputFromBlock:
inputFormat
initFromFormat:toFormat:
setSampleRateConverterQuality:
appendAudioPCMBuffer:
append:simulateRealtime:
_lidModelURL
set_lidModelURL:
set_offlineASRModelURLs:
set_asrConfidenceThreshold:
set_lidThreshold:
_converter
_queuedBuffers
_done
__lidModelURL
__offlineASRModelURLs
__asrConfidenceThreshold
__lidThreshold
startTextToSpeechTranslationWithContext:text:
initWithLength:
mutableBytes
UTF8String
getCharacters:range:
predicateWithFormat:
filteredArrayUsingPredicate:
initWithUnit:
setLanguage:
setString:
substringWithRange:
enumerateTokensInRange:usingBlock:
stringWithCharacters:length:
_ltSentencesForLocale:
clear
_cacheQueue
_cache
startCatalogDownload:options:then:
compareAssetVersionReversed:
isInstalled
isDownloading
configAssetInAssets:
code
_clearCaches
updateAllAssets:
_refreshAllAssets:
_refreshCatalogIfNeededWithCompletion:
results
assetsSortedByVersion:
isASRModel
transcribesLocale:
isANEModel
sessionWithConfiguration:
dataTaskWithURL:completionHandler:
dataWithContentsOfURL:options:error:
propertyListWithData:options:format:error:
bundleForClass:
URLForResource:withExtension:
sortUsingComparator:
_speechTranslationAssetInfoForLocalePair:installedAssets:catalogAssets:config:error:
downloadAsset:downloadOptions:progressCallback:completion:
longLongValue
progressWithTotalUnitCount:
setCompletedUnitCount:
attachProgressCallBack:
totalUnitCount
startDownload:then:
_queryLanguagePairStatus:
preferredVoiceGender
arrayWithObject:
setLanguages:
setGender:
_downloadVoiceAsset:
getAutoDownloadedVoiceAssets:
URLForDirectory:inDomain:appropriateForURL:create:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
_assetIdentifiersForLanguagePairDirectory:
numberWithLong:
_speechTranslationAssetInfoForLocalePair:error:
debugDumpAssets:
needsUpdate
updateSpeechTranslationAssetSymLinks:
pairState
downloadVoiceAssetsForLanguagePair:
refreshAllIfNeededWithCompletion:
_downloadPassthroughAssetForLocale:userInitiated:completion:
getEndpointerAssetWithType:error:
resourceURL
fallBackAssetResourcePath
checkResourceIsReachableAndReturnError:
initWithAssetUrl:featureCombinationAssetUrl:
localizedDescription
configurationPropertyListWithURL:
configAssetURL
addEntriesFromDictionary:
offlineLanguageStatus:
purgeAssetForLanguagePair:userInitiated:completion:
purgeAllAssetsExcludingConfig:completion:
downloadAssetsForLanguagePair:userInitiated:completion:
speechTranslationAssetInfoForLocalePair:error:
assetSize:
initWithType:
returnTypes:
queryMetaDataSync
profile_blob
setProfile_blob:
profile_blob:
profile_blob_version
setProfile_blob_version:
profile_checksum
setProfile_checksum:
acoustic_profile_blob
acoustic_profile_version
setAcoustic_profile_version:
setAcoustic_profile_blob:
acoustic_profile_blob:
intValue
initWithInt:
initWithBool:
setToken_text:
start_milli_seconds
setStart_milli_seconds:
end_milli_seconds
setEnd_milli_seconds:
silence_start_milli_seconds
setSilence_start_milli_seconds:
setAdd_space_after:
phone_seq
setPhone_seq:
ipa_phone_seq
setIpa_phone_seq:
setTokens:
setTok_phrases:
has_unsuggested_alternatives
setHas_unsuggested_alternatives:
setPositional_tok_phrase_alt:
setAlternative_index:
itn_alignment
setItn_alignment:
post_itn_choice_indices
setPost_itn_choice_indices:
pre_itn_token_to_post_itn_char_alignments
setPre_itn_token_to_post_itn_char_alignments:
pre_itn
setPre_itn:
post_itn
setPost_itn:
pre_itn_nbest_choices
setPre_itn_nbest_choices:
post_itn_nbest_choices
setPost_itn_nbest_choices:
pre_itn_token_to_post_itn_char_alignment
setPre_itn_token_to_post_itn_char_alignment:
choice_alignments
setChoice_alignments:
bool_stats
setBool_stats:
int32_stats
setInt32_stats:
double_stats
setDouble_stats:
request_locale
setRequest_locale:
name
setName:
value
setValue:
first_pre_itn_token_index
setFirst_pre_itn_token_index:
last_pre_itn_token_index
setLast_pre_itn_token_index:
first_post_itn_char_pos
setFirst_post_itn_char_pos:
last_post_itn_char_pos
setLast_post_itn_char_pos:
initWithFloat:
acoustic_feature_per_frame
setAcoustic_feature_per_frame:
frame_duration
setFrame_duration:
speech_recognition_features
setSpeech_recognition_features:
acoustic_features
setAcoustic_features:
setKey:
initWithInteger:
setReturn_code:
setReturn_str:
recognition_result
setRecognition_result:
lang_profile_recreate_codes
setLang_profile_recreate_codes:
audio_analytics
setAudio_analytics:
watermark_detection
setWatermark_detection:
watermark_peak_average
setWatermark_peak_average:
latnn_mitigator_result
setLatnn_mitigator_result:
has_result
setHas_result:
recognition_text
setRecognition_text:
is_stable_result
setIs_stable_result:
audio_duration_ms
setAudio_duration_ms:
unsignedLongValue
initWithUnsignedLong:
initWithUnsignedInteger:
task_name
setTask_name:
codec
setCodec:
stream_results
setStream_results:
enable_server_side_endpoint
setEnable_server_side_endpoint:
device_type
setDevice_type:
device_os
setDevice_os:
mic_type
setMic_type:
udm_host
setUdm_host:
udm_port
setUdm_port:
tandem_mode
setTandem_mode:
store_audio
setStore_audio:
stream_unstable_results
setStream_unstable_results:
end_point_mode
setEnd_point_mode:
start_audio_bookmark
setStart_audio_bookmark:
is_far_field
setIs_far_field:
enable_utterance_detection
setEnable_utterance_detection:
enable_endpoint_candidate
setEnable_endpoint_candidate:
start_recognition_at
setStart_recognition_at:
start_endpointing_at
setStart_endpointing_at:
enable_hybrid_endpoint
setEnable_hybrid_endpoint:
client_endpointer_model_version
setClient_endpointer_model_version:
keyboard_identifier
setKeyboard_identifier:
input_origin
setInput_origin:
initial_recognition_candidate_id
setInitial_recognition_candidate_id:
disable_auto_punctuation
setDisable_auto_punctuation:
keyboard_dictation
setKeyboard_dictation:
experiment_id
setExperiment_id:
speech_request_source
setSpeech_request_source:
fork_id
setFork_id:
application_name
setApplication_name:
metadata
setMetadata:
start_speech_request
setStart_speech_request:
user_parameters
setUser_parameters:
primary_speech_id
setPrimary_speech_id:
product_id
setProduct_id:
vendor_id
setVendor_id:
contextual_text
setContextual_text:
pron_hints
setPron_hints:
left_context
setLeft_context:
right_context
setRight_context:
context_with_pron_hints
setContext_with_pron_hints:
user_language_profile
setUser_language_profile:
user_acoustic_profile
setUser_acoustic_profile:
audio_bytes
setAudio_bytes:
audio_bytes:
packet_count
setPacket_count:
total_audio_recorded_seconds
setTotal_audio_recorded_seconds:
features_at_endpoint
setFeatures_at_endpoint:
server_feature_latency_distribution
setServer_feature_latency_distribution:
updated_acoustic_profile
setUpdated_acoustic_profile:
pronunciations
orthography
setOrthography:
setPronunciations:
pronunciations:
frequency
setFrequency:
setTag:
setAttributes:
category_name
setCategory_name:
category_data
setCategory_data:
user_data
setUser_data:
setError_code:
setError_str:
incomplete_profile
setIncomplete_profile:
recreate_apg_prons
setRecreate_apg_prons:
reason
setReason:
phonemes
setPhonemes:
blob
setBlob:
blob:
apg_id
setApg_id:
voc_token
setVoc_token:
tts_pronunciations
setTts_pronunciations:
human_readable_prons
setHuman_readable_prons:
apg_ids
setApg_ids:
recovery_return_codes
setRecovery_return_codes:
voc_tokens
setVoc_tokens:
num_of_requested
setNum_of_requested:
num_of_processed
setNum_of_processed:
num_of_succeeded
setNum_of_succeeded:
words_list
setWords_list:
formatted_words_list
setFormatted_words_list:
post_itn_string
setPost_itn_string:
nbest_variants_max
setNbest_variants_max:
normalized_tokens
setNormalized_tokens:
original_token
setOriginal_token:
nbest_variants
setNbest_variants:
pron_sequence
setPron_sequence:
log_weight
setLog_weight:
token
setToken:
pron_source
setPron_source:
sanitized_sequences
setSanitized_sequences:
prons
setProns:
normalized_prons
setNormalized_prons:
sanitized_tokens
setSanitized_tokens:
is_pron_guessed
setIs_pron_guessed:
g2p_version
setG2p_version:
g2p_model_version
setG2p_model_version:
phoneset_version
setPhoneset_version:
aot_token_prons
setAot_token_prons:
jit_token_prons
setJit_token_prons:
index
setIndex:
start_index
end_index
do_not_translate
meta_info
raw_sausage
setRaw_sausage:
raw_nbest_choices
setRaw_nbest_choices:
post_itn_tokens
setPost_itn_tokens:
post_itn_recognition
setPost_itn_recognition:
itn_alignments
setItn_alignments:
translation_phrase
pre_itn_payload
setPre_itn_payload:
post_itn_payload
setPost_itn_payload:
pre_sausage_payload
setPre_sausage_payload:
setSpans:
source_language
target_language
siri_translation_info
setSiri_translation_info:
speech_translation_info
setSpeech_translation_info:
siri_payload_translation_info
setSiri_payload_translation_info:
sequence_id
setSequence_id:
web_translation_info
setWeb_translation_info:
disable_log
setDisable_log:
opt_in_status
setOpt_in_status:
app_id
setReturn_string:
n_best_translated_phrases
setN_best_translated_phrases:
engine_input
setEngine_input:
engine_output
setEngine_output:
mt_alignment
setMt_alignment:
translated_tokens
setTranslated_tokens:
low_confidence
setLow_confidence:
end_point_likelihood
setEnd_point_likelihood:
setProcessed_audio_duration_ms:
latitude
setLatitude:
longitude
setLongitude:
enable_geo_location_features
setEnable_geo_location_features:
longValue
initWithLong:
speech_packet_count
setSpeech_packet_count:
processed
setProcessed:
version
setVersion:
threshold
setThreshold:
score
setScore:
result_id
setResult_id:
setSnr:
fingerprint_detection
setFingerprint_detection:
start_speech_time
setStart_speech_time:
end_speech_time
setEnd_speech_time:
speech_detected
setSpeech_detected:
audio_packets
setAudio_packets:
ref_transcript
setRef_transcript:
blamer_report
setBlamer_report:
token_str
setToken_str:
log10_score
setLog10_score:
ngram_used
setNgram_used:
transcript
setTranscript:
setPpl:
enable_completion
setEnable_completion:
max_results
setMax_results:
max_expand_paths
setMax_expand_paths:
max_tm_score
setMax_tm_score:
abs_pruning_threshold
setAbs_pruning_threshold:
rel_pruning_threshold
setRel_pruning_threshold:
enable_word_boundary
setEnable_word_boundary:
max_path_num_at_boundary
setMax_path_num_at_boundary:
parabolic_error_wide
setParabolic_error_wide:
parabolic_error_center
setParabolic_error_center:
parabolic_error_bias
setParabolic_error_bias:
parabolic_error_min
setParabolic_error_min:
max_latency
setMax_latency:
word_penalty
setWord_penalty:
delimiter
setDelimiter:
matched_result
setMatched_result:
total_score
setTotal_score:
tm_score
setTm_score:
match_ids
setMatch_ids:
debug_information
setDebug_information:
matcher_id
setMatcher_id:
query
setQuery:
target
setTarget:
config
setConfig:
latency
setLatency:
expanded_path
setExpanded_path:
setResults:
keyword_orthography
setKeyword_orthography:
posterior
setPosterior:
keywords
setKeywords:
enable_sanitization
setEnable_sanitization:
corrected_sausage
setCorrected_sausage:
n_best_list
setN_best_list:
setNum_of_words:
setTrailing_silence_duration:
setEos_likelihood:
setPause_counts:
setSilence_posterior:
original_utterance
setOriginal_utterance:
corrected_utterance
setCorrected_utterance:
original_words
setOriginal_words:
corrected_words
setCorrected_words:
corrections
setCorrections:
fe_feature
setFe_feature:
fe_feature_only
setFe_feature_only:
disable_prompts
setDisable_prompts:
quality
setQuality:
type
setType:
voice
setVoice:
resource
setResource:
channel_type
setChannel_type:
context_info
setContext_info:
dialog_identifier
setDialog_identifier:
experiment_identifier
setExperiment_identifier:
word_phonemes
setWord_phonemes:
prompts_v2
prompts
setPrompts:
setPrompts_v2:
prompts_v2:
original
setOriginal:
replacement
setReplacement:
normalized_text
setNormalized_text:
phoneme_sequence
setPhoneme_sequence:
force_use_tts_service
setForce_use_tts_service:
disable_cache
setDisable_cache:
setData:
data:
resources
setResources:
audio_type
setAudio_type:
enable_word_timing_info
setEnable_word_timing_info:
voice_name
setVoice_name:
preferred_voice_type
setPreferred_voice_type:
context
setContext:
experiment
setExperiment:
feature_flags
setFeature_flags:
debug
setDebug:
profile
setProfile:
sample_rate
setSample_rate:
format_id
setFormat_id:
format_flags
setFormat_flags:
bytes_per_packet
setBytes_per_packet:
frames_per_packet
setFrames_per_packet:
bytes_per_frame
setBytes_per_frame:
channels_per_frame
setChannels_per_frame:
bits_per_channel
setBits_per_channel:
reserved
setReserved:
word
setWord:
sample_idx
setSample_idx:
offset
setOffset:
setLength:
timestamp
setTimestamp:
setAudio:
audio:
setDecoder_description:
playback_description
setPlayback_description:
word_timing_info
setWord_timing_info:
feature
setFeature:
stream_id
setStream_id:
streaming_playback_buffer_size_in_seconds
setStreaming_playback_buffer_size_in_seconds:
current_pkt_number
setCurrent_pkt_number:
total_pkt_number
setTotal_pkt_number:
audio_length
setAudio_length:
original_session_id
setOriginal_session_id:
cache_meta_info
setCache_meta_info:
cache_object
setCache_object:
endpoint_threshold
setEndpoint_threshold:
endpoint_extra_delay
setEndpoint_extra_delay:
audio_frames
setAudio_frames:
source_locale
setSource_locale:
target_locale
setTarget_locale:
conversation_id
setConversation_id:
translation_locale_pairs
setTranslation_locale_pairs:
translation_request
setTranslation_request:
text_to_speech_requests
setText_to_speech_requests:
restricted_mode
setRestricted_mode:
translation_locale_pair
setTranslation_locale_pair:
detected_locale
setDetected_locale:
user_selected_locale
setUser_selected_locale:
senses
setSenses:
user_selected_sense
setUser_selected_sense:
user_interacted_senses
setUser_interacted_senses:
text_to_speech_response
setText_to_speech_response:
server_endpoint_features
setServer_endpoint_features:
utterance
setUtterance:
shortcuts
setShortcuts:
interaction_id
setInteraction_id:
raw_string
setRaw_string:
shortcut_score_pairs
setShortcut_score_pairs:
shortcut
setShortcut:
similarity_score
setSimilarity_score:
language_parameters_by_id
setLanguage_parameters_by_id:
is_low_confidence
setIs_low_confidence:
predictions
setPredictions:
setTranslated_text:
sentence_count
setSentence_count:
locales
setLocales:
contentAsFTStartPronGuessRequest
setContentAsFTStartPronGuessRequest:
contentAsFTAudioPacket
setContentAsFTAudioPacket:
contentAsFTFinishAudio
setContentAsFTFinishAudio:
contentAsFTCancelRequest
setContentAsFTCancelRequest:
contentAsFTPronGuessResponse
setContentAsFTPronGuessResponse:
contentAsFTStartBatchRecoverRequest
setContentAsFTStartBatchRecoverRequest:
contentAsFTBatchRecoverFinalResponse
setContentAsFTBatchRecoverFinalResponse:
contentAsFTStartSpeechRequest
setContentAsFTStartSpeechRequest:
contentAsFTUpdateAudioInfo
setContentAsFTUpdateAudioInfo:
contentAsFTSetRequestOrigin
setContentAsFTSetRequestOrigin:
contentAsFTSetSpeechContext
setContentAsFTSetSpeechContext:
contentAsFTSetSpeechProfile
setContentAsFTSetSpeechProfile:
contentAsFTSetEndpointerState
setContentAsFTSetEndpointerState:
contentAsFTResetServerEndpointer
setContentAsFTResetServerEndpointer:
contentAsFTCheckForSpeechRequest
setContentAsFTCheckForSpeechRequest:
contentAsFTSetAlternateRecognitionSausage
setContentAsFTSetAlternateRecognitionSausage:
contentAsFTFinalSpeechRecognitionResponse
setContentAsFTFinalSpeechRecognitionResponse:
contentAsFTPartialSpeechRecognitionResponse
setContentAsFTPartialSpeechRecognitionResponse:
contentAsFTUpdatedAcousticProfile
setContentAsFTUpdatedAcousticProfile:
contentAsFTEndPointLikelihood
setContentAsFTEndPointLikelihood:
contentAsFTEndPointCandidate
setContentAsFTEndPointCandidate:
contentAsFTRecognitionProgress
setContentAsFTRecognitionProgress:
contentAsFTCheckForSpeechResponse
setContentAsFTCheckForSpeechResponse:
contentAsFTRecognitionCandidate
setContentAsFTRecognitionCandidate:
contentAsFTRequestStatsResponse
setContentAsFTRequestStatsResponse:
contentAsFTServerEndpointFeatures
setContentAsFTServerEndpointFeatures:
contentAsFTClientSetupInfo
setContentAsFTClientSetupInfo:
contentAsFTAudioLimitExceeded
setContentAsFTAudioLimitExceeded:
contentAsFTMultiUserStartSpeechRequest
setContentAsFTMultiUserStartSpeechRequest:
setContentAsFTFinalBlazarResponse:
contentAsFTStartMultilingualSpeechRequest
setContentAsFTStartMultilingualSpeechRequest:
contentAsFTLanguageDetected
setContentAsFTLanguageDetected:
contentAsFTStartSpeechTranslationRequest
setContentAsFTStartSpeechTranslationRequest:
contentAsFTSpeechTranslationAudioPacket
setContentAsFTSpeechTranslationAudioPacket:
contentAsFTStartSpeechTranslationLoggingRequest
setContentAsFTStartSpeechTranslationLoggingRequest:
contentAsFTSpeechTranslationPartialRecognitionResponse
setContentAsFTSpeechTranslationPartialRecognitionResponse:
contentAsFTSpeechTranslationFinalRecognitionResponse
setContentAsFTSpeechTranslationFinalRecognitionResponse:
contentAsFTSpeechTranslationMtResponse
setContentAsFTSpeechTranslationMtResponse:
contentAsFTSpeechTranslationTextToSpeechResponse
setContentAsFTSpeechTranslationTextToSpeechResponse:
contentAsFTSpeechTranslationServerEndpointFeatures
setContentAsFTSpeechTranslationServerEndpointFeatures:
contentAsFTBatchTranslationRequest
setContentAsFTBatchTranslationResponse:
contentAsFTStartTextToSpeechStreamingRequest
setContentAsFTStartTextToSpeechStreamingRequest:
contentAsFTBeginTextToSpeechStreamingResponse
setContentAsFTBeginTextToSpeechStreamingResponse:
contentAsFTPartialTextToSpeechStreamingResponse
setContentAsFTPartialTextToSpeechStreamingResponse:
contentAsFTFinalTextToSpeechStreamingResponse
setContentAsFTFinalTextToSpeechStreamingResponse:
contentAsFTQssAckResponse
setContentAsFTQssAckResponse:
contentAsFTStartLanguageDetectionRequest
setContentAsFTStartLanguageDetectionRequest:
contentAsFTLanguageDetectionResponse
setContentAsFTLanguageDetectionResponse:
pair
decodeObjectForKey:
setPair:
sourceASRState
targetASRState
mtState
sourceTTSState
setSourceTTSState:
targetTTSState
setTargetTTSState:
_pairState
_pair
_sourceASRState
_targetASRState
_mtState
_sourceTTSState
_targetTTSState
initWithOspreyToken:
stringWithString:
setLowConfidence:
updateWithEngineMeta:locale:
initWithOspreyPhrase:
initWithOspreyMtResponsePhrase:locale:
setFinal:
setModelVersion:
containsString:
setSanitizedFormattedString:
setTranscriptions:
initWithOspreySausage:choices:locale:
setBestRecognitionAlternatives:
initWithOspreyResponse:confidenceThreshold:isSanitized:
initWithOspreyPartialRecognitionResponse:isSanitized:
dictionaryWithDictionary:
initWithModelURLs:modelVersions:
initWithModelURL:language:
initWithModelURL:task:
loadTranslatorFrom:to:
_loadRecognizers
_loadTranslatorForTask:
_loadEtiquetteSanitizers
initWithText:confidence:
sanitizedStringForString:
lowConfidence
initWithFormattedString:sanitizedFormattedString:confidence:lowConfidence:tokens:preToPostITN:
metaInfo
resultWithLocale:translations:
addFieldsFromDictionary:internalOnly:
_handleTranslationResults:withContext:
setSanitizedSourceString:
translateTokens:from:to:completion:
sanitizedFormattedString
_translateString:withContext:toLocale:completion:
_paragraphResultFromSentences:
_ltSequentialMap:completion:
_translateParagraph:withContext:toLocale:completion:
_translate:withContext:toLocale:paragraphResult:completion:
cancelRecognition
initWithCompletion:
speak:withContext:
passthroughResultWithString:sanitizedString:locale:
addFieldsWithError:
timestampWithName:
_translate:withContext:completion:
transcriptions
isLowConfidence
_getBestRecognitionResult:context:
_waitForLIDWithContext:completion:
startRecognitionForLocale:autoEndpoint:resultHandler:
initWithLocalePair:assetInfo:
_speak:context:completion:
_assetInfo
_recognizer
_synthesizer
_etiquetteSanitizers
_translator
_callbackQueue
_lidWaitGroup
_lidBestResult
_lidResult
_didEndpointSpeech
initWithSuiteName:
setLanguageCode:
setOutputPath:
setCanUseServerTTS:
startSpeakingRequest:
stopSpeakingAtNextBoundary:synchronously:error:
dictionaryMetrics
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:withRequest:didReceiveTimingInfo:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishPrewarmRequest:withError:
speechSynthesizer:didFinishSynthesisRequest:withError:
speechSynthesizer:didStopPresynthesizedAudioRequestAtEnd:error:
speechSynthesizerDidStartSpeaking:
speechSynthesizer:didFinishSpeaking:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeaking:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizerDidPauseSpeaking:
speechSynthesizerDidContinueSpeaking:
speechSynthesizer:willSpeakRangeOfSpeechString:
stringByReplacingOccurrencesOfString:withString:
_ltEqual:
_assetUrl
_featureCombinationConfigUrl
setAlignments:
initWithOspreySpeechTranslationMTResponse:
initWithModelURL:language:modelVersion:
triggerServerSideEndPointer
startRecognitionWithAutoStop:resultHandler:
_recognizers
senseFromDictionary:
setSenseID:
setDefinition:
setPhrasebookMatch:
isPhrasebookMatch
setSourceMatch:
setTargetMatch:
setLabels:
sensesFromArray:
senseWithPhrasebookMatchMeta:
senseID
definition
sourceMatch
targetMatch
labels
_phrasebookMatch
_senseID
_definition
_sourceMatch
_targetMatch
_labels
conversationID
setConversationID:
selectedLocale
setSelectedLocale:
lidResult
setLidResult:
_conversationID
_selectedLocale
userInteractedSenses
setUserInteractedSenses:
_senses
_userInteractedSenses
combinedLocaleIdentifier
markResponse
markPageComplete
markFirstParagraphComplete
dict
firstResponse
pageComplete
firstParagraphComplete
processName
setProcessName:
_start
_firstResponse
_pageComplete
_firstParagraphComplete
_processName
service
setService:
_getServiceProxyWithDelegate:errorHandler:block:
translationParagraph
translateParagraphs:withContext:completion:
_ensureServiceConnection:
log:
initWithTranslator:
translate:
provideFeedback:
setURL:
translator
setTranslator:
_outstandingRequests
_logging
_URL
requiredCapabilityIdentifier
minimumSupportedConfigurationVersion
maximumSupportedConfigurationVersion
assetVersion
isCompatibleWithThisDevice
isNewerVersionThan:
localeIdentifiers
canBePurged
translatesLanguagePair:
formatVersion
initWithIdentifier:text:shouldTranslate:
setMetaInfo:
_metaInfo
dealloc
appendData:
replaceBytesInRange:withBytes:length:
didCompressPackets:totalPacketCount:
initWithDelegate:
startCompressionNarrowband:
addAudioSampleData:
_audioConverter
_bufferedAudio
_packetIndex
_bytesConsumed
initWithIdentifier:range:
setMetaInfoData:
_metaInfoData
_range
sourceString
sanitizedSourceString
alignments
_locale
_translations
_sourceString
_sanitizedSourceString
_alignments
offlineEngine
onlineEngine
setOfflineEngine:
setOnlineEngine:
offlineDelegateBuffer
setOfflineDelegateBuffer:
_onlineTranslationStarted
_translationEnded
_serverCompleted
_offlineEngine
_onlineEngine
_offlineDelegateBuffer
_ltAsyncMap:queue:completion:
objectEnumerator
nextObject
_ltAsyncMap:completion:
sourceContentAsJSON
setSourceContentAsJSON:
targetContentAsJSON
setTargetContentAsJSON:
errorsAsJSON
setErrorsAsJSON:
safariVersion
setSafariVersion:
webpageURL
setWebpageURL:
clientBundleID
setClientBundleID:
_sourceContentAsJSON
_targetContentAsJSON
_errorsAsJSON
_safariVersion
_webpageURL
_clientBundleID
clearCaches
_getSyncServiceProxyWithDelegate:errorHandler:block:
_offlineLanguageStatus:
_downloadAssetForLanguagePair:userInitiated:completion:
_purgeAssetForLanguagePair:userInitiated:completion:
_purgeAllAssets:
_updateAllAssets:
_getAssetSize:
_startInstallationWithService:done:
availableLocalePairsForTask:completion:
additionalLikelyPreferredLocalesForLocale:completion:
configInfoForLocale:otherLocale:completion:
task:isSupportedInCountry:completion:
languageForText:completion:
languagesForText:completion:
initWithMachServiceName:options:
setRemoteObjectInterface:
setExportedObject:
setExportedInterface:
setInterruptionHandler:
invalidate
remoteObjectProxyWithErrorHandler:
initWithServiceName:options:
synchronousRemoteObjectProxyWithErrorHandler:
preheatWithContext:completion:
cleanup
archivedDataWithRootObject:requiringSecureCoding:error:
logWithRequestData:
interruptionHandler
installOfflineLocales:completion:
taskIsSupportedInCurrentRegion:completion:
preheatForRequestSync:
preheatForRequest:completion:
startTranslationSession
_connection
initWithNode:range:
node
setNode:
setRange:
_node
_token
treeForReplacementTokens:
initWithReplacementTokenDictionary:language:
lowercaseString
enumerateSubstringsInRange:options:usingBlock:
replaceCharactersInRange:withString:
replacementStringForString:forToken:
matchesForString:
stringByReplacingMatches:inString:
_replacementTree
initWithConfiguration:useQuasarFormatter:
setDetectUtterances:
setConcatenateUtterances:
runRecognitionWithResultStream:language:task:samplingRate:
recognitionHandler
resultWithPackage:locale:modelVersion:isFinal:
emptyResultWithLocale:isFinal:
_recognizedResult:error:
detectUtterances
hasSpaceAfter
tokenName
hatToQsrString:
resultWithResult:locale:modelVersion:isFinal:
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
modelURL
setRecognitionHandler:
_buffer
_detectedSpeechEndpoint
_finalResult
_recognitionQueue
_modelVersion
_language
_recognitionHandler
retrieveSessionWithID:
currentRoute
outputs
portType
defaultCenter
handleMediaServerReset
addObserver:selector:name:object:
removeObserver:
isAudioQueueRunning
waitForAudioQueueStop
signalQueueRunningStateChanged
_audioQueue
_waitForStateChange
_stateChangeCondition
_state
_offlineEngineForContext:error:
_onlineEngineForContext:error:
_engineForContext:error:
cancelExistingSessions
initWithEngine:delegate:
_speechSessionCompleted
startLoggingRequest:
setAvailableLocales:
detectionForString:
detectionForStrings:
useCellular
translateParagraphs:withContext:paragraphResult:completion:
cancelSpeechSession
cancelSpeechSessionWithID:
cleanupOfflineEngine
startInstallRequest:delegate:
_offlineCachedEngine
_onlineCachedEngine
_speakSession
_logger
delegateTranslationDidFinishWithError:
engine
setEngine:
languageDetector
endpointer
_expectFinalLidResult
_sentFinalLidResult
_translationFinishedWithoutError
_languageDetector
_endpointer
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
translate:withContext:completion:
provideFeedback:withContext:
startInstallRequest:
dataUsingEncoding:
setStatistics:
preToPostITN
statistics
proToPostITN
setProToPostITN:
_lowConfidence
_formattedString
_sanitizedFormattedString
_confidence
_preToPostITN
_tokens
_statistics
_proToPostITN
cleanupOnDisconnect
setInvalidationHandler:
stringWithUTF8String:
remoteObjectProxy
logRequestOfType:context:
_clientDelegate
initWithName:
unarchivedObjectOfClasses:fromData:error:
_speechSessionID
initWithFlatbuffData:root:verify:
initWithBytes:length:encoding:
addObjectToBuffer:
initWithBytesNoCopy:length:deallocator:
flatbuffData
initWithFlatbuffData:
initAndVerifyWithFlatbuffData:
initWithFlatbuffData:root:
_storage
_root
numberWithInt:
numberWithFloat:
completionBlock
performSpeechTranslationWithDelegate:requestBuilder:completion:
_ospreySpeechTranslationRequestWithHybridEndpointer:
sendSpeechTranslationStreamingRequest:
initCommon
_ospreyTextToSpeechTranslationRequestWithText:
updateServerTimeout:
_primaryLanguageRecognized
confirmDataIfNeeded
initWithLocaleIdentifier:
_translationForLocale:
_handlePartialRecognitionResponse:
_handleFinalRecognitionResponse:
_handleAudioLimitExceededResponse:
_handleTranslationResponse:
_handleTTSResponse:
_handleFinalBlazarResponse:
_handleServerEndpointFeatures:
streamDidReceiveSpeechTranslationStreamingResponse:
streamFailVerifySpeechTranslationStreamingResponse:
initialOnlineTimeout
setInitialOnlineTimeout:
onlineTimeout
setOnlineTimeout:
endpointTimeout
setEndpointTimeout:
_streamContext
_finalASRResults
_mtResults
_confirmedTranslations
_speechCompressor
_audioPacketCount
_initialOnlineTimeout
_onlineTimeout
_endpointTimeout
_completionBlock
arrayWithCapacity:
arrayWithArray:
nBestResults
_transcriptionWithResult:locale:
recognition
initWithRecognition:wordConfidenceThreshold:
initWithFormattedString:locale:confidence:minConfidence:maxConfidence:
initWithPackage:locale:modelVersion:isFinal:
initWithResult:locale:modelVersion:isFinal:
initEmptyResultWithLocale:isFinal:
bestRecognitionAlternatives
_final
_transcriptions
_bestRecognitionAlternatives
domain
userInfo
markStart
markEnd
_eventName
_endTime
_fields
processString:
languageHypothesesWithMaximum:
availableLocales
_availableLocales
initWithIdentifier:text:spans:
_spans
interpretationIndices
tokenSausage
hasSpaceBefore
lastObject
setHasSpaceAfter:
setBestAlternativeIndex:
setAlternatives:
alternatives
setBins:
bins
_bins
bestAlternativeIndex
_alternatives
_bestAlternativeIndex
_hasSpaceAfter
streamFailVerifyPronGuessStreamingResponse:
streamDidReceivePronGuessStreamingResponse:
bidirectionalStreamingRequestWithMethodName:requestBuilder:streamingResponseHandler:completion:
initWithGRPCStreamingCallContext:
streamFailVerifyBatchRecoverStreamingResponse:
streamDidReceiveBatchRecoverStreamingResponse:
performPronGuessWithDelegate:requestBuilder:completion:
performBatchRecoverWithDelegate:requestBuilder:completion:
streamFailVerifyRecognitionStreamingResponse:
streamDidReceiveRecognitionStreamingResponse:
unaryRequestWithMethodName:requestData:requestBuilder:responseHandler:
performRecognitionWithDelegate:requestBuilder:completion:
performErrorBlamer:requestBuilder:completion:
performItn:requestBuilder:completion:
performTextNormalization:requestBuilder:completion:
performPostItnHammer:requestBuilder:completion:
performKeywordFinder:requestBuilder:completion:
performCorrectionsValidator:requestBuilder:completion:
performGraphemeToPhoneme:requestBuilder:completion:
streamFailVerifyMultiUserStreamingResponse:
streamDidReceiveMultiUserStreamingResponse:
streamFailVerifyMultilingualStreamingResponse:
streamDidReceiveMultilingualStreamingResponse:
streamFailVerifyTextToSpeechRouterStreamingStreamingResponse:
streamDidReceiveTextToSpeechRouterStreamingStreamingResponse:
performMultiUserWithDelegate:requestBuilder:completion:
performMultilingualWithDelegate:requestBuilder:completion:
performTextToSpeechRouterStreamingWithDelegate:requestBuilder:completion:
performLmScorer:requestBuilder:completion:
performCreateLanguageProfile:requestBuilder:completion:
streamFailVerifyTextToSpeechStreamingStreamingResponse:
streamDidReceiveTextToSpeechStreamingStreamingResponse:
performTextToSpeech:requestBuilder:completion:
performTextToSpeechStreamingWithDelegate:requestBuilder:completion:
performShortcutFuzzyMatch:requestBuilder:completion:
performAStarFuzzyMatching:requestBuilder:completion:
streamFailVerifyLanguageDetectionStreamingResponse:
streamDidReceiveLanguageDetectionStreamingResponse:
performLanguageDetectionWithDelegate:requestBuilder:completion:
writeFrame:
finishWriting
sendPronGuessStreamingRequest:
_grpcContext
sendBatchRecoverStreamingRequest:
sendRecognitionStreamingRequest:
sendMultiUserStreamingRequest:
sendMultilingualStreamingRequest:
sendTextToSpeechRouterStreamingStreamingRequest:
sendTextToSpeechStreamingStreamingRequest:
sendLanguageDetectionStreamingRequest:
initWithBundleIdentifier:
specifiersForPolicyOptions:force:
groupSpecifierWithID:
rangeOfString:
valueWithNonretainedObject:
confirmOnDeviceIfNeeded:specifier:
readPreferenceValue:
preferenceSpecifierNamed:target:set:get:detail:cell:edit:
presenterForPrivacySplashWithIdentifier:
setPresentingViewController:
present
rootController
setPreferenceValue:specifier:
setTitle:
setPrompt:
setCancelButton:
setOkButton:
openAppToLanguages:
setConfirmationAction:
showConfirmationViewForSpecifier:useAlert:
defaultWorkspace
openApplicationWithBundleID:
specifiers
showTranslatePrivacy
initWithLocales:useCellular:
initWithLocales:useCellular:progressHandler:
initWithLocales:useCellular:delegate:
setUseCellular:
progressHandler
setProgressHandler:
_locales
_progressHandler
_minConfidence
_maxConfidence
jsonRepresentation
startSpeechLIDRequest:
startSpeechSensesLoggingRequest:
startSafariLatencyLoggingRequest:
startSafariFeedbackRequest:
mtAppService
_mtAppService
isValidJSONObject:
ranges
setRanges:
_ranges
_ospreyDataSharingStatus
_ttsVoiceStringWithLocale:
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v24@0:8@16
v16@0:8
v32@0:8@16@24
v40@0:8@16@24@32
v24@0:8@"_LTLanguageDetectionResult"16
v32@0:8@"_LTServerEndpointerFeatures"16@"NSLocale"24
v24@0:8@"_LTSpeechRecognitionResult"16
v24@0:8@"_LTTranslationResult"16
v24@0:8@"NSError"16
v40@0:8@"NSString"16@"_LTTranslationResult"24@"NSError"32
v32@0:8@"NSArray"16@"NSError"24
@"NSMutableDictionary"
@"_LTTranslationResult"
@"NSError"
@"<_LTSpeechTranslationDelegate>"
v40@0:8@16@24q32
@"NSObject<OS_dispatch_queue>"
@"NSOrderedSet"
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@32@0:8@16@24
@"NSLocale"
@"NSCountedSet"
@48@0:8@16@24@32@40
@40@0:8@16@24@32
@"MLModel"
@"NSString"
@"NSMutableArray"
@"NSNumber"
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
v24@0:8@"_LTClientConnection"16
@"NSXPCListener"
@"_LTTranslationServer"
q16@0:8
v24@0:8q16
v20@0:8B16
I16@0:8
v20@0:8I16
@"_LTLocalePair"
@"NSURL"
@"NSArray"
@40@0:8@16B24@28B36
@"NSDictionary"
v36@0:8@16@24B32
v36@0:8@"NSString"16@"NSDictionary"24B32
d16@0:8
@"_LTTranslationContext"
@"CSLanguageDetector"
@"_LTLanguageDetectionResult"
@"_LTLanguageDetectorFeatureCombinationModel"
v24@0:8Q16
v24@0:8d16
@40@0:8q16@24@32
@?16@0:8
v24@0:8@?16
@"_LTTranslationParagraph"
@"FTMutableBatchTranslationRequest_Paragraph"
v24@0:8@"FTBatchTranslationStreamingResponse"16
@"FTMutableBatchTranslationRequest"
@"LTSchemaBatchTranslationEvent"
@"NSDate"
v28@0:8B16@20
v40@0:8@16@24@?32
v48@0:8@16@24@?32@?40
B24@0:8@"_LTLocalePair"16
v28@0:8B16@"_LTTranslationContext"20
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v48@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSString"@"_LTTranslationResult"@"NSError">32@?<v@?@"NSError">40
v32@0:8@"_LTTranslationContext"16@"<_LTSpeechTranslationDelegate>"24
v24@0:8@"NSData"16
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTAudioData"@"NSError">32
v40@0:8@"_LTTranslationContext"16@"NSString"24@"<_LTSpeechTranslationDelegate>"32
@24@0:8q16
v48@0:8@16q24@32@?40
@"NSOperationQueue"
@"FTMtService"
@"FTBlazarService"
@"_LTOspreySpeechTranslationSession"
@"_LTBatchTranslationResponseHandler"
@"NSObject<OS_dispatch_source>"
@"AFSettingsConnection"
@"_LTTextToSpeechCache"
@64@0:8{AudioStreamBasicDescription=dIIIIIIII}16@56
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@"NSData"
v36@0:8^f16Q24f32
v24@0:8@"EARClientSilenceFeatures"16
B40@0:8@16@24@32
@"_LTHybridEndpointerAssetInfo"
@"_EAREndpointer"
@"_LTServerEndpointerFeatures"
@"EARCaesuraSilencePosteriorGenerator"
@"VSVoiceAsset"
@"MAProgressNotification"
v36@0:8@16B24@?28
@"_LTOfflineAssetManager"
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
@"<_LTTranslationEngine>"
@"_LTPlaybackService"
@64@0:8@16q24@32@40@48@56
@"MAAsset"
v32@0:8@16@?24
@56@0:8@16@24@32@40@48
v36@0:8B16@20@?28
q28@0:8@16B24
@24@0:8^{_NSZone=}16
v28@0:8^{opaqueCMSampleBuffer=}16B24
@"AVAudioConverter"
@"<_LTTranslationService>"
v44@0:8@16B24@?28@?36
v48@0:8@16B24B28@?32@?40
v28@0:8B16@?20
@32@0:8@16^@24
@56@0:8@16@24@32@40^@48
@32@0:8q16^@24
@24@0:8^@16
i16@0:8
v20@0:8i16
f16@0:8
v20@0:8f16
@36@0:8@16q24B32
@28@0:8@16B24
v48@0:8@16@24@32@?40
v56@0:8@16@24@32@?40@?48
@"_LTSpeechTranslationAssetInfo"
@"_LTMultilingualSpeechRecognizer"
@"_LTOfflineSpeechSynthesizer"
@"EMTTranslator"
@"NSObject<OS_dispatch_group>"
v52@0:8@16@24B32@36@44
v48@0:8@16{_NSRange=QQ}24@40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v36@0:8@16B24@28
v44@0:8@16B24@28@36
v40@0:8@16{_NSRange=QQ}24
v32@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSArray"32
v52@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v48@0:8@"VSSpeechSynthesizer"16{_NSRange=QQ}24@"VSSpeechRequest"40
v48@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSError"32
v36@0:8@"VSSpeechSynthesizer"16B24@"NSError"28
v24@0:8@"VSSpeechSynthesizer"16
v44@0:8@"VSSpeechSynthesizer"16B24@"NSString"28@"NSError"36
v44@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24B32@"NSError"36
v40@0:8@"VSSpeechSynthesizer"16{_NSRange=QQ}24
@24@0:8@?16
@"_LTSafariLatencyLoggingRequest"
@"_LTTranslator"
q24@0:8@16
@36@0:8@16@24B32
@"<_LTSpeechCompressorDelegate>"
^{OpaqueAudioConverter=}
@"NSMutableData"
@40@0:8@16{_NSRange=QQ}24
@"_LTSpeechTranslationResultsBuffer"
v32@0:8@?16@?24
v40@0:8@?16@24@?32
v32@0:8q16@?24
v40@0:8q16@24@?32
v40@0:8@16@?24@?32
@"NSXPCConnection"
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"_EARSpeechRecognitionResultPackage"
@60@0:8I16{AudioStreamBasicDescription=dIIIIIIII}20
@40@0:8@16q24@32
^{OpaqueAudioQueue=}
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
{_opaque_pthread_cond_t="__sig"q"__opaque"[40c]}
@"_LTServerSpeechSession"
@"_LTServerSpeakSession"
@"_LTLoggingRequestHandler"
@"NSUUID"
@"_LTLanguageDetector"
@"_LTHybridEndpointer"
v32@0:8@"_LTTranslationContext"16@?<v@?@"NSError">24
v40@0:8@"_LTTranslationParagraph"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v40@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSError">32
v32@0:8@"_LTTranslationFeedback"16@"_LTTaskContext"24
v32@0:8@"_LTTranslationContext"16@"NSString"24
v24@0:8@"_LTTranslationContext"16
v32@0:8@"NSString"16@?<v@?@"_LTLanguageDetectionResult">24
v32@0:8@"NSArray"16@?<v@?@"_LTTextLanguageDetectionResult">24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"NSError">32
v24@0:8@?<v@?@"NSArray">16
v36@0:8@"_LTLocalePair"16B24@?<v@?@"NSError">28
v24@0:8@?<v@?@"NSError">16
v24@0:8@?<v@?q@"NSError">16
v24@0:8@"_LTInstallRequest"16
v32@0:8q16@?<v@?@"NSArray">24
v40@0:8q16@"NSString"24@?<v@?B>32
v32@0:8@"NSLocale"16@?<v@?@"NSArray">24
v40@0:8@"NSLocale"16@"NSLocale"24@?<v@?@"NSDictionary">32
@60@0:8@16@24d32B40@44@52
@"_LTTranslationStatistics"
@"<_LTClientConnectionDelegate>"
@"NSData"16@0:8
@32@0:8@16r^{UserLanguageProfile=[1C]}24
@36@0:8@16r^{UserLanguageProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserLanguageProfile>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UserLanguageProfile=[1C]}
@32@0:8@16r^{UserAcousticProfile=[1C]}24
@36@0:8@16r^{UserAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserAcousticProfile>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UserAcousticProfile=[1C]}
@32@0:8@16r^{RecognitionToken=[1C]}24
@36@0:8@16r^{RecognitionToken=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionToken=[1C]}
@32@0:8@16r^{RecognitionPhraseTokens=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokens=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokens>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionPhraseTokens=[1C]}
@32@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokensAlternatives>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionPhraseTokensAlternatives=[1C]}
@32@0:8@16r^{RecognitionSausage=[1C]}24
@36@0:8@16r^{RecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionSausage>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionSausage=[1C]}
@32@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24
@36@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::SetAlternateRecognitionSausage>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SetAlternateRecognitionSausage=[1C]}
@32@0:8@16r^{RecognitionChoice=[1C]}24
@36@0:8@16r^{RecognitionChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionChoice>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionChoice=[1C]}
@32@0:8@16r^{RepeatedItnAlignment=[1C]}24
@36@0:8@16r^{RepeatedItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedItnAlignment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RepeatedItnAlignment=[1C]}
@32@0:8@16r^{ChoiceAlignment=[1C]}24
@36@0:8@16r^{ChoiceAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ChoiceAlignment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ChoiceAlignment=[1C]}
@32@0:8@16r^{RecognitionResult=[1C]}24
@36@0:8@16r^{RecognitionResult=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionResult>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionResult=[1C]}
@32@0:8@16r^{RequestStatsResponse=[1C]}24
@36@0:8@16r^{RequestStatsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RequestStatsResponse=[1C]}
@32@0:8@16r^{BoolStat=[1C]}24
@36@0:8@16r^{BoolStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::BoolStat>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BoolStat=[1C]}
@32@0:8@16r^{Int32Stat=[1C]}24
@36@0:8@16r^{Int32Stat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::Int32Stat>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Int32Stat=[1C]}
@32@0:8@16r^{DoubleStat=[1C]}24
@36@0:8@16r^{DoubleStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::DoubleStat>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{DoubleStat=[1C]}
@32@0:8@16r^{ItnAlignment=[1C]}24
@36@0:8@16r^{ItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnAlignment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ItnAlignment=[1C]}
@32@0:8@16r^{AcousticFeature=[1C]}24
@36@0:8@16r^{AcousticFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::AcousticFeature>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AcousticFeature=[1C]}
@32@0:8@16r^{AudioAnalytics=[1C]}24
@36@0:8@16r^{AudioAnalytics=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AudioAnalytics=[1C]}
@32@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24
@36@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::SpeechRecognitionFeaturesEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechRecognitionFeaturesEntry=[1C]}
@32@0:8@16r^{AcousticFeaturesEntry=[1C]}24
@36@0:8@16r^{AcousticFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::AcousticFeaturesEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AcousticFeaturesEntry=[1C]}
@32@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalSpeechRecognitionResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{FinalSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialSpeechRecognitionResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PartialSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{StartSpeechRequest=[1C]}24
@36@0:8@16r^{StartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartSpeechRequest=[1C]}
@32@0:8@16r^{UserParameters=[1C]}24
@36@0:8@16r^{UserParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::UserParameters>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UserParameters=[1C]}
@32@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24
@36@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::MultiUserStartSpeechRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MultiUserStartSpeechRequest=[1C]}
@32@0:8@16r^{UpdateAudioInfo=[1C]}24
@36@0:8@16r^{UpdateAudioInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdateAudioInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UpdateAudioInfo=[1C]}
@32@0:8@16r^{ContextWithPronHints=[1C]}24
@36@0:8@16r^{ContextWithPronHints=[1C]}24B32
{Offset<siri::speech::schema_fb::ContextWithPronHints>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ContextWithPronHints=[1C]}
@32@0:8@16r^{SetSpeechContext=[1C]}24
@36@0:8@16r^{SetSpeechContext=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechContext>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SetSpeechContext=[1C]}
@32@0:8@16r^{SetSpeechProfile=[1C]}24
@36@0:8@16r^{SetSpeechProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechProfile>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SetSpeechProfile=[1C]}
@32@0:8@16r^{SetEndpointerState=[1C]}24
@36@0:8@16r^{SetEndpointerState=[1C]}24B32
{Offset<siri::speech::schema_fb::SetEndpointerState>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SetEndpointerState=[1C]}
@32@0:8@16r^{AudioPacket=[1C]}24
@36@0:8@16r^{AudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioPacket>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AudioPacket=[1C]}
@32@0:8@16r^{FinishAudio=[1C]}24
@36@0:8@16r^{FinishAudio=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{FinishAudio=[1C]}
@32@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24
@36@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio_::ServerFeatureLatencyDistributionEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ServerFeatureLatencyDistributionEntry=[1C]}
@32@0:8@16r^{UpdatedAcousticProfile=[1C]}24
@36@0:8@16r^{UpdatedAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdatedAcousticProfile>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UpdatedAcousticProfile=[1C]}
@32@0:8@16r^{Word=[1C]}24
@36@0:8@16r^{Word=[1C]}24B32
{Offset<siri::speech::schema_fb::Word>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Word=[1C]}
@32@0:8@16r^{UserDataEntity=[1C]}24
@36@0:8@16r^{UserDataEntity=[1C]}24B32
{Offset<siri::speech::schema_fb::UserDataEntity>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UserDataEntity=[1C]}
@32@0:8@16r^{CategoryData=[1C]}24
@36@0:8@16r^{CategoryData=[1C]}24B32
{Offset<siri::speech::schema_fb::CategoryData>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CategoryData=[1C]}
@32@0:8@16r^{CreateLanguageProfileRequest=[1C]}24
@36@0:8@16r^{CreateLanguageProfileRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CreateLanguageProfileRequest=[1C]}
@32@0:8@16r^{CreateLanguageProfileResponse=[1C]}24
@36@0:8@16r^{CreateLanguageProfileResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CreateLanguageProfileResponse=[1C]}
@32@0:8@16r^{StartPronGuessRequest=[1C]}24
@36@0:8@16r^{StartPronGuessRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartPronGuessRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartPronGuessRequest=[1C]}
@32@0:8@16r^{CancelRequest=[1C]}24
@36@0:8@16r^{CancelRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CancelRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CancelRequest=[1C]}
@32@0:8@16r^{Pronunciation=[1C]}24
@36@0:8@16r^{Pronunciation=[1C]}24B32
{Offset<siri::speech::schema_fb::Pronunciation>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Pronunciation=[1C]}
@32@0:8@16r^{VocToken=[1C]}24
@36@0:8@16r^{VocToken=[1C]}24B32
{Offset<siri::speech::schema_fb::VocToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{VocToken=[1C]}
@32@0:8@16r^{PronGuessResponse=[1C]}24
@36@0:8@16r^{PronGuessResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PronGuessResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PronGuessResponse=[1C]}
@32@0:8@16r^{RecoverPronsRequest=[1C]}24
@36@0:8@16r^{RecoverPronsRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecoverPronsRequest=[1C]}
@32@0:8@16r^{RecoverPronsResponse=[1C]}24
@36@0:8@16r^{RecoverPronsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecoverPronsResponse=[1C]}
@32@0:8@16r^{StartBatchRecoverRequest=[1C]}24
@36@0:8@16r^{StartBatchRecoverRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartBatchRecoverRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartBatchRecoverRequest=[1C]}
@32@0:8@16r^{BatchRecoverFinalResponse=[1C]}24
@36@0:8@16r^{BatchRecoverFinalResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchRecoverFinalResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchRecoverFinalResponse=[1C]}
@32@0:8@16r^{ItnRequest=[1C]}24
@36@0:8@16r^{ItnRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ItnRequest=[1C]}
@32@0:8@16r^{ItnResponse=[1C]}24
@36@0:8@16r^{ItnResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ItnResponse=[1C]}
@32@0:8@16r^{PostItnHammerRequest=[1C]}24
@36@0:8@16r^{PostItnHammerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PostItnHammerRequest=[1C]}
@32@0:8@16r^{PostItnHammerResponse=[1C]}24
@36@0:8@16r^{PostItnHammerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PostItnHammerResponse=[1C]}
@32@0:8@16r^{TextNormalizationRequest=[1C]}24
@36@0:8@16r^{TextNormalizationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextNormalizationRequest=[1C]}
@32@0:8@16r^{NormalizedTokenVariant=[1C]}24
@36@0:8@16r^{NormalizedTokenVariant=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedTokenVariant>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{NormalizedTokenVariant=[1C]}
@32@0:8@16r^{NormalizedToken=[1C]}24
@36@0:8@16r^{NormalizedToken=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{NormalizedToken=[1C]}
@32@0:8@16r^{TextNormalizationResponse=[1C]}24
@36@0:8@16r^{TextNormalizationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextNormalizationResponse=[1C]}
@32@0:8@16r^{PronChoice=[1C]}24
@36@0:8@16r^{PronChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::PronChoice>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PronChoice=[1C]}
@32@0:8@16r^{SanitizedPronToken=[1C]}24
@36@0:8@16r^{SanitizedPronToken=[1C]}24B32
{Offset<siri::speech::schema_fb::SanitizedPronToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SanitizedPronToken=[1C]}
@32@0:8@16r^{TokenProns=[1C]}24
@36@0:8@16r^{TokenProns=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TokenProns=[1C]}
@32@0:8@16r^{SanitizedSequence=[1C]}24
@36@0:8@16r^{SanitizedSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns_::SanitizedSequence>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SanitizedSequence=[1C]}
@32@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{GraphemeToPhonemeRequest=[1C]}
@32@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{GraphemeToPhonemeResponse=[1C]}
@32@0:8@16r^{Alignment=[1C]}24
@36@0:8@16r^{Alignment=[1C]}24B32
{Offset<siri::speech::schema_fb::Alignment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Alignment=[1C]}
@32@0:8@16r^{Span=[1C]}24
@36@0:8@16r^{Span=[1C]}24B32
{Offset<siri::speech::schema_fb::Span>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Span=[1C]}
@32@0:8@16r^{RepeatedSpan=[1C]}24
@36@0:8@16r^{RepeatedSpan=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedSpan>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RepeatedSpan=[1C]}
@32@0:8@16r^{SpeechTranslationInfo=[1C]}24
@36@0:8@16r^{SpeechTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationInfo=[1C]}
@32@0:8@16r^{SiriTranslationInfo=[1C]}24
@36@0:8@16r^{SiriTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriTranslationInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SiriTranslationInfo=[1C]}
@32@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24
@36@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriPayloadTranslationInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SiriPayloadTranslationInfo=[1C]}
@32@0:8@16r^{WebTranslationInfo=[1C]}24
@36@0:8@16r^{WebTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WebTranslationInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{WebTranslationInfo=[1C]}
@32@0:8@16r^{TranslationRequest=[1C]}24
@36@0:8@16r^{TranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TranslationRequest=[1C]}
@32@0:8@16r^{TranslationResponse=[1C]}24
@36@0:8@16r^{TranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TranslationResponse=[1C]}
@32@0:8@16r^{TranslationToken=[1C]}24
@36@0:8@16r^{TranslationToken=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TranslationToken=[1C]}
@32@0:8@16r^{TranslationPhrase=[1C]}24
@36@0:8@16r^{TranslationPhrase=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationPhrase>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TranslationPhrase=[1C]}
@32@0:8@16r^{EndPointLikelihood=[1C]}24
@36@0:8@16r^{EndPointLikelihood=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointLikelihood>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{EndPointLikelihood=[1C]}
@32@0:8@16r^{EndPointCandidate=[1C]}24
@36@0:8@16r^{EndPointCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointCandidate>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{EndPointCandidate=[1C]}
@32@0:8@16r^{SetRequestOrigin=[1C]}24
@36@0:8@16r^{SetRequestOrigin=[1C]}24B32
{Offset<siri::speech::schema_fb::SetRequestOrigin>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SetRequestOrigin=[1C]}
@32@0:8@16r^{RecognitionProgress=[1C]}24
@36@0:8@16r^{RecognitionProgress=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionProgress>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionProgress=[1C]}
@32@0:8@16r^{ResetServerEndpointer=[1C]}24
@36@0:8@16r^{ResetServerEndpointer=[1C]}24B32
{Offset<siri::speech::schema_fb::ResetServerEndpointer>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ResetServerEndpointer=[1C]}
@32@0:8@16r^{LatnnMitigatorResult=[1C]}24
@36@0:8@16r^{LatnnMitigatorResult=[1C]}24B32
{Offset<siri::speech::schema_fb::LatnnMitigatorResult>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LatnnMitigatorResult=[1C]}
@32@0:8@16r^{RecognitionCandidate=[1C]}24
@36@0:8@16r^{RecognitionCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionCandidate>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionCandidate=[1C]}
@32@0:8@16r^{CheckForSpeechRequest=[1C]}24
@36@0:8@16r^{CheckForSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CheckForSpeechRequest=[1C]}
@32@0:8@16r^{CheckForSpeechResponse=[1C]}24
@36@0:8@16r^{CheckForSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CheckForSpeechResponse=[1C]}
@32@0:8@16r^{ErrorBlamerRequest=[1C]}24
@36@0:8@16r^{ErrorBlamerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ErrorBlamerRequest=[1C]}
@32@0:8@16r^{ErrorBlamerResponse=[1C]}24
@36@0:8@16r^{ErrorBlamerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ErrorBlamerResponse=[1C]}
@32@0:8@16r^{LmScorerToken=[1C]}24
@36@0:8@16r^{LmScorerToken=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LmScorerToken=[1C]}
@32@0:8@16r^{LmScorerRequest=[1C]}24
@36@0:8@16r^{LmScorerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LmScorerRequest=[1C]}
@32@0:8@16r^{LmScorerResponse=[1C]}24
@36@0:8@16r^{LmScorerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LmScorerResponse=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingConfig=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingConfig>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AStarFuzzyMatchingConfig=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingResult=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingResult=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingResult>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AStarFuzzyMatchingResult=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingRequest=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AStarFuzzyMatchingRequest=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingResponse=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AStarFuzzyMatchingResponse=[1C]}
@32@0:8@16r^{Keyword=[1C]}24
@36@0:8@16r^{Keyword=[1C]}24B32
{Offset<siri::speech::schema_fb::Keyword>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Keyword=[1C]}
@32@0:8@16r^{KeywordFinderRequest=[1C]}24
@36@0:8@16r^{KeywordFinderRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{KeywordFinderRequest=[1C]}
@32@0:8@16r^{KeywordFinderResponse=[1C]}24
@36@0:8@16r^{KeywordFinderResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{KeywordFinderResponse=[1C]}
@32@0:8@16r^{ServerEndpointFeatures=[1C]}24
@36@0:8@16r^{ServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::ServerEndpointFeatures>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ServerEndpointFeatures=[1C]}
@32@0:8@16r^{CorrectionsValidatorRequest=[1C]}24
@36@0:8@16r^{CorrectionsValidatorRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CorrectionsValidatorRequest=[1C]}
@32@0:8@16r^{CorrectionsAlignment=[1C]}24
@36@0:8@16r^{CorrectionsAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsAlignment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CorrectionsAlignment=[1C]}
@32@0:8@16r^{CorrectionsValidatorResponse=[1C]}24
@36@0:8@16r^{CorrectionsValidatorResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CorrectionsValidatorResponse=[1C]}
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext_::ContextInfoEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{TTSWordPhonemes=[1C]}24
@36@0:8@16r^{TTSWordPhonemes=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSWordPhonemes>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TTSWordPhonemes=[1C]}
@32@0:8@16r^{TTSPhonemeSequence=[1C]}24
@36@0:8@16r^{TTSPhonemeSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPhonemeSequence>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TTSPhonemeSequence=[1C]}
@32@0:8@16r^{TTSPrompts=[1C]}24
@36@0:8@16r^{TTSPrompts=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSPrompts>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TTSPrompts=[1C]}
@32@0:8@16r^{TTSReplacement=[1C]}24
@36@0:8@16r^{TTSReplacement=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSReplacement>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TTSReplacement=[1C]}
@32@0:8@16r^{TTSNormalizedText=[1C]}24
@36@0:8@16r^{TTSNormalizedText=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSNormalizedText>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TTSNormalizedText=[1C]}
@32@0:8@16r^{TextToSpeechFeature=[1C]}24
@36@0:8@16r^{TextToSpeechFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechFeature>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechFeature=[1C]}
@32@0:8@16r^{TextToSpeechRequestDebug=[1C]}24
@36@0:8@16r^{TextToSpeechRequestDebug=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestDebug>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRequestDebug=[1C]}
@32@0:8@16r^{TextToSpeechVoiceResource=[1C]}24
@36@0:8@16r^{TextToSpeechVoiceResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoiceResource>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechVoiceResource=[1C]}
@32@0:8@16r^{TextToSpeechUserProfile=[1C]}24
@36@0:8@16r^{TextToSpeechUserProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechUserProfile>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechUserProfile=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRequest=[1C]}
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{TextToSpeechResponse=[1C]}24
@36@0:8@16r^{TextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechResponse=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24
@36@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheMetaInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechCacheMetaInfo=[1C]}
@32@0:8@16r^{TextToSpeechCacheObject=[1C]}24
@36@0:8@16r^{TextToSpeechCacheObject=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheObject>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechCacheObject=[1C]}
@32@0:8@16r^{TextToSpeechCacheContainer=[1C]}24
@36@0:8@16r^{TextToSpeechCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheContainer>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechCacheContainer=[1C]}
@32@0:8@16r^{QssAckResponse=[1C]}24
@36@0:8@16r^{QssAckResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::QssAckResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{QssAckResponse=[1C]}
@32@0:8@16r^{ClientSetupInfo=[1C]}24
@36@0:8@16r^{ClientSetupInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::ClientSetupInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ClientSetupInfo=[1C]}
@32@0:8@16r^{AudioLimitExceeded=[1C]}24
@36@0:8@16r^{AudioLimitExceeded=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioLimitExceeded>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AudioLimitExceeded=[1C]}
@32@0:8@16r^{AudioFrame=[1C]}24
@36@0:8@16r^{AudioFrame=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioFrame>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AudioFrame=[1C]}
@32@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24
@36@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationAudioPacket>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationAudioPacket=[1C]}
@32@0:8@16r^{TranslationLocalePair=[1C]}24
@36@0:8@16r^{TranslationLocalePair=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationLocalePair>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TranslationLocalePair=[1C]}
@32@0:8@16r^{StartSpeechTranslationRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartSpeechTranslationRequest=[1C]}
@32@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationLoggingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartSpeechTranslationLoggingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationPartialRecognitionResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationPartialRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationFinalRecognitionResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationFinalRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationMtResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationMtResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationMtResponse=[1C]}
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse_::TranslationPhrase>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
@32@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationTextToSpeechResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationTextToSpeechResponse=[1C]}
@32@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24
@36@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationServerEndpointFeatures>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationServerEndpointFeatures=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ShortcutFuzzyMatchRequest=[1C]}
@32@0:8@16r^{StringTokenPair=[1C]}24
@36@0:8@16r^{StringTokenPair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest_::StringTokenPair>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StringTokenPair=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ShortcutFuzzyMatchResponse=[1C]}
@32@0:8@16r^{ShortcutScorePair=[1C]}24
@36@0:8@16r^{ShortcutScorePair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse_::ShortcutScorePair>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ShortcutScorePair=[1C]}
@32@0:8@16r^{LanguageParameters=[1C]}24
@36@0:8@16r^{LanguageParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageParameters>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageParameters=[1C]}
@32@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24
@36@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartMultilingualSpeechRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartMultilingualSpeechRequest=[1C]}
@32@0:8@16r^{LanguageDetectionPrediction=[1C]}24
@36@0:8@16r^{LanguageDetectionPrediction=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionPrediction>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageDetectionPrediction=[1C]}
@32@0:8@16r^{LanguageDetected=[1C]}24
@36@0:8@16r^{LanguageDetected=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetected>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageDetected=[1C]}
@32@0:8@16r^{FinalBlazarResponse=[1C]}24
@36@0:8@16r^{FinalBlazarResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalBlazarResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{FinalBlazarResponse=[1C]}
@32@0:8@16r^{BatchTranslationRequest=[1C]}24
@36@0:8@16r^{BatchTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchTranslationRequest=[1C]}
@32@0:8@16r^{Paragraph=[1C]}24
@36@0:8@16r^{Paragraph=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest_::Paragraph>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Paragraph=[1C]}
@32@0:8@16r^{BatchTranslationResponse=[1C]}24
@36@0:8@16r^{BatchTranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchTranslationResponse=[1C]}
@32@0:8@16r^{BatchTranslationCacheContainer=[1C]}24
@36@0:8@16r^{BatchTranslationCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationCacheContainer>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchTranslationCacheContainer=[1C]}
@32@0:8@16r^{StartLanguageDetectionRequest=[1C]}24
@36@0:8@16r^{StartLanguageDetectionRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartLanguageDetectionRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartLanguageDetectionRequest=[1C]}
@32@0:8@16r^{LanguageDetectionResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageDetectionResponse=[1C]}
@32@0:8@16r^{PronGuessStreamingRequest=[1C]}24
@36@0:8@16r^{PronGuessStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PronGuessStreamingRequest=[1C]}
@32@0:8@16r^{PronGuessStreamingResponse=[1C]}24
@36@0:8@16r^{PronGuessStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PronGuessStreamingResponse=[1C]}
@32@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchRecoverStreamingRequest=[1C]}
@32@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchRecoverStreamingResponse=[1C]}
@32@0:8@16r^{RecognitionStreamingRequest=[1C]}24
@36@0:8@16r^{RecognitionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionStreamingRequest=[1C]}
@32@0:8@16r^{RecognitionStreamingResponse=[1C]}24
@36@0:8@16r^{RecognitionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionStreamingResponse=[1C]}
@32@0:8@16r^{MultiUserStreamingRequest=[1C]}24
@36@0:8@16r^{MultiUserStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MultiUserStreamingRequest=[1C]}
@32@0:8@16r^{MultiUserStreamingResponse=[1C]}24
@36@0:8@16r^{MultiUserStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MultiUserStreamingResponse=[1C]}
@32@0:8@16r^{MultilingualStreamingRequest=[1C]}24
@36@0:8@16r^{MultilingualStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MultilingualStreamingRequest=[1C]}
@32@0:8@16r^{MultilingualStreamingResponse=[1C]}24
@36@0:8@16r^{MultilingualStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MultilingualStreamingResponse=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationStreamingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationStreamingResponse=[1C]}
@32@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchTranslationStreamingRequest=[1C]}
@32@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchTranslationStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechStreamingStreamingResponse=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageDetectionStreamingRequest=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageDetectionStreamingResponse=[1C]}
v24@0:8@"FTSpeechTranslationStreamingResponse"16
v32@0:8@16Q24
v32@0:8@"NSArray"16Q24
@"FTSpeechTranslationStreamingContext"
@"_LTSpeechCompressor"
@44@0:8@16@24@32B40
@"_LTSpeechRecognitionSausage"
v28@0:8@16B24
@"NLLanguageRecognizer"
@32@0:8@16q24
@40@0:8@16@?24@?32
@"<OspreyClientStreamingContext>"
@36@0:8@16B24@?28
@36@0:8@16B24@28
@56@0:8@16@24d32d40d48
@20@0:8B16
@32@0:8@16d24
