error setting SRC quality: %@
%s: error %@ %s level metering
%s: error converting disambiguation context
%s: allowing recognition start
%s: recognition requested when busy
%s: releasing active client to begin
%s: client requested cancellation of active recognition
%s: client requested cancellation of queued recognition
cancelling recognition
released from holding.. beginning now.
Running with background thread priority
couldn't create instance for client port - cancelling
couldn't open audio input file for reading
%s: sample rate change (now %d Hz); invalidating queue
%s: no valid models could be created
%s: client died - cancelling recognition
couldn't add listener for queue running state (%@)
couldn't create audio queue
setting recognition thread priority to %d
%s: sleeping for %g s
%s: finished starting queue in %g s
couldn't start audio queue for recognition (%@)
%s: starting recognition
%s: starting recognition from file
couldn't get file format description.
Recognition results:
--------------------
%s: error posting client completion notification
%s: error posting client error notification
%s: posted %s to client
caching model <%s> class <%s> ...
no valid cache found; recaching everything.
cache for model <%s> is valid; skipping recache request.
... finished caching model in %g s with error %d <%s> class <%s>
cache for model <%s> is valid; skipping recache.
recache for model <%s> done in %g s
error caching model <%s>
%s: couldn't write keyword index for cache
%s: couldn't create manifest for cache
%s: error setting info dict on temp cache
%s: couldn't move temp cache into place... deleting
%s: couldn't save cache; no base dir exists or couldn't create temp cache
error writing model configuration cache Info.plist:
beginning plugin registry rebuild...
finished.
%s: error examining plugins directory (%ld)
%s: error writing plugin registry cache:
data provider does not implement value method
%s: plugin class does not conform to appropriate protocol
%s: plugin class not found
%s: error loading plugin:
err %d copying manifest
#AudioSession session interrupted
#AudioSession mediaserverd died
#AudioSession : Setting up audio session
#AudioSession error setting HW sample rate: %ld
#AudioSession : category = %d
#AudioSession error %ld setting audio category
#AudioSession error %ld setting bluetooth allowability
#AudioSession : Bluetooth %sabled
#AudioSession active count went negative for input!
#AudioSession active count went negative for output!
#AudioSession active count went negative!
#AudioSession : activity %d --> %s
#AudioSession : Active --> FALSE
#AudioSession : Active --> TRUE
#AudioSession error %ld activating or deactivating session for activity %ld
#AudioSession could not stop queue (%@)
voiced starting up...
Migration failed, %@
Cannot register CacheDelete service.
Receive notification %s
com.apple.MobileAsset.VoiceServices.VoiceResources.ma.new-asset-installed: checking for a voice update
Perform force asset update
xpc_activity state must be RUN, got: %ld
running xpc_activity
Error cleanUnusedAssets in scheduled background task: %@
xpc activity com.apple.voiced, failed to set state to done.
running com.apple.voiced.weekly
xpc activity com.apple.voiced.weekly, failed to set state to done.
running com.apple.voiced.neural-compiling
Neural voice is already compiled: '%@'
Triggered compiling neural voice '%@'
Neural voice finished compiling '%@'
xpc activity com.apple.voiced.neuralCompiling, failed to set state to done.
XPC connection invalidated, identifier: %{public}@
_VSAudioQueueSetLevelMeteringPropertyValue
enabling
disabling
_default
server_VSRecognitionPrepareOrBegin
server_VSRecognitionBegin
server_VSRecognitionCancel
com.apple.voiceservices.recognition
Error %d at %s:%d
/Library/Caches/com.apple.xbs/Sources/VoiceServicesDaemons_Sim/VoiceServices-632.3/Daemon/VSRecognitionServer.c
_CreateEngineIfNecessary
_InitializeEngine
_RecognitionClientInvalidationCallback
Error %d at %s:%d (%s)
couldn't start recognition
recording.wav
_BeginRecognition
_SendChoices
VSClientPostNotification
0x%x
VSLocaleIdentifier
VSVersion
VSPluginVersions
KeywordIndex.plist
%@%@
.vscache
Info.plist
temp.vscache.XXXXX
_SaveEngineToCache
VSEngineIdentifier
temp.vscache.
PluginPath
PluginRegistry.plist
_CreateRegistryAndSaveToCache
modelid-desc
pluginid-vers
pluginpath-moddate
/System/Library/VoiceServices/PlugIns
Library
Caches
VoiceServices
VSRecognitionVersion
VSRecognitionModels
VSRecognitionModelIdentifier
VSRecognitionModelFileName
VSRecognitionModelIsTopLevel
VSRecognitionModelWeight
VSRecognitionModelIsCancelModel
VSRecognitionModelRequiredCapabilities
VSRecognitionModelDataProvider
VSRecognitionResultValidator
VSRecognitionResultHandler
vsplugin
lang
VSRecognitionModelDefinition
.plist
VSPlugin
<VSPlugin %p: %@>
VSRecognitionClasses
VSRecognitionSequences
VSRecognitionKeywords
VSRecognitionClassIdentifier
VSRecognitionClassRequiredCapabilities
VSRecognitionClassElements
VSRecognitionClassElementValues
VSRecognitionClassSequences
VSRecognitionClassType
VSRecognitionClassWeight
VSRecognitionClassContainsKeywords
VSRecognitionClassTypeCommand
VSRecognitionClassTypePersonName
VSRecognitionClassTypeStreetName
VSRecognitionClassTypeCityName
VSRecognitionClassTypeSongTitle
VSRecognitionClassTypeArtistName
VSRecognitionClassTypeAlbumName
VSRecognitionSequenceElements
VSRecognitionSequenceDisambiguationTag
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
_InstantiatePluginClassWithRecognitionModelKeyedName
_LoadPluginIfNecessary
isvalid
VSRecognitionClassDataProvider
dflt%ld
VSRecognitionModel
VSRecognitionClass
VSRecognitionSequence
<%@>
Manifest.sqlitedb
SELECT model_id, validity FROM Model;
 WHERE model_id = ?;
INSERT OR REPLACE INTO ValueTranslation (model_id, class_id, original_value, translated_value) VALUES (?, ?, ?, ?);
SELECT original_value FROM ValueTranslation WHERE model_id = ? AND class_id = ? AND translated_value = ?;
DELETE FROM ValueTranslation
 model_id = ?
 class_id = ?
 WHERE
 AND
VSRecognitionConfigurationCacheManifest
Model
model_id
validity
last_update
SELECT %s FROM %s WHERE ROWID = ?
UPDATE %s SET %s = ? WHERE ROWID = ?
ValueTranslation
CREATE TABLE Model (ROWID INTEGER PRIMARY KEY AUTOINCREMENT, model_id TEXT, validity TEXT, last_update INTEGER, UNIQUE(model_id));
CREATE INDEX ModelIdIndex on Model(model_id);
CREATE TABLE ValueTranslation (ROWID INTEGER PRIMARY KEY AUTOINCREMENT, model_id TEXT, class_id TEXT, original_value TEXT, translated_value TEXT, UNIQUE(model_id, class_id, original_value));
CREATE INDEX ValueTranslationModelIdClassIdIndex on ValueTranslation(model_id, class_id, translated_value);
v8@?0
VSAudioSessionQueue
ACTIVE
INACTIVE
LatencyFudgeFactor
com.apple.voiceservices.notification.voice-update
com.apple.voiceservices.trigger.asset-force-update
v16@?0@"NSError"8
com.apple.notifyd.matching
v16@?0@"NSObject<OS_xpc_object>"8
com.apple.MobileAsset.VoiceServicesVocalizerVoice.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceServices.GryphonVoice.ma.new-asset-installed
com.apple.MobileAsset.VoiceServicesVocalizerVoice.ma.new-asset-installed
com.apple.MobileAsset.VoiceServices.VoiceResources.ma.new-asset-installed
LastAttemptedDownloadTimeForNewResource
com.apple.voiced
KeepAliveManager
com.apple.voiceservices.keepalive
com.apple.voiced.weekly
com.apple.voiced.neural-compiling
connectionCount
TQ,N,V_connectionCount
runloopSourceRef
T^{__CFRunLoopSource=},N,V_runloopSourceRef
listener
T@"NSXPCListener",&,N,V_listener
VS4CC
VSRecognitionModelDataProvider
NSObject
VSRecognitionResultValidator
VSAudioSession
VSRemoteKeepAlive
VSKeepAliveServer
NSXPCListenerDelegate
VSServerKeepAliveManager
VSKeepAliveClient
VSSpeechServiceDelegate
VSSpeechXPCServiceProtocol
VSSpeechServer
vs_stringFrom4CC:
getValue:weight:atIndex:forClassWithIdentifier:inModelWithIdentifier:
phoneticValueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
valueCountForClassWithIdentifier:inModelWithIdentifier:
valueAtIndex:forClassWithIdentifier:inModelWithIdentifier:
cacheValidityIdentifier
isCacheValidityIdentifierValid:
beginReportingChanges
stopReportingChanges
validRecognitionResultFromRecognitionResult:
validRecognitionResultFromRecognitionResult:knownDisambiguationValues:
init
defaultCenter
_audioSessionInterrupted:
addObserver:selector:name:object:
_mediaServicesWereReset:
removeObserver:
dealloc
userInfo
objectForKey:
integerValue
_setupAudioSession
sharedInstance
setPreferredSampleRate:error:
code
setCategory:error:
categoryOptions
setCategory:withOptions:error:
_setCategoryForActivity:
_nextActivityForActive:activity:serverActivity:
setActive:error:
category
_safeSetupAudioSession
_safeServerGeneration
_safeSetCategoryForActivity:
_safeSetActive:withActivity:
_safeSetBluetoothInputAllowed:
.cxx_destruct
_queue
_audioSessionIsSetUp
_desiredState
_cachedState
_bluetoothAllowed
_activityBag
_serverGeneration
outputLatency
inputLatency
IOBufferDuration
doubleValue
currentRoute
inputs
count
objectAtIndex:
portType
opaqueSessionID
performPostInstallWithCompletion:
sharedService
registerCacheDelete
initWithType:
updateVoicesAndVoiceResources
resume
currentRunLoop
timeIntervalSinceNow
date
sharedManager
resetCache
UTF8String
resetResourcesCache
numberWithDouble:
initWithMachServiceName:
setDelegate:
invalidate
maintainWithAudioType:keepAudioSessionActive:
cancel
interfaceWithProtocol:
setExportedInterface:
setExportedObject:
setInvalidationHandler:
listener:shouldAcceptNewConnection:
_keepAliveListener
_keepAliveManager
addObject:
removeObject:
hasActiveKeepAlives
maintainKeepAlive:
cancelKeepAlive:
_activeKeepAlives
_shouldChangeAudioSession
setManager:
_manager
_isActive
_activity
_keepSessionActive
_transaction
_registryRunLoopSource
scheduleBackgroundTasks
isHomePod
localizedDescription
cleanUnusedAssets:
defaultCacheStore
cleanCache
defaultService
removeOldFiles
installedAssetsForType:voicename:language:gender:footprint:
standardInstance
enableLocalVoices
installedLocalVoices
arrayByAddingObjectsFromArray:
countByEnumeratingWithState:objects:count:
voicePath
isANEModelCompiled:
compileANEModel:
speechRequestDidStart
speechRequestDidPause
speechRequestDidContinue
speechRequestMark:didStartForRange:
speechRequestDidStopWithSuccess:phonemesSpoken:error:
speechRequestSuccessWithInstrumentMetrics:
speechRequestDidReceiveTimingInfo:
synthesisRequest:didReceiveTimingInfo:
synthesisRequest:didFinishWithInstrumentMetrics:error:
presynthesizedAudioRequestDidStart
presynthesizedAudioRequestDidStopAtEnd:error:
presynthesizedAudioRequestSuccessWithInstrumentMetrics:error:
setRemoteObjectInterface:
updateWithConnectionIdentifier:
prewarmIfNeededWithRequest:reply:
queryPhaticCapabilityWithRequest:reply:
estimateDurationWithRequest:reply:
startSpeechRequest:reply:
startSynthesisRequest:
pauseSpeechRequestAtMark:
continueSpeechRequest
stopSpeechRequestAtMark:
startPresynthesizedAudioRequest:
cachePresynthesizedAudioRequest:
stopPresynthesizedAudioRequest
getVoiceNamesForLanguage:reply:
getFootprintsForVoiceName:languageCode:reply:
getSpeechIsActiveReply:
getSpeechIsActiveForConnectionReply:
beginAudioPowerUpdateWithReply:
endAudioPowerUpdate
getLocalVoicesForLanguage:reply:
getLocalVoiceResourcesReply:
setAutoDownloadedVoiceAssets:withClientID:
triggerCellularDownloadedVoiceAssets:withClientID:
getAutoDownloadedVoiceAssetsWithClientID:reply:
getVoiceResourceForLanguage:reply:
getVoiceInfoForLanguageCode:footprint:gender:type:reply:
cancelDownloads:
setLogToFile:
getLogToFile:
getTTSServerVoicesWithFilter:reply:
forwardStreamObject:
invokeDaemon:
killDaemon
arrayWithObjects:count:
setWithArray:
setClasses:forSelector:argumentIndex:ofReply:
initWithConnection:
connectionIdentifier
isSpeaking
connectionCount
setConnectionCount:
runloopSourceRef
setRunloopSourceRef:
listener
setListener:
_connectionCount
_runloopSourceRef
_listener
@20@0:8i16
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
q32@0:8@16@24
@40@0:8q16@24@32
B56@0:8^@16^q24q32@40@48
v16@0:8
q32@0:8@"NSString"16@"NSString"24
@"NSString"40@0:8q16@"NSString"24@"NSString"32
B56@0:8^@16^q24q32@"NSString"40@"NSString"48
@"NSDictionary"16@0:8
B24@0:8@"NSDictionary"16
@24@0:8@16
@32@0:8@16@24
@"VSRecognitionResult"24@0:8@"VSRecognitionResult"16
@"VSRecognitionResult"32@0:8@"VSRecognitionResult"16@"NSDictionary"24
v24@0:8@16
v24@0:8q16
q36@0:8B16q20q28
q16@0:8
v28@0:8B16q20
v20@0:8B16
@"NSObject<OS_dispatch_queue>"
{?="category"q"activity"q}
^{__CFBag=}
Vv28@0:8q16B24
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
@"NSXPCListener"
@"VSServerKeepAliveManager"
@"NSMutableSet"
@"NSObject<OS_os_transaction>"
^{__CFRunLoopSource=}
Vv40@0:8q16{_NSRange=QQ}24
Vv36@0:8B16@20@28
Vv24@0:8@16
Vv32@0:8@16@24
Vv40@0:8@16@24@32
Vv28@0:8B16@20
Vv36@0:8B16@"NSString"20@"NSError"28
Vv24@0:8@"VSInstrumentMetrics"16
Vv24@0:8@"NSArray"16
Vv32@0:8@"VSSpeechRequest"16@"NSArray"24
Vv40@0:8@"VSSpeechRequest"16@"VSInstrumentMetrics"24@"NSError"32
Vv28@0:8B16@"NSError"20
Vv32@0:8@"VSInstrumentMetrics"16@"NSError"24
Vv32@0:8@16@?24
Vv24@0:8q16
Vv40@0:8@16@24@?32
Vv24@0:8@?16
Vv56@0:8@16q24q32q40@?48
Vv20@0:8B16
Vv24@0:8@"NSString"16
Vv32@0:8@"VSSpeechRequest"16@?<v@?@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?B>24
Vv32@0:8@"VSSpeechRequest"16@?<v@?d@"NSError">24
Vv32@0:8@"VSSpeechRequest"16@?<v@?>24
Vv24@0:8@"VSSpeechRequest"16
Vv24@0:8@"VSPresynthesizedAudioRequest"16
Vv32@0:8@"NSString"16@?<v@?@"NSArray">24
Vv40@0:8@"NSString"16@"NSString"24@?<v@?@"NSArray">32
Vv24@0:8@?<v@?B>16
Vv24@0:8@?<v@?@"AFXPCWrapper">16
Vv24@0:8@?<v@?@"NSError">16
Vv32@0:8@"NSString"16@?<v@?@"NSArray"@"NSError">24
Vv24@0:8@?<v@?@"NSArray"@"NSError">16
Vv32@0:8@"NSArray"16@"NSString"24
Vv32@0:8@"NSString"16@?<v@?@"VSVoiceResourceAsset">24
Vv56@0:8@"NSString"16q24q32q40@?<v@?@"VSVoiceAsset">48
Vv24@0:8@?<v@?>16
Vv32@0:8@"VSVoiceAsset"16@?<v@?@"NSArray"@"NSError">24
Vv24@0:8@"SATTSSpeechSynthesisStreaming"16
v24@0:8Q16
^{__CFRunLoopSource=}16@0:8
v24@0:8^{__CFRunLoopSource=}16
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>BuildMachineOSBuild</key>
<string>19A603013</string>
<key>CFBundleDevelopmentRegion</key>
<string>English</string>
<key>CFBundleExecutable</key>
<string>voiced</string>
<key>CFBundleIdentifier</key>
<string>com.apple.voiced</string>
<key>CFBundleInfoDictionaryVersion</key>
<string>6.0</string>
<key>CFBundleName</key>
<string>voiced</string>
<key>CFBundlePackageType</key>
<string>FMWK</string>
<key>CFBundleShortVersionString</key>
<string>1.0.0</string>
<key>CFBundleSignature</key>
<string>????</string>
<key>CFBundleSupportedPlatforms</key>
<array>
<string>iPhoneSimulator</string>
</array>
<key>CFBundleVersion</key>
<string>1.0</string>
<key>DTCompiler</key>
<string>com.apple.compilers.llvm.clang.1_0</string>
<key>DTPlatformBuild</key>
<string>12A8179f</string>
<key>DTPlatformName</key>
<string>iphonesimulator</string>
<key>DTPlatformVersion</key>
<string>14.2</string>
<key>DTSDKBuild</key>
<string>18B5072c</string>
<key>DTSDKName</key>
<string>iphonesimulator14.2.internal</string>
<key>DTXcode</key>
<string>1200</string>
<key>DTXcodeBuild</key>
<string>12A8179f</string>
<key>MinimumOSVersion</key>
<string>14.2</string>
<key>UIDeviceFamily</key>
<array>
<integer>1</integer>
<integer>2</integer>
</array>
</dict>
</plist>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
<key>abs-client</key>
<string>1821501079</string>
<key>application-identifier</key>
<string>com.apple.voiced</string>
<key>com.apple.Contacts.database-allow</key>
<true/>
<key>com.apple.coreaudio.allow-opus-codec</key>
<true/>
<key>com.apple.coreaudio.register-internal-aus</key>
<true/>
<key>com.apple.developer.networking.multipath_extended</key>
<true/>
<key>com.apple.private.assets.accessible-asset-types</key>
<array>
<string>com.apple.MobileAsset.VoiceServices.CustomVoice</string>
<string>com.apple.MobileAsset.VoiceServices.VoiceResources</string>
<string>com.apple.MobileAsset.VoiceServicesVocalizerVoice</string>
<string>com.apple.MobileAsset.VoiceServices.GryphonVoice</string>
</array>
<key>com.apple.private.assets.change-daemon-config</key>
<true/>
<key>com.apple.private.coreaudio.borrowaudiosession.allow</key>
<true/>
<key>com.apple.private.tcc.allow</key>
<array>
<string>kTCCServiceAddressBook</string>
<string>kTCCServiceMicrophone</string>
<string>kTCCServiceMediaLibrary</string>
</array>
<key>com.apple.security.iokit-user-client-class</key>
<array>
<string>AGXCommandQueue</string>
<string>AGXDevice</string>
<string>AGXDeviceUserClient</string>
<string>AGXSharedUserClient</string>
<string>H11ANEInDirectPathClient</string>
<string>IOAccelContext</string>
<string>IOAccelContext2</string>
<string>IOAccelDevice</string>
<string>IOAccelDevice2</string>
<string>IOAccelSharedUserClient</string>
<string>IOAccelSharedUserClient2</string>
<string>IOAccelSubmitter2</string>
<string>IOSurfaceRootUserClient</string>
</array>
<key>com.apple.siri.client_lite</key>
<true/>
<key>com.apple.tailspin.dump-output</key>
<true/>
<key>fairplay-client</key>
<string>511712240</string>
<key>keychain-access-groups</key>
<array>
<string>com.apple.siri.osprey</string>
</array>
</dict>
</plist>
